{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPu_tWr1WsxR"
   },
   "source": [
    "<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500,>\n",
    "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4TIC_99WsxT"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ezjWeWD7WsxU"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Домашнее задание: соревнование на Kaggle по распознаванию одежды</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bsX5wbIWsxV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-V-v1F-WsxW"
   },
   "source": [
    "Всем привет!  \n",
    "\n",
    "Надеемся, что вам показались интересными и понятными лекция и семинар по многослйным нейросетям и PyTorch. Если же Вы ещё не успели ими насладиться -- просьба посмотреть видео на нашем канале и просмотреть ноутбуки с семинара, в этом ноутбуке эти знания будут использоваться на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkmeeD-iWsxX"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>FashionMNIST</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AygNFOvoWsxY"
   },
   "source": [
    "<img src=\"https://emiliendupont.github.io/imgs/mnist-chicken/mnist-and-fashion-examples.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo4NBY_VWsxZ"
   },
   "source": [
    "Выше изображены примеры того, с чем мы будем работать -- чёрно-белые изображения одежды. Слева более классический датасет -- MNIST, он же датасет рукописных цифр. Мы решили, что вам будет интереснее всё же рнаучить машину распознавать одежду (спойлер: с рукописными цифрами такой подход это тоже будут работать ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1PNq7r2Wsxc"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Ссылка на соревнование: https://www.kaggle.com/c/dlschool-fashionmnist3. Вам нужно скачать оттуда всё из раздела `Data`, далее мы будем работать с этим - обучаться на train и предсказывать на test.</b></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvTA4J9mWsxa"
   },
   "source": [
    "<h4 style=\"text-align: center;\"><b>Оргиниальный датасет: https://www.kaggle.com/zalando-research/fashionmnist</b></h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "79CtpmmbWsxe"
   },
   "source": [
    "После скачивания (скачанный архив распакуйте в одну папку с этим ноутбуком) и регистрации на Kaggle Вам нужно вступить в соревнование (по ссылке выше) и прочитать его описание.\n",
    "\n",
    "<h3 style=\"text-align: center;\"><b>Пожалуйста, укажите в соревновании свой ник == вашему нику на Canvas, иначе мы не сможем потом поставить вам баллы</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0FUJIqEWsxf"
   },
   "source": [
    "Платформа **Kaggle** -- основная платформа для соревнований в Data Science, так что привыкайте ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-u9DDJYWsxg"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Данные</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNF5C2b_Wsxh"
   },
   "source": [
    "Мы будем работать с картинками одежды (чёрно-белыми, то есть цветовых каналов не 3, а 1). По входной картинке нужно предсказать тип одежды. Давайте посмотрим на то, что за датасет мы скачали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ASlXpLtWsxi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EW5PlYt_Wsxm"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = './fashionmnist/fashion-mnist_train.csv'\n",
    "TEST_PATH = './fashionmnist/fashion-mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7gRnQkxWsxq"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fddbeN1fWsxt",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>105</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>136</td>\n",
       "      <td>155</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>138</td>\n",
       "      <td>151</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>225</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>146</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>210</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>158</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>227</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>219</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>197</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>117</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>67</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>182</td>\n",
       "      <td>199</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>119</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0          0       0       0       0       0       0       0       9       8   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          0       0       0       0       0       0      14      53      99   \n",
       "3          0       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "5          0       0       0       0       0      44     105      44      10   \n",
       "6          0       0       0       0       0       0       0       0       0   \n",
       "7          0       0       0       0       0       0       0       1       0   \n",
       "8          0       0       0       0       0       0       0       0       0   \n",
       "9          0       0       0       0       0       0       0       0       0   \n",
       "10         0       0       0       0       0       0       0       1       0   \n",
       "11         0       0       0       0       0       0       1       1       0   \n",
       "12         0       0       0       0       0       0       0       0       0   \n",
       "13         0       0       0       0       0       0       1       1       0   \n",
       "14         0       0       0       0       0       0       0       0       0   \n",
       "15         0       0       0       0       0       0       0       0       0   \n",
       "16         0       0       0       0       0       0       1       5       0   \n",
       "17         0       0       0       0       0       0       0       0      15   \n",
       "18         0       0       0       0       0       0       0       2       2   \n",
       "19         0       0       0       0       0       0       0       0       0   \n",
       "20         0       0       0       0       0       0       0       0       0   \n",
       "21         0       0       0       0       0       0       0       0       0   \n",
       "22         0       0       0       0       0       0       1       0       0   \n",
       "23         0       0       0       0       0       0       0       0       0   \n",
       "24         0       0       0       0       0       0       0       0       0   \n",
       "25         0       0       0       0       0       0       0       0       0   \n",
       "26         0       0       0       0       0       0       0       0       0   \n",
       "27         0       0       0       0       0       0       0       0       0   \n",
       "28         0       0       0       0       0       0       0       0       0   \n",
       "29         0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9970       0       0       0       0       0       0       0       0       0   \n",
       "9971       0       0       0       0       0       0       0       0       0   \n",
       "9972       0       0       0       0       0       0       0       0       0   \n",
       "9973       0       0       0       0       0       0       0       0       0   \n",
       "9974       0       0       0       0       0       0       0       0       0   \n",
       "9975       0       0       3       0       1       2       0       0       0   \n",
       "9976       0       0       0       0       0       0       0       0       0   \n",
       "9977       0       0       0       0       0       0       0       0       0   \n",
       "9978       0       0       0       0       0       0       0       0       0   \n",
       "9979       0       0       0       0       0       0       1       0       0   \n",
       "9980       0       0       0       0       0       0       0       0       0   \n",
       "9981       0       0       0       0       0       0       0       0       0   \n",
       "9982       0       0       0       0       0       0       0       0       0   \n",
       "9983       0       0       0       0       0       0       0       0       0   \n",
       "9984       0       0       0       0       0       0       0       0       0   \n",
       "9985       0       0       0       0       0       0       0       0       0   \n",
       "9986       0       0       0       0       2       0       2       0       0   \n",
       "9987       0       0       0       0       0       0       0       0       0   \n",
       "9988       0       0       0       0       0       0       0       0       0   \n",
       "9989       0       0       0       0       0       0       0       0       0   \n",
       "9990       0       0       0       0       0       0       0       0       0   \n",
       "9991       0       0       0       0       0       0       0       0       0   \n",
       "9992       0       0       0       0       0       0       0       0       0   \n",
       "9993       0       0       0       0       0       0       0       0       0   \n",
       "9994       0       0       0       0       0       0       0       1       0   \n",
       "9995       0       0       0       0       0       0       0       0       0   \n",
       "9996       0       0       0       0       0       0       0       0       0   \n",
       "9997       0       0       0       0       0       0       0       0       0   \n",
       "9998       0       1       3       0       0       0       0       0       0   \n",
       "9999       0       0       0       0       0       0       0     140     119   \n",
       "\n",
       "      pixel10    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0    ...          103        87        56         0         0   \n",
       "1           0    ...           34         0         0         0         0   \n",
       "2          17    ...            0         0         0         0        63   \n",
       "3         161    ...          137       126       140         0       133   \n",
       "4           0    ...            0         0         0         0         0   \n",
       "5           0    ...          105        64        30         0         0   \n",
       "6           0    ...            0         0         0         0         0   \n",
       "7           0    ...          174       136       155        31         0   \n",
       "8           0    ...            0         0         0         0         0   \n",
       "9           0    ...           57        70        28         0         2   \n",
       "10          0    ...           12         0         0         0         0   \n",
       "11          0    ...            2         0        21       138       151   \n",
       "12          0    ...          118        73         0       164       225   \n",
       "13          0    ...            0         0         0         0        17   \n",
       "14          0    ...            0         0         0         0         0   \n",
       "15          0    ...            0         0         0         0         0   \n",
       "16          0    ...           90        60         0       129       146   \n",
       "17        132    ...            3         0         3         0         0   \n",
       "18          2    ...            0         0         0         5         3   \n",
       "19          0    ...            0         0         0         0         0   \n",
       "20          0    ...          187       210        52         0         2   \n",
       "21          0    ...            0         1         0         0         0   \n",
       "22          0    ...            0         0         0       118       158   \n",
       "23          4    ...          227        96         0         0         0   \n",
       "24          0    ...            0         0         0         0         0   \n",
       "25          0    ...            0         0         0         0         0   \n",
       "26          3    ...           39        31        19        19         0   \n",
       "27          0    ...           50        17         0         0         0   \n",
       "28          0    ...            0         0       215       219       172   \n",
       "29         18    ...          197       177         0         0         0   \n",
       "...       ...    ...          ...       ...       ...       ...       ...   \n",
       "9970        0    ...            0         0         0         0         0   \n",
       "9971        0    ...            0         0         0         0         0   \n",
       "9972       65    ...           63        32         0         0         0   \n",
       "9973        0    ...           82         1         0         0         0   \n",
       "9974        0    ...            0         0         0         0         0   \n",
       "9975        0    ...          127       117       110         0         0   \n",
       "9976        0    ...           95        98        98        96        99   \n",
       "9977        0    ...            0         0         0         0         0   \n",
       "9978        0    ...            0         0         0         0         0   \n",
       "9979        0    ...            0         0         0         0         0   \n",
       "9980        0    ...            0         0         0         0         0   \n",
       "9981        0    ...            0         0         0         0        70   \n",
       "9982        0    ...            0         0         0         0         0   \n",
       "9983        0    ...            0         0         0         0         0   \n",
       "9984        0    ...            0         0         0         0         0   \n",
       "9985        0    ...           94        74         0         0         0   \n",
       "9986        0    ...            7         0         0         1         0   \n",
       "9987        0    ...           63        44         0         0        38   \n",
       "9988        0    ...            0         0         0         0         0   \n",
       "9989        0    ...            0         0         0         0         0   \n",
       "9990        0    ...            0         0         0         0         0   \n",
       "9991        0    ...            0         0         0         0         0   \n",
       "9992        0    ...          120         0         0         1         0   \n",
       "9993        0    ...            0         0         0         0         0   \n",
       "9994        2    ...           85        67       114        51         0   \n",
       "9995       37    ...           32        23        14        20         0   \n",
       "9996        0    ...            0         0         0         2        52   \n",
       "9997        0    ...          175       172       172       182       199   \n",
       "9998        0    ...            0         0         0         0         0   \n",
       "9999      103    ...          111        95        75        44         1   \n",
       "\n",
       "      pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0            0         0         0         0         0  \n",
       "1            0         0         0         0         0  \n",
       "2           53        31         0         0         0  \n",
       "3          224       222        56         0         0  \n",
       "4            0         0         0         0         0  \n",
       "5            0         0         0         0         0  \n",
       "6            0         0         0         0         0  \n",
       "7            1         0         0         0         0  \n",
       "8            0         0         0         0         0  \n",
       "9            0         0         0         0         0  \n",
       "10           0         0         0         0         0  \n",
       "11          71         0         0         0         0  \n",
       "12         123         0         0         0         0  \n",
       "13           0         0         0         0         0  \n",
       "14           0         0         0         0         0  \n",
       "15           0         0         0         0         0  \n",
       "16          78         0         0         0         0  \n",
       "17           0         0         0         0         0  \n",
       "18           1         0         0         0         0  \n",
       "19          50       107        18         0         0  \n",
       "20           0         0         0         0         0  \n",
       "21           0         0         0         0         0  \n",
       "22          92         0         0         0         0  \n",
       "23           0         0         0         0         0  \n",
       "24           0         0         0         0         0  \n",
       "25           0         0         0         0         0  \n",
       "26           0         0         0         0         0  \n",
       "27           1         4         1         0         0  \n",
       "28           0         0         0         0         0  \n",
       "29           0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "9970         0         0         0         0         0  \n",
       "9971         0         0         0         0         0  \n",
       "9972         1         0         0         0         0  \n",
       "9973         0         0         0         0         0  \n",
       "9974         0         0         0         0         0  \n",
       "9975         1         0         0         0         0  \n",
       "9976        87        50         0         0         0  \n",
       "9977         0         0         0         0         0  \n",
       "9978         0         0         0         0         0  \n",
       "9979         0         1        34         0         0  \n",
       "9980         0         0         0         0         0  \n",
       "9981        89        30         0         0         0  \n",
       "9982         0         0         0         0         0  \n",
       "9983         0         0         0         0         0  \n",
       "9984         0         0         0         0         0  \n",
       "9985         0         0         0         0         0  \n",
       "9986         1         1         0         1         0  \n",
       "9987        38        44         0         0         0  \n",
       "9988         0         0         0         0         0  \n",
       "9989         0         0         0         0         0  \n",
       "9990         0         0         0         0         0  \n",
       "9991         0         0         0         0         0  \n",
       "9992         0         0         0         0         0  \n",
       "9993         0         0         0         0         0  \n",
       "9994         1         0         0         0         0  \n",
       "9995         0         1         0         0         0  \n",
       "9996        23        28         0         0         0  \n",
       "9997       222        42         0         1         0  \n",
       "9998         1         0         0         0         0  \n",
       "9999         0         0         0         0         0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIiU_p1sWsx0"
   },
   "source": [
    "Выведем начало таблиц:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5L7SZzJWsx2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxopo2vFWsx7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0       0       0       0       0       0       0       0       9       8   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0      14      53      99   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel10    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0        0    ...          103        87        56         0         0   \n",
       "1        0    ...           34         0         0         0         0   \n",
       "2       17    ...            0         0         0         0        63   \n",
       "3      161    ...          137       126       140         0       133   \n",
       "4        0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rit5xeXHWsx_"
   },
   "source": [
    "Выведем размеры обучающей и тестовой выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jqayM9nWsyA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMqwe6RyWsyE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "StH0t16pWsyI"
   },
   "source": [
    "Что значат эти размеры и числа внутри DataFrame'ов? Всё просто -- **каждая строчка соответствует одной картинке**, а **столбцы -- это значения в пикселях этой кратинки**. **Первый столбец в train_df говорит о типе (классе) одежды (от 0 до 9)**.  \n",
    "\n",
    "Однако перед тем, как двигаться дальше, краткая информация о представлении изображений в компьютере:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnuz9mU1WsyJ"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Изображения</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kux-xnPyWsyK"
   },
   "source": [
    "<p align=center><img src=\"https://openclipart.org/image/2400px/svg_to_png/136057/1304647802.png\" width=300 height=300></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpLs0GgVWsyM"
   },
   "source": [
    "Как и вся информация, изображения представляются в компьютере числами. Стандартное цветовое пространство, с помощью которого декодируют и отрисовывают изображение -- это RGB (Red, Green и Blue). Каждая комбинация трёх чисел от 0 до 255 задаёт какой-то цвет. Например, (255,255,255) задаёт белый цвет, (255,0,0) -- красный. Также происходит и при загрузке картинок в Python, давайте посмотрим напрмиере:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkmJr74RWsyN"
   },
   "source": [
    "* Загрузим произвольную цветную картинку с помощью matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gubsex4JWsyO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWfoM2hnWsyT"
   },
   "outputs": [],
   "source": [
    "image_png = plt.imread('./fpmi_logo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UuzzHQNrWsyX",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9098039 , 0.9254902 , 0.94509804, 0.5686275 ],\n",
       "        [0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "        [0.9098039 , 0.9254902 , 0.94509804, 0.5686275 ]],\n",
       "\n",
       "       [[0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.89411765, 0.92156863, 0.92156863, 0.14901961]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.89411765, 0.92156863, 0.92156863, 0.14901961]],\n",
       "\n",
       "       [[0.9098039 , 0.9254902 , 0.94509804, 0.5686275 ],\n",
       "        [0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "        [0.9098039 , 0.9254902 , 0.94509804, 0.5686275 ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKVe5uU9Wsyc"
   },
   "source": [
    "* Посмотрим на тип загруженного объекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8S2w7zeWsye"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7nQeNrQWsyh"
   },
   "source": [
    "Интересно, картинка стала `numpy.array`. А какая его форма и что внутри?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4JEd1oqWsyi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716, 2232, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_png.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_yPEQV8_Wsym",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2232, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_png[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB7zP_fBWsyp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9098039 , 0.9254902 , 0.94509804, 0.5686275 ],\n",
       "       [0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.89411765, 0.92156863, 0.92156863, 0.14901961],\n",
       "       [0.9098039 , 0.9254902 , 0.94509804, 0.5686275 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_png[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANo0JUCHWsyv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_png.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "urWGXYTQWsy1"
   },
   "source": [
    "То есть это какая матрица, а точнее тензор (потому что есть третья размерность), у которого 573 строки, 1579 столбцов и 4 канала. Можно представлять это себе как 4 наложенных друг на друга матрицы, каждая из которых отвечает за один цвет -- R, G и B.  Внутри всех этих матриц лежат числа типа float32, то есть вещественные. Тут стоит сказать, что это просто тонкости загрузки в matplotlib -- на самом деле это матрицы из целых числе от 0 до 255 (включительно).\n",
    "\n",
    "Стоп, но ведь каналов 4, а не 3? Да, четвёртый канал в данном случае -- это альфа-канал, у .png картинок он обычно присутствует. Давайте попробуем загрузить .jpg картинку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxJbveMsWsy2"
   },
   "outputs": [],
   "source": [
    "image_jpg = plt.imread('./dlschool_logo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jyYk-jM1Wsy4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_jpg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RT8fmjS6Wsy8"
   },
   "source": [
    "Отлично, теперь 3 канала и нам совсем не страшно -- это три матрицы 400 на 400, каждая из которых отвечает за один цвет. Давайте отрисуем две загруженные картинки с помощью matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tses8xyIWsy9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_png);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eM1kkdsWszA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_jpg);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfdPDmeJWszD"
   },
   "source": [
    "В данном случае **пиксель** -- это кортеж (упорядоченная последовательность чисел), состоящий из трёх чисел (как в примере раньше, например, (255,0,0) -- полностью красный пиксель). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eK39snZEWszF"
   },
   "source": [
    "Итак, картинки -- это матрицы, состоящие из чисел, которые характеризуют насышенность данного пикселя определённым цветом цветом.  \n",
    "\n",
    "Аналогично и с **чёрно-белыми изображениями** -- это просто матрица с одним каналом (то есть пксель -- это просто число), например, 28 на 28, каждое число которой от 0 до 255 характеризует яркость пикселя (насыщенность белым). \n",
    "Например, 255 -- это полностью белый пиксель, 0 -- полностью чёрный. Пора посмотреть, с чем мы будем работать в соревновании."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYFINa9AWszF"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Данные (2)</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ua4SkGMiWszG"
   },
   "source": [
    "Вернёмся к данным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkWg8nbCWszH",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>214</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>177</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>190</td>\n",
       "      <td>162</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>142</td>\n",
       "      <td>69</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>93</td>\n",
       "      <td>87</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>166</td>\n",
       "      <td>165</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59970</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59971</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59972</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59973</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59974</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59975</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59976</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59977</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59978</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59979</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59981</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59982</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>115</td>\n",
       "      <td>114</td>\n",
       "      <td>132</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59983</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59984</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59985</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59986</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "      <td>124</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59987</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59988</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59989</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>131</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>161</td>\n",
       "      <td>165</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59991</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59992</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59993</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>113</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59994</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>135</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          2       0       0       0       0       0       0       0       0   \n",
       "1          9       0       0       0       0       0       0       0       0   \n",
       "2          6       0       0       0       0       0       0       0       5   \n",
       "3          0       0       0       0       1       2       0       0       0   \n",
       "4          3       0       0       0       0       0       0       0       0   \n",
       "5          4       0       0       0       5       4       5       5       3   \n",
       "6          4       0       0       0       0       0       0       0       0   \n",
       "7          5       0       0       0       0       0       0       0       0   \n",
       "8          4       0       0       0       0       0       0       3       2   \n",
       "9          8       0       0       0       0       0       0       0       0   \n",
       "10         0       0       0       0       0       1       0       0       0   \n",
       "11         8       0       0       0       0       0       0       0       0   \n",
       "12         9       0       0       0       0       0       0       0       0   \n",
       "13         0       0       0       0       0       0       0       0       0   \n",
       "14         2       0       0       0       0       1       1       0       0   \n",
       "15         2       0       0       0       0       0       0       0       0   \n",
       "16         9       0       0       0       0       0       0       0       0   \n",
       "17         3       0       0       0       0       0       0       0       0   \n",
       "18         3       0       0       0       0       0       0       0       0   \n",
       "19         3       0       0       0       0       0       0       0       0   \n",
       "20         8       0       0       0       0       0       0       0       0   \n",
       "21         7       0       0       0       0       0       0       0       0   \n",
       "22         4       0       0       0       0       0       0       0       0   \n",
       "23         4       0       0       0       0       0       1       0       1   \n",
       "24         0       0       0       0       0       0       0       0       0   \n",
       "25         4       0       0       0       0       2       0       0       0   \n",
       "26         4       0       0       0       0       0       0       0       1   \n",
       "27         8       0       0       0       0       0       0       0       1   \n",
       "28         7       0       0       0       0       0       0       0       0   \n",
       "29         1       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "59970      7       0       0       0       0       0       0       0       0   \n",
       "59971      5       0       0       0       0       0       0       0       0   \n",
       "59972      2       0       0       0       0       0       0       0       0   \n",
       "59973      8       0       0       0       0       0       0       0       0   \n",
       "59974      7       0       0       0       0       0       0       0       0   \n",
       "59975      9       0       0       0       0       0       0       0       0   \n",
       "59976      5       0       0       0       0       0       0       0       0   \n",
       "59977      8       0       0       0       0       0       0       0       0   \n",
       "59978      6       0       0       0       0       0       0       0       0   \n",
       "59979      5       0       0       0       0       0       0       0       0   \n",
       "59980      0       0       0       0       2       0       0       0       0   \n",
       "59981      5       0       0       0       0       0       0       0       0   \n",
       "59982      5       0       0       0       0       0       0       0       0   \n",
       "59983      5       0       0       0       0       0       0       0       0   \n",
       "59984      7       0       0       0       0       0       0       0       0   \n",
       "59985      6       0       0       0       0       0       0       0       0   \n",
       "59986      6       0       0       0       0       0       0       0       0   \n",
       "59987      5       0       0       0       0       0       0       0       0   \n",
       "59988      5       0       0       0       0       0       0       0       0   \n",
       "59989      4       0       0       0       0       0       0       0       0   \n",
       "59990      0       0       0       0       0       0       0       0       0   \n",
       "59991      5       0       0       0       0       0       0       0       0   \n",
       "59992      5       0       0       0       0       0       0       0       0   \n",
       "59993      2       0       0       0       0       0       0       1       0   \n",
       "59994      9       0       0       0       0       0       0       0       0   \n",
       "59995      9       0       0       0       0       0       0       0       0   \n",
       "59996      1       0       0       0       0       0       0       0       0   \n",
       "59997      8       0       0       0       0       0       0       0       0   \n",
       "59998      8       0       0       0       0       0       0       0       0   \n",
       "59999      7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0    ...            0         0         0         0         0   \n",
       "1           0    ...            0         0         0         0         0   \n",
       "2           0    ...            0         0         0        30        43   \n",
       "3           0    ...            3         0         0         0         0   \n",
       "4           0    ...            0         0         0         0         0   \n",
       "5           5    ...            7         8         7         4         3   \n",
       "6           0    ...           14         0         0         0         0   \n",
       "7           0    ...            0         0         0         0         0   \n",
       "8           0    ...            1         0         0         0         0   \n",
       "9           0    ...          203       214       166         0         0   \n",
       "10          0    ...          164       177       163         0         0   \n",
       "11          0    ...            9        10         9         9         8   \n",
       "12          0    ...            0         0         0         0         0   \n",
       "13          0    ...            0         0         0         0         0   \n",
       "14          0    ...            0         0       118       190       162   \n",
       "15         16    ...            0         0         1         1         1   \n",
       "16          0    ...            0         0         0         0         0   \n",
       "17          0    ...          101        20         0         0         1   \n",
       "18          0    ...            0        11        15         0         0   \n",
       "19          0    ...            0         0         0         0         0   \n",
       "20          0    ...           80        73        62        37        16   \n",
       "21          0    ...            0         0         0         0         0   \n",
       "22          0    ...           69         0         0         2         0   \n",
       "23          0    ...            0         0         2         0        61   \n",
       "24         40    ...          125        93        87        49         0   \n",
       "25          1    ...            4         1         0         7       166   \n",
       "26          0    ...          153        45         0         0         0   \n",
       "27          0    ...           15        23        10        19        21   \n",
       "28          0    ...            0         0         0         0         0   \n",
       "29          0    ...            0         1         0         0         0   \n",
       "...       ...    ...          ...       ...       ...       ...       ...   \n",
       "59970       0    ...            0         0         0         0         0   \n",
       "59971       0    ...            0         0         0         0         0   \n",
       "59972       0    ...            0         0         0         0         0   \n",
       "59973       0    ...            0         0         0         0         0   \n",
       "59974       0    ...            0         0         0         0         0   \n",
       "59975       0    ...            0         0         0         0         0   \n",
       "59976       0    ...            0         0         0         0         0   \n",
       "59977       0    ...            0         0         0         0         0   \n",
       "59978       0    ...            0         0         0         0         1   \n",
       "59979       0    ...            0         0         0         0         0   \n",
       "59980       0    ...           37        25         9         0         0   \n",
       "59981       0    ...            0         0         0         0         0   \n",
       "59982       0    ...           61        58        70       115       114   \n",
       "59983       0    ...            0         0         0         0         0   \n",
       "59984       0    ...            0         0         0         0         0   \n",
       "59985       0    ...            0         0         0         0         0   \n",
       "59986       0    ...            0         0         0         0        20   \n",
       "59987       0    ...            0         0         0         0         0   \n",
       "59988       0    ...            0         0         0         0         0   \n",
       "59989       0    ...          122       131        25         0         0   \n",
       "59990       0    ...          154       161       165        83         0   \n",
       "59991       0    ...            0         0         0         0         0   \n",
       "59992       0    ...            0         0         0         0         0   \n",
       "59993       0    ...            0         0         0         0       141   \n",
       "59994       0    ...            0         0         0         0         0   \n",
       "59995       0    ...            0         0         0         0         0   \n",
       "59996       0    ...           73         0         0         0         0   \n",
       "59997       0    ...          160       162       163       135        94   \n",
       "59998       0    ...            0         0         0         0         0   \n",
       "59999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             1         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "5             7         5         0         0         0  \n",
       "6             0         0         0         0         0  \n",
       "7             0         0         0         0         0  \n",
       "8             0         0         0         0         0  \n",
       "9             0         0         0         0         0  \n",
       "10            1         0         0         0         0  \n",
       "11            1         0         0         0         0  \n",
       "12            0         0         0         0         0  \n",
       "13            0         1         0         0         0  \n",
       "14           82         0         0         0         0  \n",
       "15            1         0         0         0         0  \n",
       "16            0         0         0         0         0  \n",
       "17            0         0         0         0         0  \n",
       "18            0         0         0         0         0  \n",
       "19            0         0         0         0         0  \n",
       "20            0         0         0         0         0  \n",
       "21            0         0         0         0         0  \n",
       "22            0         0         0         0         0  \n",
       "23          142        69        97         0         0  \n",
       "24            0         0         0         0         0  \n",
       "25          165        89         0         0         0  \n",
       "26            0         0         0         0         0  \n",
       "27           41        78         6         0         0  \n",
       "28            0         0         0         0         0  \n",
       "29            0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "59970         0         0         0         0         0  \n",
       "59971         0         0         0         0         0  \n",
       "59972         0         0         0         0         0  \n",
       "59973         0         0         0         0         0  \n",
       "59974         0         0         0         0         0  \n",
       "59975         0         0         0         0         0  \n",
       "59976         0         0         0         0         0  \n",
       "59977         0         0         0         0         0  \n",
       "59978         0         0         0         0         0  \n",
       "59979         0         0         0         0         0  \n",
       "59980         0         0         0         0         0  \n",
       "59981         0         0         0         0         0  \n",
       "59982       132        73         0         0         0  \n",
       "59983         0         0         0         0         0  \n",
       "59984         0         0         0         0         0  \n",
       "59985         0         0         0         0         0  \n",
       "59986       126       124        27         0         0  \n",
       "59987         0         0         0         0         0  \n",
       "59988         0         0         0         0         0  \n",
       "59989         0         0         0         0         0  \n",
       "59990         5         0         0         0         0  \n",
       "59991         0         0         0         0         0  \n",
       "59992         0         0         0         0         0  \n",
       "59993       113         9         0         0         0  \n",
       "59994         0         0         0         0         0  \n",
       "59995         0         0         0         0         0  \n",
       "59996         0         0         0         0         0  \n",
       "59997         0         0         0         0         0  \n",
       "59998         0         0         0         0         0  \n",
       "59999         0         0         0         0         0  \n",
       "\n",
       "[60000 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i45xDzltWszM",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>105</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>136</td>\n",
       "      <td>155</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>138</td>\n",
       "      <td>151</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>225</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>146</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>107</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>210</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>158</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>227</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>219</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>197</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>127</td>\n",
       "      <td>117</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>67</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>182</td>\n",
       "      <td>199</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>119</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0          0       0       0       0       0       0       0       9       8   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          0       0       0       0       0       0      14      53      99   \n",
       "3          0       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "5          0       0       0       0       0      44     105      44      10   \n",
       "6          0       0       0       0       0       0       0       0       0   \n",
       "7          0       0       0       0       0       0       0       1       0   \n",
       "8          0       0       0       0       0       0       0       0       0   \n",
       "9          0       0       0       0       0       0       0       0       0   \n",
       "10         0       0       0       0       0       0       0       1       0   \n",
       "11         0       0       0       0       0       0       1       1       0   \n",
       "12         0       0       0       0       0       0       0       0       0   \n",
       "13         0       0       0       0       0       0       1       1       0   \n",
       "14         0       0       0       0       0       0       0       0       0   \n",
       "15         0       0       0       0       0       0       0       0       0   \n",
       "16         0       0       0       0       0       0       1       5       0   \n",
       "17         0       0       0       0       0       0       0       0      15   \n",
       "18         0       0       0       0       0       0       0       2       2   \n",
       "19         0       0       0       0       0       0       0       0       0   \n",
       "20         0       0       0       0       0       0       0       0       0   \n",
       "21         0       0       0       0       0       0       0       0       0   \n",
       "22         0       0       0       0       0       0       1       0       0   \n",
       "23         0       0       0       0       0       0       0       0       0   \n",
       "24         0       0       0       0       0       0       0       0       0   \n",
       "25         0       0       0       0       0       0       0       0       0   \n",
       "26         0       0       0       0       0       0       0       0       0   \n",
       "27         0       0       0       0       0       0       0       0       0   \n",
       "28         0       0       0       0       0       0       0       0       0   \n",
       "29         0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9970       0       0       0       0       0       0       0       0       0   \n",
       "9971       0       0       0       0       0       0       0       0       0   \n",
       "9972       0       0       0       0       0       0       0       0       0   \n",
       "9973       0       0       0       0       0       0       0       0       0   \n",
       "9974       0       0       0       0       0       0       0       0       0   \n",
       "9975       0       0       3       0       1       2       0       0       0   \n",
       "9976       0       0       0       0       0       0       0       0       0   \n",
       "9977       0       0       0       0       0       0       0       0       0   \n",
       "9978       0       0       0       0       0       0       0       0       0   \n",
       "9979       0       0       0       0       0       0       1       0       0   \n",
       "9980       0       0       0       0       0       0       0       0       0   \n",
       "9981       0       0       0       0       0       0       0       0       0   \n",
       "9982       0       0       0       0       0       0       0       0       0   \n",
       "9983       0       0       0       0       0       0       0       0       0   \n",
       "9984       0       0       0       0       0       0       0       0       0   \n",
       "9985       0       0       0       0       0       0       0       0       0   \n",
       "9986       0       0       0       0       2       0       2       0       0   \n",
       "9987       0       0       0       0       0       0       0       0       0   \n",
       "9988       0       0       0       0       0       0       0       0       0   \n",
       "9989       0       0       0       0       0       0       0       0       0   \n",
       "9990       0       0       0       0       0       0       0       0       0   \n",
       "9991       0       0       0       0       0       0       0       0       0   \n",
       "9992       0       0       0       0       0       0       0       0       0   \n",
       "9993       0       0       0       0       0       0       0       0       0   \n",
       "9994       0       0       0       0       0       0       0       1       0   \n",
       "9995       0       0       0       0       0       0       0       0       0   \n",
       "9996       0       0       0       0       0       0       0       0       0   \n",
       "9997       0       0       0       0       0       0       0       0       0   \n",
       "9998       0       1       3       0       0       0       0       0       0   \n",
       "9999       0       0       0       0       0       0       0     140     119   \n",
       "\n",
       "      pixel10    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0    ...          103        87        56         0         0   \n",
       "1           0    ...           34         0         0         0         0   \n",
       "2          17    ...            0         0         0         0        63   \n",
       "3         161    ...          137       126       140         0       133   \n",
       "4           0    ...            0         0         0         0         0   \n",
       "5           0    ...          105        64        30         0         0   \n",
       "6           0    ...            0         0         0         0         0   \n",
       "7           0    ...          174       136       155        31         0   \n",
       "8           0    ...            0         0         0         0         0   \n",
       "9           0    ...           57        70        28         0         2   \n",
       "10          0    ...           12         0         0         0         0   \n",
       "11          0    ...            2         0        21       138       151   \n",
       "12          0    ...          118        73         0       164       225   \n",
       "13          0    ...            0         0         0         0        17   \n",
       "14          0    ...            0         0         0         0         0   \n",
       "15          0    ...            0         0         0         0         0   \n",
       "16          0    ...           90        60         0       129       146   \n",
       "17        132    ...            3         0         3         0         0   \n",
       "18          2    ...            0         0         0         5         3   \n",
       "19          0    ...            0         0         0         0         0   \n",
       "20          0    ...          187       210        52         0         2   \n",
       "21          0    ...            0         1         0         0         0   \n",
       "22          0    ...            0         0         0       118       158   \n",
       "23          4    ...          227        96         0         0         0   \n",
       "24          0    ...            0         0         0         0         0   \n",
       "25          0    ...            0         0         0         0         0   \n",
       "26          3    ...           39        31        19        19         0   \n",
       "27          0    ...           50        17         0         0         0   \n",
       "28          0    ...            0         0       215       219       172   \n",
       "29         18    ...          197       177         0         0         0   \n",
       "...       ...    ...          ...       ...       ...       ...       ...   \n",
       "9970        0    ...            0         0         0         0         0   \n",
       "9971        0    ...            0         0         0         0         0   \n",
       "9972       65    ...           63        32         0         0         0   \n",
       "9973        0    ...           82         1         0         0         0   \n",
       "9974        0    ...            0         0         0         0         0   \n",
       "9975        0    ...          127       117       110         0         0   \n",
       "9976        0    ...           95        98        98        96        99   \n",
       "9977        0    ...            0         0         0         0         0   \n",
       "9978        0    ...            0         0         0         0         0   \n",
       "9979        0    ...            0         0         0         0         0   \n",
       "9980        0    ...            0         0         0         0         0   \n",
       "9981        0    ...            0         0         0         0        70   \n",
       "9982        0    ...            0         0         0         0         0   \n",
       "9983        0    ...            0         0         0         0         0   \n",
       "9984        0    ...            0         0         0         0         0   \n",
       "9985        0    ...           94        74         0         0         0   \n",
       "9986        0    ...            7         0         0         1         0   \n",
       "9987        0    ...           63        44         0         0        38   \n",
       "9988        0    ...            0         0         0         0         0   \n",
       "9989        0    ...            0         0         0         0         0   \n",
       "9990        0    ...            0         0         0         0         0   \n",
       "9991        0    ...            0         0         0         0         0   \n",
       "9992        0    ...          120         0         0         1         0   \n",
       "9993        0    ...            0         0         0         0         0   \n",
       "9994        2    ...           85        67       114        51         0   \n",
       "9995       37    ...           32        23        14        20         0   \n",
       "9996        0    ...            0         0         0         2        52   \n",
       "9997        0    ...          175       172       172       182       199   \n",
       "9998        0    ...            0         0         0         0         0   \n",
       "9999      103    ...          111        95        75        44         1   \n",
       "\n",
       "      pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0            0         0         0         0         0  \n",
       "1            0         0         0         0         0  \n",
       "2           53        31         0         0         0  \n",
       "3          224       222        56         0         0  \n",
       "4            0         0         0         0         0  \n",
       "5            0         0         0         0         0  \n",
       "6            0         0         0         0         0  \n",
       "7            1         0         0         0         0  \n",
       "8            0         0         0         0         0  \n",
       "9            0         0         0         0         0  \n",
       "10           0         0         0         0         0  \n",
       "11          71         0         0         0         0  \n",
       "12         123         0         0         0         0  \n",
       "13           0         0         0         0         0  \n",
       "14           0         0         0         0         0  \n",
       "15           0         0         0         0         0  \n",
       "16          78         0         0         0         0  \n",
       "17           0         0         0         0         0  \n",
       "18           1         0         0         0         0  \n",
       "19          50       107        18         0         0  \n",
       "20           0         0         0         0         0  \n",
       "21           0         0         0         0         0  \n",
       "22          92         0         0         0         0  \n",
       "23           0         0         0         0         0  \n",
       "24           0         0         0         0         0  \n",
       "25           0         0         0         0         0  \n",
       "26           0         0         0         0         0  \n",
       "27           1         4         1         0         0  \n",
       "28           0         0         0         0         0  \n",
       "29           0         0         0         0         0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "9970         0         0         0         0         0  \n",
       "9971         0         0         0         0         0  \n",
       "9972         1         0         0         0         0  \n",
       "9973         0         0         0         0         0  \n",
       "9974         0         0         0         0         0  \n",
       "9975         1         0         0         0         0  \n",
       "9976        87        50         0         0         0  \n",
       "9977         0         0         0         0         0  \n",
       "9978         0         0         0         0         0  \n",
       "9979         0         1        34         0         0  \n",
       "9980         0         0         0         0         0  \n",
       "9981        89        30         0         0         0  \n",
       "9982         0         0         0         0         0  \n",
       "9983         0         0         0         0         0  \n",
       "9984         0         0         0         0         0  \n",
       "9985         0         0         0         0         0  \n",
       "9986         1         1         0         1         0  \n",
       "9987        38        44         0         0         0  \n",
       "9988         0         0         0         0         0  \n",
       "9989         0         0         0         0         0  \n",
       "9990         0         0         0         0         0  \n",
       "9991         0         0         0         0         0  \n",
       "9992         0         0         0         0         0  \n",
       "9993         0         0         0         0         0  \n",
       "9994         1         0         0         0         0  \n",
       "9995         0         1         0         0         0  \n",
       "9996        23        28         0         0         0  \n",
       "9997       222        42         0         1         0  \n",
       "9998         1         0         0         0         0  \n",
       "9999         0         0         0         0         0  \n",
       "\n",
       "[10000 rows x 784 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oo_UFzMxWszP"
   },
   "source": [
    "Самый первый столбец -- **label**. Подробнее:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZTfJ0dBWszP"
   },
   "source": [
    "каждая картинка иметт класс от 0 до 9, расшифровка меток класса:  \n",
    "\n",
    "|class_id|class_name|\n",
    "|----|----|\n",
    "|0| T-shirt/top|\n",
    "|1| Trouser|\n",
    "|2| Pullover|\n",
    "|3| Dress|\n",
    "|4| Coat|\n",
    "|5| Sandal|\n",
    "|6| Shirt|\n",
    "|7| Sneaker|\n",
    "|8| Bag|\n",
    "|9| Ankle boot| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZO80od3WszQ",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,\n",
       "         0,   0,   0,   0,  62,  61,  21,  29,  23,  51, 136,  61,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  88, 201, 228, 225, 255, 115,  62, 137, 255, 235,\n",
       "       222, 255, 135,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  47, 252, 234, 238, 224, 215, 215, 229, 108, 180,\n",
       "       207, 214, 224, 231, 249, 254,  45,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   1,   0,   0, 214, 222, 210, 213, 224, 225, 217, 220,\n",
       "       254, 233, 219, 221, 217, 223, 221, 240, 254,   0,   0,   1,   0,\n",
       "         0,   0,   1,   0,   0,   0, 128, 237, 207, 224, 224, 207, 216,\n",
       "       214, 210, 208, 211, 221, 208, 219, 213, 226, 211, 237, 150,   0,\n",
       "         0,   0,   0,   0,   0,   2,   0,   0, 237, 222, 215, 207, 210,\n",
       "       212, 213, 206, 214, 213, 214, 213, 210, 215, 214, 206, 199, 218,\n",
       "       255,  13,   0,   2,   0,   0,   0,   4,   0,  85, 228, 210, 218,\n",
       "       200, 211, 208, 203, 215, 210, 209, 209, 210, 213, 211, 210, 217,\n",
       "       206, 213, 231, 175,   0,   0,   0,   0,   0,   0,   0, 217, 224,\n",
       "       215, 206, 205, 204, 217, 230, 222, 215, 224, 233, 228, 232, 228,\n",
       "       224, 207, 212, 215, 213, 229,  31,   0,   4,   0,   1,   0,  21,\n",
       "       225, 212, 212, 203, 211, 225, 193, 139, 136, 195, 147, 156, 139,\n",
       "       128, 162, 197, 223, 207, 220, 213, 232, 177,   0,   0,   0,   0,\n",
       "         0, 123, 226, 207, 211, 209, 205, 228, 158,  90, 103, 186, 138,\n",
       "       100, 121, 147, 158, 183, 226, 208, 214, 209, 216, 255,  13,   0,\n",
       "         1,   0,   0, 226, 219, 202, 208, 206, 205, 216, 184, 156, 150,\n",
       "       193, 170, 164, 168, 188, 186, 200, 219, 216, 213, 213, 211, 233,\n",
       "       148,   0,   0,   0,  45, 227, 204, 214, 211, 218, 222, 221, 230,\n",
       "       229, 221, 213, 224, 233, 226, 220, 219, 221, 224, 223, 217, 210,\n",
       "       218, 213, 254,   0,   0,   0, 157, 226, 203, 207, 211, 209, 215,\n",
       "       205, 198, 207, 208, 201, 201, 197, 203, 205, 210, 207, 213, 214,\n",
       "       214, 214, 213, 208, 234, 107,   0,   0, 235, 213, 204, 211, 210,\n",
       "       209, 213, 202, 197, 204, 215, 217, 213, 212, 210, 206, 212, 203,\n",
       "       211, 218, 215, 214, 208, 209, 222, 230,   0,  52, 255, 207, 200,\n",
       "       208, 213, 210, 210, 208, 207, 202, 201, 209, 216, 216, 216, 216,\n",
       "       214, 212, 205, 215, 201, 228, 208, 214, 212, 218,  25, 118, 217,\n",
       "       201, 206, 208, 213, 208, 205, 206, 210, 211, 202, 199, 207, 208,\n",
       "       209, 210, 207, 210, 210, 245, 139, 119, 255, 202, 203, 236, 114,\n",
       "       171, 238, 212, 203, 220, 216, 217, 209, 207, 205, 210, 211, 206,\n",
       "       204, 206, 209, 211, 215, 210, 206, 221, 242,   0, 224, 234, 230,\n",
       "       181,  26,  39, 145, 201, 255, 157, 115, 250, 200, 207, 206, 207,\n",
       "       213, 216, 206, 205, 206, 207, 206, 215, 207, 221, 238,   0,   0,\n",
       "       188,  85,   0,   0,   0,   0,   0,  31,   0, 129, 253, 190, 207,\n",
       "       208, 208, 208, 209, 211, 211, 209, 209, 209, 212, 201, 226, 165,\n",
       "         0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,  89, 254,\n",
       "       199, 199, 192, 196, 198, 199, 201, 202, 203, 204, 203, 203, 200,\n",
       "       222, 155,   0,   3,   3,   3,   2,   0,   0,   0,   1,   5,   0,\n",
       "         0, 255, 218, 226, 232, 228, 224, 222, 220, 219, 219, 217, 221,\n",
       "       220, 212, 236,  95,   0,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 155, 194, 168, 170, 171, 173, 173, 179, 177, 175,\n",
       "       172, 171, 167, 161, 180,   0,   0,   1,   0,   1,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dCQGTjhWszU"
   },
   "source": [
    "Видно, что это картинка типа Pullover (класс 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awB4icMDWszV"
   },
   "source": [
    "**Примечание:** у тестового датасета нужно удалить столбец label (по понятным причинам) -- вам нужно будет его предсказать и отправить эти предсказания в Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQ0iZM3bWszW"
   },
   "source": [
    "Итак, мы имеем 60000 картинок, у каждой известна метка класса (то есть что это за одежда).  \n",
    "Отделим `X` (признаковое описание объектов) и `y` (метки классов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUlpe0TAWszX"
   },
   "outputs": [],
   "source": [
    "X_train = train_df.values[:, 1:]\n",
    "y_train = train_df.values[:, 0]\n",
    "\n",
    "X_test = test_df.values  # [:, 1:]  # удаляем столбец 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqxoKKa1Wsza"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmptC_VuWszh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NwsDadrzWszm"
   },
   "source": [
    "Но почему пиксели так странно представлены? На самом деле 784 пикселя -- это 28 * 28, то есть это \"развёрнутая в строку\" чёрно-белая картинка 28 на 28 пикселей.\n",
    "\n",
    "Давайте убедимся в этом, отрисовав несколько (можете менять индекс и смотрть на отрисовку):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgpklY5nWszm"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28, 28), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-A_kmVUcWszq"
   },
   "source": [
    "Не слишком похоже на пулловер, правда? :)  \n",
    "    \n",
    "Просто если мы будем использовать изображения большего разрешения, нам понадобятся бОльшие вычислительные мощности, поэтому пока что будем довольствоваться такими размерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYJeXSOBWszr"
   },
   "source": [
    "Отлично, мы убедились в том, что имеем 60k картинок с метками для обучения, картинки \"развёрнуты\" в строку. Зачем разворачивать в строку? Потому что каждый пиксель в данном случае -- это один признак, то есть всего 784 признака, и уже их мы будем взвешивать нашей нейросетью, то есть у одного нейрона на входном слое будет 784 веса (+ Bias,  то есть 785 весов), на каждый пиксель по весу, и дальше уже будут второй слой, третий слой и так далее.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nOG2bGFWszs"
   },
   "source": [
    "Время тренировать нейросети!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doaFoyiVWszt"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Нейросеть на PyTorch</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_DjMGZPWszt"
   },
   "source": [
    "Надеемся, что вы уже прорешали семинар, там довольно подробно всё описано. На всякий случай ещё раз напомним, из чего состоит процесс обучения нейросети:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WndYRg6RWszt"
   },
   "source": [
    "- непосредственно, сама **архитектура** нейросети (сюда входят, например, типы функций активации у каждого нейрона);\n",
    "- начальная **инициализация** весов каждого слоя;\n",
    "- метод **оптимизации** нейросети (сюда ещё входит метод изменения `learning_rate`);\n",
    "- размер **батчей** (`batch_size`);\n",
    "- количество **итераций обучения** (`num_epochs`);\n",
    "- **функция потерь** (`loss`);  \n",
    "- тип **регуляризации** нейросети (для каждого слоя можно свой);  \n",
    "\n",
    "То, что связано с ***данными и задачей***:  \n",
    "- само **качество** выборки (непротиворечивость, чистота, корректность постановки задачи);  \n",
    "- **размер** выборки;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXUuW65eWszu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7tQA0FmWszx"
   },
   "source": [
    "Проверим версию PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxQ3R877Wszy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSMvZJ8LWsz0"
   },
   "source": [
    "Сначала обернём данные в тензоры пайторча (может занять некоторое время):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMrbvXGsWsz1"
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train.astype(np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAz0SbvOWsz3"
   },
   "source": [
    "Проверим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOHGbpjuWsz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784]) torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.shape, y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEowe826Wsz5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 7, 8, 5, 4, 3, 0, 6, 9, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbNCGnqlWsz_"
   },
   "source": [
    "На лекции обсуждалось, что нельзя просто запихнуть в LogLoss (основная функция потерь для задачи классификации, [как мы помним](https://drive.google.com/open?id=15wdyreZufKDxNQ55v4cl4Em2rtj7Q45B)) метки классов, предлагаем вам самим ещё раз подумать, почему. На всякий случай -- [ноутбук с более подробной информацией о функциях потерь](https://drive.google.com/open?id=1j6WpzeJQV1kS1Os4VJ0Avf68OkXVBo6W)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJwJHEz0Wsz_"
   },
   "source": [
    "Так вот, нам надо преобразовать метки классов из целых чисел в OneHot-кодированные метки (если вам не знакомо это слово, [посмотрите первую половину этого видео](https://www.youtube.com/watch?v=ufkDhrngcr0)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4js9UxVWsz_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 9, 6,  ..., 8, 8, 7])\n",
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "length = y_train_tensor.shape[0]\n",
    "num_classes = 10  # количество классов, в нашем случае 10 типов одежды\n",
    "\n",
    "# закодированные OneHot-ом метки классов\n",
    "y_onehot = torch.FloatTensor(length, num_classes)\n",
    "\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, y_train_tensor.view(-1, 1), 1)\n",
    "\n",
    "print(y_train_tensor)\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUn1EpyOWs0C"
   },
   "source": [
    "Видим, что наши метки перешли в вид \"единица там, где номер класса, а остальные нули\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OoBBEr8aWs0D"
   },
   "source": [
    "Напишем код, очень похожий на код с семинара: возьмём два слоя -- входной и один скрытый (выходной обычно не считают, но он тоже есть):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTueWl8oWs0E"
   },
   "outputs": [],
   "source": [
    "# N - размер батча (batch_size, нужно для метода оптимизации)\n",
    "# D_in - размерность входа (количество признаков у объекта)\n",
    "# H - размерность скрытых слоёв; \n",
    "# D_out - размерность выходного слоя (суть - количество классов)\n",
    "D_in, H, D_out = 784, 100, 10\n",
    "\n",
    "# определим нейросеть:\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIuTPDNGWs0G"
   },
   "source": [
    "Обратите внимание:  \n",
    "\n",
    "`D_in` -- это входная размерность (784 признака -- пикселя)  \n",
    "`D_out` -- выходная размерность (10 классов -- типов одежды), то есть 10 нейронов на выходном слое  \n",
    "`H` -- количество нейронов в скрытом слое  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_T6liPECWs0I"
   },
   "source": [
    "Осталось выбрать Loss (функцию потерь) и метод оптимизации, с помощью которого мы будем считать градиенты и обновлять с помощью них обновлять веса.  \n",
    "\n",
    "Loss мы выберем CrossEntropy, то есть кросс-энтропию, этот лосс почти всегда используется в задаче многоклассовой классификации (см. лекцию и ноутбук [loss_functions.ipynb](https://drive.google.com/open?id=1j6WpzeJQV1kS1Os4VJ0Avf68OkXVBo6W), там всё подробно объясняется), а метод оптимизации выберем обычный SGD (Stochastic Gradient Descent, стохастический градиентный спуск, см. лекцию про нейрон)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiofNi-sWs0J"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mu_8ipPsWs0K"
   },
   "source": [
    "Однако перед тем, как перейти к коду обучения нейросети, есть одна тонкость -- **батчи**, а точнее **мини-батчи**.\n",
    "\n",
    "**Мини-батчи** -- это небольшие (обычно размера 16, 32 или 64) \"куски\" выборки, то есть мини-батч размера 64 -- это 64 объекта из датасета. Обычно мини-батч называют просто батч (batch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkO8_LxBWs0L"
   },
   "source": [
    "Так вот: методы оптимиазции по типу стохастического градиентного спуска часто считаются не под одному объекту (в этом случае оптимизация будет очень нестабильная, \"шумная\"), а по нескольким -- по батчу. То есть в обычном градиентном спуске будет сумма по всей выборке, в стохастическом (чистом варианте) -- по одному объекту, а \"между ними\" -- мини-батч SGD, то есть подсчёт градиентов на небольшом кусочке данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z05JLquFWs0M"
   },
   "source": [
    "Одна **итерация (iteration)** алгоритма оптимизации -- это проход по одному батчу.\n",
    "Одна **эпоха (epoch)** алгоритма оптимизации -- это проход по всей выборке. \n",
    "\n",
    "То есть, например, если выборка размера 60000, а батч размера 64, то одна эпоха занимает 60000 / 64 = 937,5 = 938 итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4H3goUV8Ws0N"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yl1_YBn7Ws0N"
   },
   "source": [
    "Напишем функцию, генерирующую батчи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLq3bipeWs0O"
   },
   "outputs": [],
   "source": [
    "def generate_batches(X, y, batch_size=64):\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        X_batch, y_batch = X[i:i+batch_size], y[i:i+batch_size]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rliJVrCQWs0R"
   },
   "source": [
    "Код обучения нейросети (обязателньо убедитесь, что понимаете, что делает каждая строчка -- это необходимо для ваших дальнейших экспериментов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3djxdFiWs0S",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 100] current loss: 4.83777855682373\n",
      "[0, 200] current loss: 4.8591286544799805\n",
      "[0, 300] current loss: 4.859483921051026\n",
      "[0, 400] current loss: 4.8505137901306155\n",
      "[0, 500] current loss: 4.8577303771972655\n",
      "[0, 600] current loss: 4.85462056350708\n",
      "[0, 700] current loss: 4.871253910064698\n",
      "[0, 800] current loss: 4.877690464019776\n",
      "[0, 900] current loss: 4.881663200378418\n",
      "[1, 100] current loss: 4.83437712097168\n",
      "[1, 200] current loss: 4.84690246963501\n",
      "[1, 300] current loss: 4.859758659362793\n",
      "[1, 400] current loss: 4.8543605041503906\n",
      "[1, 500] current loss: 4.864965843200683\n",
      "[1, 600] current loss: 4.852820892333984\n",
      "[1, 700] current loss: 4.870418182373047\n",
      "[1, 800] current loss: 4.866510341644287\n",
      "[1, 900] current loss: 4.861665073394775\n",
      "[2, 100] current loss: 4.836540897369384\n",
      "[2, 200] current loss: 4.849175312042236\n",
      "[2, 300] current loss: 4.874750492095948\n",
      "[2, 400] current loss: 4.85192021560669\n",
      "[2, 500] current loss: 4.853126182556152\n",
      "[2, 600] current loss: 4.8468264389038085\n",
      "[2, 700] current loss: 4.869833209991455\n",
      "[2, 800] current loss: 4.867254531860351\n",
      "[2, 900] current loss: 4.864958435058594\n",
      "[3, 100] current loss: 4.832234558105469\n",
      "[3, 200] current loss: 4.845916019439697\n",
      "[3, 300] current loss: 4.859120838165283\n",
      "[3, 400] current loss: 4.840495895385742\n",
      "[3, 500] current loss: 4.852265811920166\n",
      "[3, 600] current loss: 4.844736598968506\n",
      "[3, 700] current loss: 4.869422649383545\n",
      "[3, 800] current loss: 4.865351078033448\n",
      "[3, 900] current loss: 4.8608405418395995\n",
      "[4, 100] current loss: 4.828841430664062\n",
      "[4, 200] current loss: 4.84818501663208\n",
      "[4, 300] current loss: 4.862967025756836\n",
      "[4, 400] current loss: 4.850955989837646\n",
      "[4, 500] current loss: 4.85376441192627\n",
      "[4, 600] current loss: 4.852212261199951\n",
      "[4, 700] current loss: 4.864109210968017\n",
      "[4, 800] current loss: 4.863018634796142\n",
      "[4, 900] current loss: 4.854525142669678\n",
      "[5, 100] current loss: 4.830049583435058\n",
      "[5, 200] current loss: 4.85205216217041\n",
      "[5, 300] current loss: 4.8592169494628905\n",
      "[5, 400] current loss: 4.851448497772217\n",
      "[5, 500] current loss: 4.858034454345703\n",
      "[5, 600] current loss: 4.847701419830322\n",
      "[5, 700] current loss: 4.86718204498291\n",
      "[5, 800] current loss: 4.85249927520752\n",
      "[5, 900] current loss: 4.8533103485107425\n",
      "[6, 100] current loss: 4.832562179565429\n",
      "[6, 200] current loss: 4.860508396148681\n",
      "[6, 300] current loss: 4.868093189239502\n",
      "[6, 400] current loss: 4.848332122802734\n",
      "[6, 500] current loss: 4.867911781311035\n",
      "[6, 600] current loss: 4.85188687133789\n",
      "[6, 700] current loss: 4.8606498985290525\n",
      "[6, 800] current loss: 4.855833869934082\n",
      "[6, 900] current loss: 4.863973937988281\n",
      "[7, 100] current loss: 4.838330085754395\n",
      "[7, 200] current loss: 4.845384929656983\n",
      "[7, 300] current loss: 4.8583192596435545\n",
      "[7, 400] current loss: 4.837887752532959\n",
      "[7, 500] current loss: 4.8466409492492675\n",
      "[7, 600] current loss: 4.8550264892578125\n",
      "[7, 700] current loss: 4.8679094314575195\n",
      "[7, 800] current loss: 4.857760974884033\n",
      "[7, 900] current loss: 4.861137382507324\n",
      "[8, 100] current loss: 4.836661617279053\n",
      "[8, 200] current loss: 4.850468162536621\n",
      "[8, 300] current loss: 4.863834049224853\n",
      "[8, 400] current loss: 4.836501968383789\n",
      "[8, 500] current loss: 4.85653405380249\n",
      "[8, 600] current loss: 4.838996692657471\n",
      "[8, 700] current loss: 4.862601421356201\n",
      "[8, 800] current loss: 4.86394849395752\n",
      "[8, 900] current loss: 4.861301635742188\n",
      "[9, 100] current loss: 4.825668285369873\n",
      "[9, 200] current loss: 4.844826522827148\n",
      "[9, 300] current loss: 4.854980056762695\n",
      "[9, 400] current loss: 4.833157962799072\n",
      "[9, 500] current loss: 4.859693244934082\n",
      "[9, 600] current loss: 4.834647529602051\n",
      "[9, 700] current loss: 4.862905021667481\n",
      "[9, 800] current loss: 4.859650848388672\n",
      "[9, 900] current loss: 4.868884262084961\n",
      "[10, 100] current loss: 4.827965553283692\n",
      "[10, 200] current loss: 4.844555171966553\n",
      "[10, 300] current loss: 4.85721187210083\n",
      "[10, 400] current loss: 4.834523387908936\n",
      "[10, 500] current loss: 4.855110534667968\n",
      "[10, 600] current loss: 4.845961730957031\n",
      "[10, 700] current loss: 4.860062309265137\n",
      "[10, 800] current loss: 4.873597545623779\n",
      "[10, 900] current loss: 4.85888703918457\n",
      "[11, 100] current loss: 4.8374167137146\n",
      "[11, 200] current loss: 4.859385505676269\n",
      "[11, 300] current loss: 4.86068892288208\n",
      "[11, 400] current loss: 4.834648601531982\n",
      "[11, 500] current loss: 4.854550693511963\n",
      "[11, 600] current loss: 4.8421223335266115\n",
      "[11, 700] current loss: 4.850728439331054\n",
      "[11, 800] current loss: 4.869630046844483\n",
      "[11, 900] current loss: 4.846561866760254\n",
      "[12, 100] current loss: 4.82038533782959\n",
      "[12, 200] current loss: 4.845802711486816\n",
      "[12, 300] current loss: 4.849019332885742\n",
      "[12, 400] current loss: 4.84721810913086\n",
      "[12, 500] current loss: 4.844232761383057\n",
      "[12, 600] current loss: 4.841576103210449\n",
      "[12, 700] current loss: 4.862969722747803\n",
      "[12, 800] current loss: 4.8579264183044435\n",
      "[12, 900] current loss: 4.8549886970520015\n",
      "[13, 100] current loss: 4.826114238739014\n",
      "[13, 200] current loss: 4.845258197784424\n",
      "[13, 300] current loss: 4.857364364624024\n",
      "[13, 400] current loss: 4.850596340179443\n",
      "[13, 500] current loss: 4.851128429412841\n",
      "[13, 600] current loss: 4.838598731994629\n",
      "[13, 700] current loss: 4.859508499145508\n",
      "[13, 800] current loss: 4.858563934326172\n",
      "[13, 900] current loss: 4.85078341293335\n",
      "[14, 100] current loss: 4.834706260681152\n",
      "[14, 200] current loss: 4.843978515625\n",
      "[14, 300] current loss: 4.854769218444824\n",
      "[14, 400] current loss: 4.841554363250732\n",
      "[14, 500] current loss: 4.8565880432128905\n",
      "[14, 600] current loss: 4.837846473693848\n",
      "[14, 700] current loss: 4.874700950622558\n",
      "[14, 800] current loss: 4.86246125793457\n",
      "[14, 900] current loss: 4.8494387702941895\n",
      "[15, 100] current loss: 4.823294715881348\n",
      "[15, 200] current loss: 4.839535160064697\n",
      "[15, 300] current loss: 4.857545166015625\n",
      "[15, 400] current loss: 4.835987236022949\n",
      "[15, 500] current loss: 4.860236797332764\n",
      "[15, 600] current loss: 4.841243774414062\n",
      "[15, 700] current loss: 4.8589366264343266\n",
      "[15, 800] current loss: 4.857761505126953\n",
      "[15, 900] current loss: 4.847899532318115\n",
      "[16, 100] current loss: 4.817114471435547\n",
      "[16, 200] current loss: 4.847584190368653\n",
      "[16, 300] current loss: 4.857028564453125\n",
      "[16, 400] current loss: 4.8471604881286625\n",
      "[16, 500] current loss: 4.845259567260742\n",
      "[16, 600] current loss: 4.847619693756103\n",
      "[16, 700] current loss: 4.861507846832275\n",
      "[16, 800] current loss: 4.8558466987609865\n",
      "[16, 900] current loss: 4.848177047729492\n",
      "[17, 100] current loss: 4.8293697471618655\n",
      "[17, 200] current loss: 4.846015171051025\n",
      "[17, 300] current loss: 4.8453065910339355\n",
      "[17, 400] current loss: 4.841267734527588\n",
      "[17, 500] current loss: 4.844803268432617\n",
      "[17, 600] current loss: 4.83770980834961\n",
      "[17, 700] current loss: 4.851845180511474\n",
      "[17, 800] current loss: 4.856058486938476\n",
      "[17, 900] current loss: 4.8590961265563966\n",
      "[18, 100] current loss: 4.815533767700195\n",
      "[18, 200] current loss: 4.843720371246338\n",
      "[18, 300] current loss: 4.857586166381836\n",
      "[18, 400] current loss: 4.827140129089355\n",
      "[18, 500] current loss: 4.8429273376464845\n",
      "[18, 600] current loss: 4.834265445709229\n",
      "[18, 700] current loss: 4.861731483459472\n",
      "[18, 800] current loss: 4.858295440673828\n",
      "[18, 900] current loss: 4.847769023895264\n",
      "[19, 100] current loss: 4.82556819152832\n",
      "[19, 200] current loss: 4.8460832862854\n",
      "[19, 300] current loss: 4.846274623870849\n",
      "[19, 400] current loss: 4.82507341003418\n",
      "[19, 500] current loss: 4.848508632659912\n",
      "[19, 600] current loss: 4.832316596984863\n",
      "[19, 700] current loss: 4.861013996124267\n",
      "[19, 800] current loss: 4.85025333404541\n",
      "[19, 900] current loss: 4.846266525268555\n",
      "[20, 100] current loss: 4.814206859588623\n",
      "[20, 200] current loss: 4.850486736297608\n",
      "[20, 300] current loss: 4.85351774597168\n",
      "[20, 400] current loss: 4.845062278747559\n",
      "[20, 500] current loss: 4.850400154113769\n",
      "[20, 600] current loss: 4.841824375152588\n",
      "[20, 700] current loss: 4.85283332824707\n",
      "[20, 800] current loss: 4.8524549789428715\n",
      "[20, 900] current loss: 4.849110473632813\n",
      "[21, 100] current loss: 4.812424125671387\n",
      "[21, 200] current loss: 4.829699588775635\n",
      "[21, 300] current loss: 4.859414531707763\n",
      "[21, 400] current loss: 4.826991371154785\n",
      "[21, 500] current loss: 4.8437694091796875\n",
      "[21, 600] current loss: 4.83380945968628\n",
      "[21, 700] current loss: 4.852898731231689\n",
      "[21, 800] current loss: 4.849413009643555\n",
      "[21, 900] current loss: 4.847087593078613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 100] current loss: 4.826147087097168\n",
      "[22, 200] current loss: 4.843009479522705\n",
      "[22, 300] current loss: 4.845191291809082\n",
      "[22, 400] current loss: 4.833236206054687\n",
      "[22, 500] current loss: 4.842474178314209\n",
      "[22, 600] current loss: 4.842234394073486\n",
      "[22, 700] current loss: 4.844154479980468\n",
      "[22, 800] current loss: 4.854459030151367\n",
      "[22, 900] current loss: 4.8405192260742185\n",
      "[23, 100] current loss: 4.8232759132385254\n",
      "[23, 200] current loss: 4.834588897705078\n",
      "[23, 300] current loss: 4.841828475952148\n",
      "[23, 400] current loss: 4.832803649902344\n",
      "[23, 500] current loss: 4.834067497253418\n",
      "[23, 600] current loss: 4.828721004486084\n",
      "[23, 700] current loss: 4.852428630828857\n",
      "[23, 800] current loss: 4.853787246704101\n",
      "[23, 900] current loss: 4.849641441345215\n",
      "[24, 100] current loss: 4.820181991577148\n",
      "[24, 200] current loss: 4.842169376373291\n",
      "[24, 300] current loss: 4.8461056976318355\n",
      "[24, 400] current loss: 4.840874782562256\n",
      "[24, 500] current loss: 4.84579220199585\n",
      "[24, 600] current loss: 4.831642265319824\n",
      "[24, 700] current loss: 4.847859588623047\n",
      "[24, 800] current loss: 4.843630302429199\n",
      "[24, 900] current loss: 4.854023864746094\n",
      "[25, 100] current loss: 4.82624280166626\n",
      "[25, 200] current loss: 4.849622299194336\n",
      "[25, 300] current loss: 4.851481727600097\n",
      "[25, 400] current loss: 4.831548095703125\n",
      "[25, 500] current loss: 4.839742763519287\n",
      "[25, 600] current loss: 4.83102258682251\n",
      "[25, 700] current loss: 4.846191146850586\n",
      "[25, 800] current loss: 4.844331462860107\n",
      "[25, 900] current loss: 4.836893623352051\n",
      "[26, 100] current loss: 4.812933784484863\n",
      "[26, 200] current loss: 4.838585514068604\n",
      "[26, 300] current loss: 4.85199520111084\n",
      "[26, 400] current loss: 4.829087448120117\n",
      "[26, 500] current loss: 4.842052444458008\n",
      "[26, 600] current loss: 4.834711845397949\n",
      "[26, 700] current loss: 4.853949760437012\n",
      "[26, 800] current loss: 4.845079181671142\n",
      "[26, 900] current loss: 4.84384878540039\n",
      "[27, 100] current loss: 4.811837772369385\n",
      "[27, 200] current loss: 4.828607112884521\n",
      "[27, 300] current loss: 4.838550331115723\n",
      "[27, 400] current loss: 4.82854899597168\n",
      "[27, 500] current loss: 4.8344320335388185\n",
      "[27, 600] current loss: 4.822792938232422\n",
      "[27, 700] current loss: 4.843035312652588\n",
      "[27, 800] current loss: 4.848044696807861\n",
      "[27, 900] current loss: 4.84201579284668\n",
      "[28, 100] current loss: 4.830245674133301\n",
      "[28, 200] current loss: 4.837528007507324\n",
      "[28, 300] current loss: 4.840153102874756\n",
      "[28, 400] current loss: 4.821592102050781\n",
      "[28, 500] current loss: 4.832158950805664\n",
      "[28, 600] current loss: 4.8256835327148435\n",
      "[28, 700] current loss: 4.842330261230469\n",
      "[28, 800] current loss: 4.848230182647705\n",
      "[28, 900] current loss: 4.835832912445069\n",
      "[29, 100] current loss: 4.815681880950928\n",
      "[29, 200] current loss: 4.834102416992187\n",
      "[29, 300] current loss: 4.835325538635254\n",
      "[29, 400] current loss: 4.82185391998291\n",
      "[29, 500] current loss: 4.836972175598144\n",
      "[29, 600] current loss: 4.827700508117676\n",
      "[29, 700] current loss: 4.843691730499268\n",
      "[29, 800] current loss: 4.838394123077393\n",
      "[29, 900] current loss: 4.83301053237915\n",
      "[30, 100] current loss: 4.818780998229981\n",
      "[30, 200] current loss: 4.831428653717041\n",
      "[30, 300] current loss: 4.832232334136963\n",
      "[30, 400] current loss: 4.824500015258789\n",
      "[30, 500] current loss: 4.83515149307251\n",
      "[30, 600] current loss: 4.8197657546997075\n",
      "[30, 700] current loss: 4.838114391326904\n",
      "[30, 800] current loss: 4.840723533630371\n",
      "[30, 900] current loss: 4.834683048248291\n",
      "[31, 100] current loss: 4.815627773284912\n",
      "[31, 200] current loss: 4.833735767364502\n",
      "[31, 300] current loss: 4.83659236907959\n",
      "[31, 400] current loss: 4.821784545898438\n",
      "[31, 500] current loss: 4.8314887733459475\n",
      "[31, 600] current loss: 4.826252780914307\n",
      "[31, 700] current loss: 4.840288249969483\n",
      "[31, 800] current loss: 4.848210956573486\n",
      "[31, 900] current loss: 4.84216060256958\n",
      "[32, 100] current loss: 4.817656352996826\n",
      "[32, 200] current loss: 4.833347434997559\n",
      "[32, 300] current loss: 4.829080047607422\n",
      "[32, 400] current loss: 4.8210967254638675\n",
      "[32, 500] current loss: 4.834973346710205\n",
      "[32, 600] current loss: 4.81662654876709\n",
      "[32, 700] current loss: 4.8356493301391605\n",
      "[32, 800] current loss: 4.842662071228028\n",
      "[32, 900] current loss: 4.838069469451904\n",
      "[33, 100] current loss: 4.813564880371094\n",
      "[33, 200] current loss: 4.824100727081299\n",
      "[33, 300] current loss: 4.836483837127686\n",
      "[33, 400] current loss: 4.820809162139892\n",
      "[33, 500] current loss: 4.8340748596191405\n",
      "[33, 600] current loss: 4.81807723236084\n",
      "[33, 700] current loss: 4.839428779602051\n",
      "[33, 800] current loss: 4.846292953491211\n",
      "[33, 900] current loss: 4.832476287841797\n",
      "[34, 100] current loss: 4.812916213989258\n",
      "[34, 200] current loss: 4.822704048156738\n",
      "[34, 300] current loss: 4.835938056945801\n",
      "[34, 400] current loss: 4.829525634765625\n",
      "[34, 500] current loss: 4.8339643478393555\n",
      "[34, 600] current loss: 4.821908130645752\n",
      "[34, 700] current loss: 4.838464641571045\n",
      "[34, 800] current loss: 4.8336121940612795\n",
      "[34, 900] current loss: 4.834455177307129\n",
      "[35, 100] current loss: 4.8140848426818845\n",
      "[35, 200] current loss: 4.8252541465759275\n",
      "[35, 300] current loss: 4.829089721679687\n",
      "[35, 400] current loss: 4.826527431488037\n",
      "[35, 500] current loss: 4.8325676879882815\n",
      "[35, 600] current loss: 4.820240425109863\n",
      "[35, 700] current loss: 4.848257446289063\n",
      "[35, 800] current loss: 4.84542123413086\n",
      "[35, 900] current loss: 4.846025852203369\n",
      "[36, 100] current loss: 4.8144933700561525\n",
      "[36, 200] current loss: 4.828329414367675\n",
      "[36, 300] current loss: 4.845577091217041\n",
      "[36, 400] current loss: 4.823557739257812\n",
      "[36, 500] current loss: 4.825821647644043\n",
      "[36, 600] current loss: 4.815730316162109\n",
      "[36, 700] current loss: 4.840189891815186\n",
      "[36, 800] current loss: 4.848316188812256\n",
      "[36, 900] current loss: 4.834302680969238\n",
      "[37, 100] current loss: 4.805704883575439\n",
      "[37, 200] current loss: 4.8325512428283695\n",
      "[37, 300] current loss: 4.830199962615967\n",
      "[37, 400] current loss: 4.822218357086181\n",
      "[37, 500] current loss: 4.843367542266845\n",
      "[37, 600] current loss: 4.817238525390625\n",
      "[37, 700] current loss: 4.836729579925537\n",
      "[37, 800] current loss: 4.836544200897217\n",
      "[37, 900] current loss: 4.836142227172852\n",
      "[38, 100] current loss: 4.815637878417968\n",
      "[38, 200] current loss: 4.825704109191895\n",
      "[38, 300] current loss: 4.843167827606202\n",
      "[38, 400] current loss: 4.818870136260986\n",
      "[38, 500] current loss: 4.826958190917969\n",
      "[38, 600] current loss: 4.811311225891114\n",
      "[38, 700] current loss: 4.835094802856445\n",
      "[38, 800] current loss: 4.836482315063477\n",
      "[38, 900] current loss: 4.829252716064453\n",
      "[39, 100] current loss: 4.8059346389770505\n",
      "[39, 200] current loss: 4.8215140571594235\n",
      "[39, 300] current loss: 4.825076396942139\n",
      "[39, 400] current loss: 4.813751083374023\n",
      "[39, 500] current loss: 4.849412311553955\n",
      "[39, 600] current loss: 4.82406099319458\n",
      "[39, 700] current loss: 4.841135993957519\n",
      "[39, 800] current loss: 4.834432418823242\n",
      "[39, 900] current loss: 4.842900882720947\n",
      "[40, 100] current loss: 4.801967830657959\n",
      "[40, 200] current loss: 4.818029476165772\n",
      "[40, 300] current loss: 4.846040050506592\n",
      "[40, 400] current loss: 4.818971633911133\n",
      "[40, 500] current loss: 4.837236083984375\n",
      "[40, 600] current loss: 4.811820789337158\n",
      "[40, 700] current loss: 4.834571060180664\n",
      "[40, 800] current loss: 4.83306330871582\n",
      "[40, 900] current loss: 4.834919834136963\n",
      "[41, 100] current loss: 4.806445602416992\n",
      "[41, 200] current loss: 4.823991268157959\n",
      "[41, 300] current loss: 4.833537792205811\n",
      "[41, 400] current loss: 4.821886310577392\n",
      "[41, 500] current loss: 4.833554649353028\n",
      "[41, 600] current loss: 4.825272247314453\n",
      "[41, 700] current loss: 4.836157402038574\n",
      "[41, 800] current loss: 4.840120323181153\n",
      "[41, 900] current loss: 4.828489479064942\n",
      "[42, 100] current loss: 4.80425724029541\n",
      "[42, 200] current loss: 4.82074522781372\n",
      "[42, 300] current loss: 4.839524421691895\n",
      "[42, 400] current loss: 4.82208056640625\n",
      "[42, 500] current loss: 4.832990005493164\n",
      "[42, 600] current loss: 4.813716575622559\n",
      "[42, 700] current loss: 4.831661922454834\n",
      "[42, 800] current loss: 4.841776931762696\n",
      "[42, 900] current loss: 4.828138473510742\n",
      "[43, 100] current loss: 4.800805030822754\n",
      "[43, 200] current loss: 4.813216011047364\n",
      "[43, 300] current loss: 4.8323809509277345\n",
      "[43, 400] current loss: 4.814986469268799\n",
      "[43, 500] current loss: 4.821567825317382\n",
      "[43, 600] current loss: 4.812719356536865\n",
      "[43, 700] current loss: 4.84513911819458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 800] current loss: 4.843005939483643\n",
      "[43, 900] current loss: 4.833013439178467\n",
      "[44, 100] current loss: 4.804469276428223\n",
      "[44, 200] current loss: 4.8231523208618166\n",
      "[44, 300] current loss: 4.828381065368652\n",
      "[44, 400] current loss: 4.825420516967774\n",
      "[44, 500] current loss: 4.826751747131348\n",
      "[44, 600] current loss: 4.810167964935303\n",
      "[44, 700] current loss: 4.834876140594482\n",
      "[44, 800] current loss: 4.843764781951904\n",
      "[44, 900] current loss: 4.825470726013184\n",
      "[45, 100] current loss: 4.810955661773682\n",
      "[45, 200] current loss: 4.818933528900146\n",
      "[45, 300] current loss: 4.8289536743164065\n",
      "[45, 400] current loss: 4.819922725677491\n",
      "[45, 500] current loss: 4.829363525390625\n",
      "[45, 600] current loss: 4.806673038482666\n",
      "[45, 700] current loss: 4.828805099487305\n",
      "[45, 800] current loss: 4.838305721282959\n",
      "[45, 900] current loss: 4.835608798980713\n",
      "[46, 100] current loss: 4.806937099456787\n",
      "[46, 200] current loss: 4.81869344329834\n",
      "[46, 300] current loss: 4.832421588897705\n",
      "[46, 400] current loss: 4.823931316375733\n",
      "[46, 500] current loss: 4.834918659210205\n",
      "[46, 600] current loss: 4.8220974006652835\n",
      "[46, 700] current loss: 4.844694244384765\n",
      "[46, 800] current loss: 4.832148265838623\n",
      "[46, 900] current loss: 4.82551307296753\n",
      "[47, 100] current loss: 4.806704776763916\n",
      "[47, 200] current loss: 4.818820549011231\n",
      "[47, 300] current loss: 4.8220122604370115\n",
      "[47, 400] current loss: 4.812553581237793\n",
      "[47, 500] current loss: 4.8195023994445805\n",
      "[47, 600] current loss: 4.809661037445069\n",
      "[47, 700] current loss: 4.832345298767089\n",
      "[47, 800] current loss: 4.831043239593506\n",
      "[47, 900] current loss: 4.828231170654297\n",
      "[48, 100] current loss: 4.801831878662109\n",
      "[48, 200] current loss: 4.823047779083252\n",
      "[48, 300] current loss: 4.838904201507568\n",
      "[48, 400] current loss: 4.819374961853027\n",
      "[48, 500] current loss: 4.825314418792725\n",
      "[48, 600] current loss: 4.809168148040771\n",
      "[48, 700] current loss: 4.839714141845703\n",
      "[48, 800] current loss: 4.829317554473877\n",
      "[48, 900] current loss: 4.834291881561279\n",
      "[49, 100] current loss: 4.810951263427734\n",
      "[49, 200] current loss: 4.817253131866455\n",
      "[49, 300] current loss: 4.829491024017334\n",
      "[49, 400] current loss: 4.812731014251709\n",
      "[49, 500] current loss: 4.825418872833252\n",
      "[49, 600] current loss: 4.807142948150635\n",
      "[49, 700] current loss: 4.8394440574646\n",
      "[49, 800] current loss: 4.827940727233886\n",
      "[49, 900] current loss: 4.822255672454834\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch_num  in range(NUM_EPOCHS):\n",
    "    iter_num = 0\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        # forward (подсчёт ответа с текущими весами)\n",
    "        y_pred = net(X_batch)\n",
    "\n",
    "        # вычисляем loss'ы\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # выводем качество каждые 2000 батчей\n",
    "            \n",
    "        if iter_num % 100 == 99:\n",
    "            print('[{}, {}] current loss: {}'.format(epoch_num, iter_num + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        # зануляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward (подсчёт новых градиентов)\n",
    "        loss.backward()\n",
    "\n",
    "        # обновляем веса\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYT3dV9AWs0V"
   },
   "source": [
    "Отлично, мы получили обученную нейросеть. Давайте измерим качество на обучающей выбоорке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AupOUbQqWs0W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        y_pred = net(X_batch)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        c = (predicted == y_batch).squeeze()\n",
    "        for i in range(len(y_pred)):\n",
    "            label = y_batch[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qszxr3LgWs0b"
   },
   "source": [
    "Уже сейчас видно, что сеть далеко не идеально -- она предсказывает только 7 классов, а про некоторые просто \"забывает\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA1qrDVDWs0c"
   },
   "source": [
    "Теперь предскажем на тестовой и сохраним предсказания в файл. Это ни что иное, как baseline, который вам надо побить, чтобы получить хоть какие-то ненулевые баллы за это ДЗ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1don3P3oWs0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 592 ms, sys: 64 ms, total: 656 ms\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = net(torch.FloatTensor(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WYEWB3OWs0g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYP_4ba3Ws0j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9981e-01, 4.9694e-29, 1.7823e-25, 1.1789e-24, 2.6459e-33, 1.7560e-24,\n",
       "         1.9320e-04, 1.0090e-25, 1.7856e-25, 2.7866e-36],\n",
       "        [9.7803e-34, 1.0000e+00, 7.1976e-30, 1.1064e-23, 1.1519e-22, 1.2413e-33,\n",
       "         2.4033e-37, 7.8268e-30, 1.5618e-35, 2.6366e-31],\n",
       "        [3.5939e-08, 3.5411e-12, 1.0000e+00, 1.1159e-14, 1.0292e-12, 2.9635e-11,\n",
       "         7.9403e-10, 2.9067e-11, 8.1536e-15, 7.4345e-15],\n",
       "        [1.0000e+00, 8.0494e-29, 5.3273e-12, 6.2650e-24, 0.0000e+00, 5.7920e-21,\n",
       "         3.9258e-23, 1.0628e-33, 1.0424e-32, 3.6255e-27],\n",
       "        [3.8365e-21, 1.2023e-18, 5.8993e-04, 3.6316e-01, 6.3625e-01, 2.0695e-14,\n",
       "         7.2647e-11, 3.5397e-12, 1.5806e-19, 8.1672e-23]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3j5-QJtDWs0m"
   },
   "source": [
    "Преобразуем OneHot'ы в числовые метки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1MoGXmHWs0m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2,  ..., 8, 8, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predicted = torch.max(y_test_pred, 1)\n",
    "\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdyMyDvHWs0p"
   },
   "source": [
    "Сохраним в датафрейм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7mnGBF3Ws0p",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category\n",
       "0         0\n",
       "1         1\n",
       "2         2\n",
       "3         0\n",
       "4         4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df = pd.DataFrame(data=predicted.numpy(), columns=['Category'])\n",
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzXh9H1qWs0r"
   },
   "outputs": [],
   "source": [
    "answer_df['Id'] = answer_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3DKzZCKWs0u"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  Id\n",
       "0         0   0\n",
       "1         1   1\n",
       "2         2   2\n",
       "3         0   3\n",
       "4         4   4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBl_9g9dWs0w",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>6</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8</td>\n",
       "      <td>9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>8</td>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>4</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category    Id\n",
       "9995         0  9995\n",
       "9996         6  9996\n",
       "9997         8  9997\n",
       "9998         8  9998\n",
       "9999         4  9999"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kf7IiHBRWs0y"
   },
   "source": [
    "Отлично, созраним в файл и отправим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJqw8f32Ws0z"
   },
   "outputs": [],
   "source": [
    "answer_df.to_csv('./baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98zRsGfFWs02"
   },
   "source": [
    "В точности этот файл и есть **baseline.csv**, который вы видите на лидерборде и который вам нужно побить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkDjjoj2Ws04"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Задание</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpDM9WANWs04"
   },
   "source": [
    "Добейтесь как можно лучшего качества в соревновании!  \n",
    "\n",
    "Используйте знания, полученные на занятиях и те, которые вы найдёте в интернете. Если у вас получится, можете использовать и свёрточные нейросети, а не только полносвязные. Вам нужно как минимум побить baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pC5T2TFTWs05"
   },
   "source": [
    "*Рекомендация*: попробуйте поменять количество итераций, количество нейронов, количество слоёв, гиперпараметры сети (learning_rate, метод оптимизации вместо SGD можно взять другой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ev5LShUSWs06"
   },
   "outputs": [],
   "source": [
    "def create_submission(y_test_pred, num):\n",
    "    _, predicted = torch.max(y_test_pred, 1)\n",
    "    answer_df = pd.DataFrame(data=predicted.numpy(), columns=['Category'])\n",
    "    answer_df['Id'] = answer_df.index\n",
    "    answer_df.to_csv('./baseline' + str(num) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 layers 300 neurons each 64-size batch 50 epochs lr 1e-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULT: 0.89000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8W0HbJjWs0-"
   },
   "outputs": [],
   "source": [
    "# N - размер батча (batch_size, нужно для метода оптимизации)\n",
    "# D_in - размерность входа (количество признаков у объекта)\n",
    "# H - размерность скрытых слоёв; \n",
    "# D_out - размерность выходного слоя (суть - количество классов)\n",
    "D_in, H, D_out = 784, 300, 10\n",
    "\n",
    "# определим нейросеть:\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 100] current loss: 6.190324394226074\n",
      "[0, 200] current loss: 5.906044361114502\n",
      "[0, 300] current loss: 5.869128673553467\n",
      "[0, 400] current loss: 5.860502891540527\n",
      "[0, 500] current loss: 5.86519548034668\n",
      "[0, 600] current loss: 5.858341640472412\n",
      "[0, 700] current loss: 5.818626537322998\n",
      "[0, 800] current loss: 5.815522445678711\n",
      "[0, 900] current loss: 5.825626419067383\n",
      "[1, 100] current loss: 5.788535926818848\n",
      "[1, 200] current loss: 5.806752349853515\n",
      "[1, 300] current loss: 5.788576858520508\n",
      "[1, 400] current loss: 5.7952818794250485\n",
      "[1, 500] current loss: 5.810810569763183\n",
      "[1, 600] current loss: 5.827996868133545\n",
      "[1, 700] current loss: 5.789656177520752\n",
      "[1, 800] current loss: 5.773353759765625\n",
      "[1, 900] current loss: 5.7888254623413085\n",
      "[2, 100] current loss: 5.7581144714355466\n",
      "[2, 200] current loss: 5.781654628753662\n",
      "[2, 300] current loss: 5.7705365180969235\n",
      "[2, 400] current loss: 5.772638008117676\n",
      "[2, 500] current loss: 5.789854839324951\n",
      "[2, 600] current loss: 5.809413333892822\n",
      "[2, 700] current loss: 5.766209953308105\n",
      "[2, 800] current loss: 5.754581920623779\n",
      "[2, 900] current loss: 5.771367023468017\n",
      "[3, 100] current loss: 5.740876731872558\n",
      "[3, 200] current loss: 5.647726577758789\n",
      "[3, 300] current loss: 5.489455978393555\n",
      "[3, 400] current loss: 5.483983291625977\n",
      "[3, 500] current loss: 5.487393836975098\n",
      "[3, 600] current loss: 5.514142120361329\n",
      "[3, 700] current loss: 5.468626049041748\n",
      "[3, 800] current loss: 5.460309799194336\n",
      "[3, 900] current loss: 5.483110496520996\n",
      "[4, 100] current loss: 5.464064399719239\n",
      "[4, 200] current loss: 5.459047477722168\n",
      "[4, 300] current loss: 5.4624432258605955\n",
      "[4, 400] current loss: 5.455348804473877\n",
      "[4, 500] current loss: 5.463054424285889\n",
      "[4, 600] current loss: 5.491193943023681\n",
      "[4, 700] current loss: 5.4478852043151855\n",
      "[4, 800] current loss: 5.4440691223144535\n",
      "[4, 900] current loss: 5.466628875732422\n",
      "[5, 100] current loss: 5.448065967559814\n",
      "[5, 200] current loss: 5.440268581390381\n",
      "[5, 300] current loss: 5.445820968627929\n",
      "[5, 400] current loss: 5.4439552268981934\n",
      "[5, 500] current loss: 5.452645351409912\n",
      "[5, 600] current loss: 5.4816282196044925\n",
      "[5, 700] current loss: 5.436203216552735\n",
      "[5, 800] current loss: 5.433518001556396\n",
      "[5, 900] current loss: 5.45584041595459\n",
      "[6, 100] current loss: 5.431460556030274\n",
      "[6, 200] current loss: 5.433816242218017\n",
      "[6, 300] current loss: 5.432481399536133\n",
      "[6, 400] current loss: 5.428248851776123\n",
      "[6, 500] current loss: 5.444206996917725\n",
      "[6, 600] current loss: 5.47198189163208\n",
      "[6, 700] current loss: 5.4280235443115235\n",
      "[6, 800] current loss: 5.424555744171142\n",
      "[6, 900] current loss: 5.445500862121582\n",
      "[7, 100] current loss: 5.4287991676330565\n",
      "[7, 200] current loss: 5.422306529998779\n",
      "[7, 300] current loss: 5.425800941467285\n",
      "[7, 400] current loss: 5.418191413879395\n",
      "[7, 500] current loss: 5.443402851104737\n",
      "[7, 600] current loss: 5.462335559844971\n",
      "[7, 700] current loss: 5.421643135070801\n",
      "[7, 800] current loss: 5.417607837677002\n",
      "[7, 900] current loss: 5.444302391052246\n",
      "[8, 100] current loss: 5.421479751586914\n",
      "[8, 200] current loss: 5.415824840545654\n",
      "[8, 300] current loss: 5.4196422615051265\n",
      "[8, 400] current loss: 5.4167521362304685\n",
      "[8, 500] current loss: 5.430794364929199\n",
      "[8, 600] current loss: 5.462266193389892\n",
      "[8, 700] current loss: 5.413043754577637\n",
      "[8, 800] current loss: 5.41671397781372\n",
      "[8, 900] current loss: 5.433558837890625\n",
      "[9, 100] current loss: 5.417431781768799\n",
      "[9, 200] current loss: 5.41469002532959\n",
      "[9, 300] current loss: 5.410084655761719\n",
      "[9, 400] current loss: 5.41222749710083\n",
      "[9, 500] current loss: 5.431728912353516\n",
      "[9, 600] current loss: 5.459411529541016\n",
      "[9, 700] current loss: 5.408971508026123\n",
      "[9, 800] current loss: 5.414045658111572\n",
      "[9, 900] current loss: 5.432442516326904\n",
      "[10, 100] current loss: 5.411058650970459\n",
      "[10, 200] current loss: 5.413820579528808\n",
      "[10, 300] current loss: 5.407527423858642\n",
      "[10, 400] current loss: 5.409198074340821\n",
      "[10, 500] current loss: 5.426420070648193\n",
      "[10, 600] current loss: 5.452555644989014\n",
      "[10, 700] current loss: 5.409077171325683\n",
      "[10, 800] current loss: 5.4066063575744625\n",
      "[10, 900] current loss: 5.425866798400879\n",
      "[11, 100] current loss: 5.408278636932373\n",
      "[11, 200] current loss: 5.404655391693115\n",
      "[11, 300] current loss: 5.411347236633301\n",
      "[11, 400] current loss: 5.404273380279541\n",
      "[11, 500] current loss: 5.424804859161377\n",
      "[11, 600] current loss: 5.4484205856323245\n",
      "[11, 700] current loss: 5.40351929473877\n",
      "[11, 800] current loss: 5.405119926452636\n",
      "[11, 900] current loss: 5.419014228820801\n",
      "[12, 100] current loss: 5.404248863220215\n",
      "[12, 200] current loss: 5.399638889312744\n",
      "[12, 300] current loss: 5.403687553405762\n",
      "[12, 400] current loss: 5.3988776206970215\n",
      "[12, 500] current loss: 5.421774421691895\n",
      "[12, 600] current loss: 5.4441909561157225\n",
      "[12, 700] current loss: 5.3965186042785644\n",
      "[12, 800] current loss: 5.401297389984131\n",
      "[12, 900] current loss: 5.417212669372558\n",
      "[13, 100] current loss: 5.399029865264892\n",
      "[13, 200] current loss: 5.39766089630127\n",
      "[13, 300] current loss: 5.399792953491211\n",
      "[13, 400] current loss: 5.400656723022461\n",
      "[13, 500] current loss: 5.415605529785156\n",
      "[13, 600] current loss: 5.4392405738830565\n",
      "[13, 700] current loss: 5.393524894714355\n",
      "[13, 800] current loss: 5.40132470703125\n",
      "[13, 900] current loss: 5.415129558563232\n",
      "[14, 100] current loss: 5.398211463928223\n",
      "[14, 200] current loss: 5.400161518096924\n",
      "[14, 300] current loss: 5.39823452758789\n",
      "[14, 400] current loss: 5.4003958282470705\n",
      "[14, 500] current loss: 5.412311222076416\n",
      "[14, 600] current loss: 5.4356065979003905\n",
      "[14, 700] current loss: 5.395863040924072\n",
      "[14, 800] current loss: 5.396341930389404\n",
      "[14, 900] current loss: 5.411842704772949\n",
      "[15, 100] current loss: 5.394318416595459\n",
      "[15, 200] current loss: 5.393408828735351\n",
      "[15, 300] current loss: 5.39684672164917\n",
      "[15, 400] current loss: 5.397923709869385\n",
      "[15, 500] current loss: 5.413166618347168\n",
      "[15, 600] current loss: 5.434926898956299\n",
      "[15, 700] current loss: 5.390333889007568\n",
      "[15, 800] current loss: 5.39373307800293\n",
      "[15, 900] current loss: 5.40917635345459\n",
      "[16, 100] current loss: 5.390448757171631\n",
      "[16, 200] current loss: 5.386338241577149\n",
      "[16, 300] current loss: 5.39112699508667\n",
      "[16, 400] current loss: 5.392536827087403\n",
      "[16, 500] current loss: 5.4089283332824705\n",
      "[16, 600] current loss: 5.433692363739014\n",
      "[16, 700] current loss: 5.385137821197509\n",
      "[16, 800] current loss: 5.391307518005371\n",
      "[16, 900] current loss: 5.4050480728149415\n",
      "[17, 100] current loss: 5.390278305053711\n",
      "[17, 200] current loss: 5.384040718078613\n",
      "[17, 300] current loss: 5.386547916412353\n",
      "[17, 400] current loss: 5.3900178489685056\n",
      "[17, 500] current loss: 5.4062196769714355\n",
      "[17, 600] current loss: 5.432136726379395\n",
      "[17, 700] current loss: 5.383687854766846\n",
      "[17, 800] current loss: 5.391215209960937\n",
      "[17, 900] current loss: 5.400833354949951\n",
      "[18, 100] current loss: 5.395271213531494\n",
      "[18, 200] current loss: 5.3859208374023435\n",
      "[18, 300] current loss: 5.387501541137695\n",
      "[18, 400] current loss: 5.392140209197998\n",
      "[18, 500] current loss: 5.401184223175049\n",
      "[18, 600] current loss: 5.427053550720215\n",
      "[18, 700] current loss: 5.380764389038086\n",
      "[18, 800] current loss: 5.3884634552001955\n",
      "[18, 900] current loss: 5.399343391418457\n",
      "[19, 100] current loss: 5.388870258331298\n",
      "[19, 200] current loss: 5.38164867401123\n",
      "[19, 300] current loss: 5.385642395019532\n",
      "[19, 400] current loss: 5.387097946166993\n",
      "[19, 500] current loss: 5.398491790771485\n",
      "[19, 600] current loss: 5.4281301574707035\n",
      "[19, 700] current loss: 5.383358688354492\n",
      "[19, 800] current loss: 5.390402931213379\n",
      "[19, 900] current loss: 5.399803100585937\n",
      "[20, 100] current loss: 5.384991878509521\n",
      "[20, 200] current loss: 5.383306854248047\n",
      "[20, 300] current loss: 5.382761501312256\n",
      "[20, 400] current loss: 5.382126369476318\n",
      "[20, 500] current loss: 5.392025779724121\n",
      "[20, 600] current loss: 5.424686676025391\n",
      "[20, 700] current loss: 5.378867073059082\n",
      "[20, 800] current loss: 5.38503267288208\n",
      "[20, 900] current loss: 5.396001628875732\n",
      "[21, 100] current loss: 5.381897434234619\n",
      "[21, 200] current loss: 5.3780589714050295\n",
      "[21, 300] current loss: 5.378965732574463\n",
      "[21, 400] current loss: 5.3794715766906736\n",
      "[21, 500] current loss: 5.393444313049317\n",
      "[21, 600] current loss: 5.42206226348877\n",
      "[21, 700] current loss: 5.375907131195069\n",
      "[21, 800] current loss: 5.384241928100586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 900] current loss: 5.398677703857422\n",
      "[22, 100] current loss: 5.31367993927002\n",
      "[22, 200] current loss: 5.241243949890137\n",
      "[22, 300] current loss: 5.212556758880615\n",
      "[22, 400] current loss: 5.225608005523681\n",
      "[22, 500] current loss: 5.2227692260742185\n",
      "[22, 600] current loss: 5.224827972412109\n",
      "[22, 700] current loss: 5.205695026397705\n",
      "[22, 800] current loss: 5.19575082397461\n",
      "[22, 900] current loss: 5.211776504516601\n",
      "[23, 100] current loss: 5.194010112762451\n",
      "[23, 200] current loss: 5.188278587341308\n",
      "[23, 300] current loss: 5.1833496742248535\n",
      "[23, 400] current loss: 5.204162715911865\n",
      "[23, 500] current loss: 5.195622714996338\n",
      "[23, 600] current loss: 5.2038350105285645\n",
      "[23, 700] current loss: 5.181006244659423\n",
      "[23, 800] current loss: 5.19100887298584\n",
      "[23, 900] current loss: 5.204219226837158\n",
      "[24, 100] current loss: 5.185978790283203\n",
      "[24, 200] current loss: 5.1771474342346195\n",
      "[24, 300] current loss: 5.173421676635742\n",
      "[24, 400] current loss: 5.179296993255615\n",
      "[24, 500] current loss: 5.190136589050293\n",
      "[24, 600] current loss: 5.19156616973877\n",
      "[24, 700] current loss: 5.179011428833008\n",
      "[24, 800] current loss: 5.164543907165528\n",
      "[24, 900] current loss: 5.19405260848999\n",
      "[25, 100] current loss: 5.17480428314209\n",
      "[25, 200] current loss: 5.17566943359375\n",
      "[25, 300] current loss: 5.1695793418884275\n",
      "[25, 400] current loss: 5.180921009063721\n",
      "[25, 500] current loss: 5.186949165344238\n",
      "[25, 600] current loss: 5.186589126586914\n",
      "[25, 700] current loss: 5.15917463684082\n",
      "[25, 800] current loss: 5.159204753875732\n",
      "[25, 900] current loss: 5.190624980926514\n",
      "[26, 100] current loss: 5.165767597198486\n",
      "[26, 200] current loss: 5.165216499328613\n",
      "[26, 300] current loss: 5.162762382507324\n",
      "[26, 400] current loss: 5.168606521606446\n",
      "[26, 500] current loss: 5.169549140930176\n",
      "[26, 600] current loss: 5.1780526657104495\n",
      "[26, 700] current loss: 5.157982364654541\n",
      "[26, 800] current loss: 5.156190891265869\n",
      "[26, 900] current loss: 5.183536926269531\n",
      "[27, 100] current loss: 5.165819484710694\n",
      "[27, 200] current loss: 5.172474365234375\n",
      "[27, 300] current loss: 5.1534959449768065\n",
      "[27, 400] current loss: 5.165872989654541\n",
      "[27, 500] current loss: 5.162700298309326\n",
      "[27, 600] current loss: 5.173873718261719\n",
      "[27, 700] current loss: 5.155280441284179\n",
      "[27, 800] current loss: 5.149564559936524\n",
      "[27, 900] current loss: 5.176180694580078\n",
      "[28, 100] current loss: 5.159368480682373\n",
      "[28, 200] current loss: 5.161146785736084\n",
      "[28, 300] current loss: 5.149333198547363\n",
      "[28, 400] current loss: 5.165341270446778\n",
      "[28, 500] current loss: 5.167515277862549\n",
      "[28, 600] current loss: 5.170862442016602\n",
      "[28, 700] current loss: 5.144973091125488\n",
      "[28, 800] current loss: 5.141161640167236\n",
      "[28, 900] current loss: 5.175849411010742\n",
      "[29, 100] current loss: 5.158716930389405\n",
      "[29, 200] current loss: 5.15419372177124\n",
      "[29, 300] current loss: 5.141788177490234\n",
      "[29, 400] current loss: 5.163283622741699\n",
      "[29, 500] current loss: 5.1569176826477054\n",
      "[29, 600] current loss: 5.163571952819824\n",
      "[29, 700] current loss: 5.146328739166259\n",
      "[29, 800] current loss: 5.138812168121338\n",
      "[29, 900] current loss: 5.165217788696289\n",
      "[30, 100] current loss: 5.1453997459411625\n",
      "[30, 200] current loss: 5.155619552612305\n",
      "[30, 300] current loss: 5.143425937652588\n",
      "[30, 400] current loss: 5.157572811126709\n",
      "[30, 500] current loss: 5.155496570587158\n",
      "[30, 600] current loss: 5.157941993713379\n",
      "[30, 700] current loss: 5.137469013214111\n",
      "[30, 800] current loss: 5.1331064338684085\n",
      "[30, 900] current loss: 5.169038524627686\n",
      "[31, 100] current loss: 5.144574970245361\n",
      "[31, 200] current loss: 5.152369556427002\n",
      "[31, 300] current loss: 5.14415355682373\n",
      "[31, 400] current loss: 5.161815231323242\n",
      "[31, 500] current loss: 5.16640376663208\n",
      "[31, 600] current loss: 5.149553760528565\n",
      "[31, 700] current loss: 5.137326793670654\n",
      "[31, 800] current loss: 5.134005550384521\n",
      "[31, 900] current loss: 5.163733303070068\n",
      "[32, 100] current loss: 5.142843360900879\n",
      "[32, 200] current loss: 5.152199104309082\n",
      "[32, 300] current loss: 5.141859592437744\n",
      "[32, 400] current loss: 5.151341789245605\n",
      "[32, 500] current loss: 5.156896842956543\n",
      "[32, 600] current loss: 5.153807209014893\n",
      "[32, 700] current loss: 5.132142574310302\n",
      "[32, 800] current loss: 5.133991519927979\n",
      "[32, 900] current loss: 5.1618002243042\n",
      "[33, 100] current loss: 5.134376579284668\n",
      "[33, 200] current loss: 5.147677501678467\n",
      "[33, 300] current loss: 5.138466018676758\n",
      "[33, 400] current loss: 5.14726736831665\n",
      "[33, 500] current loss: 5.152388912200927\n",
      "[33, 600] current loss: 5.15255281829834\n",
      "[33, 700] current loss: 5.132019901275635\n",
      "[33, 800] current loss: 5.1249529571533206\n",
      "[33, 900] current loss: 5.1650097427368165\n",
      "[34, 100] current loss: 5.133839416503906\n",
      "[34, 200] current loss: 5.140087615966797\n",
      "[34, 300] current loss: 5.134046646118164\n",
      "[34, 400] current loss: 5.1541180992126465\n",
      "[34, 500] current loss: 5.147044486999512\n",
      "[34, 600] current loss: 5.153764492034912\n",
      "[34, 700] current loss: 5.133403900146484\n",
      "[34, 800] current loss: 5.123699462890625\n",
      "[34, 900] current loss: 5.154762042999268\n",
      "[35, 100] current loss: 5.126682193756103\n",
      "[35, 200] current loss: 5.145012325286865\n",
      "[35, 300] current loss: 5.129370697021485\n",
      "[35, 400] current loss: 5.141410778045654\n",
      "[35, 500] current loss: 5.140776165008545\n",
      "[35, 600] current loss: 5.147062255859375\n",
      "[35, 700] current loss: 5.125617912292481\n",
      "[35, 800] current loss: 5.120699314117432\n",
      "[35, 900] current loss: 5.15753186416626\n",
      "[36, 100] current loss: 5.129416046142578\n",
      "[36, 200] current loss: 5.1424587478637696\n",
      "[36, 300] current loss: 5.125840824127197\n",
      "[36, 400] current loss: 5.13870100402832\n",
      "[36, 500] current loss: 5.146618927001954\n",
      "[36, 600] current loss: 5.14526746749878\n",
      "[36, 700] current loss: 5.1268355102539065\n",
      "[36, 800] current loss: 5.122437026977539\n",
      "[36, 900] current loss: 5.146688652038574\n",
      "[37, 100] current loss: 5.1276189193725585\n",
      "[37, 200] current loss: 5.130779750823975\n",
      "[37, 300] current loss: 5.127120952606202\n",
      "[37, 400] current loss: 5.142248336791992\n",
      "[37, 500] current loss: 5.138957702636719\n",
      "[37, 600] current loss: 5.143407611846924\n",
      "[37, 700] current loss: 5.127293155670166\n",
      "[37, 800] current loss: 5.1216088371276856\n",
      "[37, 900] current loss: 5.147956897735596\n",
      "[38, 100] current loss: 5.122987297058105\n",
      "[38, 200] current loss: 5.134351398468017\n",
      "[38, 300] current loss: 5.128225811004639\n",
      "[38, 400] current loss: 5.139488033294677\n",
      "[38, 500] current loss: 5.138808799743653\n",
      "[38, 600] current loss: 5.139664054870606\n",
      "[38, 700] current loss: 5.12795552444458\n",
      "[38, 800] current loss: 5.114696029663086\n",
      "[38, 900] current loss: 5.1497348670959475\n",
      "[39, 100] current loss: 5.121190818786621\n",
      "[39, 200] current loss: 5.127107051849365\n",
      "[39, 300] current loss: 5.119363780975342\n",
      "[39, 400] current loss: 5.138125286102295\n",
      "[39, 500] current loss: 5.1296770401000975\n",
      "[39, 600] current loss: 5.1373219985961915\n",
      "[39, 700] current loss: 5.113953819274903\n",
      "[39, 800] current loss: 5.112789924621582\n",
      "[39, 900] current loss: 5.1497447967529295\n",
      "[40, 100] current loss: 5.117223663330078\n",
      "[40, 200] current loss: 5.129143985748291\n",
      "[40, 300] current loss: 5.118736972808838\n",
      "[40, 400] current loss: 5.1329515876770015\n",
      "[40, 500] current loss: 5.1375498046875\n",
      "[40, 600] current loss: 5.131696170806885\n",
      "[40, 700] current loss: 5.113667091369629\n",
      "[40, 800] current loss: 5.111381233215332\n",
      "[40, 900] current loss: 5.144476821899414\n",
      "[41, 100] current loss: 5.1184283561706545\n",
      "[41, 200] current loss: 5.124775440216064\n",
      "[41, 300] current loss: 5.117518112182617\n",
      "[41, 400] current loss: 5.134373188018799\n",
      "[41, 500] current loss: 5.130102790832519\n",
      "[41, 600] current loss: 5.129667453765869\n",
      "[41, 700] current loss: 5.113441082000732\n",
      "[41, 800] current loss: 5.105641143798828\n",
      "[41, 900] current loss: 5.1430794067382815\n",
      "[42, 100] current loss: 5.119767780303955\n",
      "[42, 200] current loss: 5.1202888031005855\n",
      "[42, 300] current loss: 5.121385475158691\n",
      "[42, 400] current loss: 5.1310958023071285\n",
      "[42, 500] current loss: 5.130195762634277\n",
      "[42, 600] current loss: 5.137257865905761\n",
      "[42, 700] current loss: 5.113987823486328\n",
      "[42, 800] current loss: 5.1097814598083495\n",
      "[42, 900] current loss: 5.1382367858886715\n",
      "[43, 100] current loss: 5.115893051147461\n",
      "[43, 200] current loss: 5.12749328994751\n",
      "[43, 300] current loss: 5.110667694091797\n",
      "[43, 400] current loss: 5.128131259918213\n",
      "[43, 500] current loss: 5.128199813842773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 600] current loss: 5.122774208068848\n",
      "[43, 700] current loss: 5.111224601745605\n",
      "[43, 800] current loss: 5.112190647125244\n",
      "[43, 900] current loss: 5.138252880096435\n",
      "[44, 100] current loss: 5.108429443359375\n",
      "[44, 200] current loss: 5.1207417984008785\n",
      "[44, 300] current loss: 5.110500392913818\n",
      "[44, 400] current loss: 5.123739490509033\n",
      "[44, 500] current loss: 5.126409122467041\n",
      "[44, 600] current loss: 5.122114086151123\n",
      "[44, 700] current loss: 5.113995426177978\n",
      "[44, 800] current loss: 5.103451713562012\n",
      "[44, 900] current loss: 5.133968444824219\n",
      "[45, 100] current loss: 5.1149954452514645\n",
      "[45, 200] current loss: 5.112858856201172\n",
      "[45, 300] current loss: 5.106965522766114\n",
      "[45, 400] current loss: 5.1229067840576175\n",
      "[45, 500] current loss: 5.124750778198242\n",
      "[45, 600] current loss: 5.123790256500244\n",
      "[45, 700] current loss: 5.11139836883545\n",
      "[45, 800] current loss: 5.102549209594726\n",
      "[45, 900] current loss: 5.131286346435547\n",
      "[46, 100] current loss: 5.1121539115905765\n",
      "[46, 200] current loss: 5.115608654022217\n",
      "[46, 300] current loss: 5.109832969665527\n",
      "[46, 400] current loss: 5.129781673431396\n",
      "[46, 500] current loss: 5.126931156158447\n",
      "[46, 600] current loss: 5.119593830108642\n",
      "[46, 700] current loss: 5.107891689300537\n",
      "[46, 800] current loss: 5.1044953994750975\n",
      "[46, 900] current loss: 5.131649471282959\n",
      "[47, 100] current loss: 5.107385677337646\n",
      "[47, 200] current loss: 5.111226501464844\n",
      "[47, 300] current loss: 5.10425638961792\n",
      "[47, 400] current loss: 5.12563032913208\n",
      "[47, 500] current loss: 5.1233301239013675\n",
      "[47, 600] current loss: 5.122243984222412\n",
      "[47, 700] current loss: 5.11142293548584\n",
      "[47, 800] current loss: 5.098894207000733\n",
      "[47, 900] current loss: 5.132296932220459\n",
      "[48, 100] current loss: 5.112262962341308\n",
      "[48, 200] current loss: 5.115712520599366\n",
      "[48, 300] current loss: 5.10468111038208\n",
      "[48, 400] current loss: 5.115669677734375\n",
      "[48, 500] current loss: 5.1221327896118165\n",
      "[48, 600] current loss: 5.119629653930664\n",
      "[48, 700] current loss: 5.103462352752685\n",
      "[48, 800] current loss: 5.1014181404113765\n",
      "[48, 900] current loss: 5.134024181365967\n",
      "[49, 100] current loss: 5.1069128074645995\n",
      "[49, 200] current loss: 5.110258094787597\n",
      "[49, 300] current loss: 5.101527057647705\n",
      "[49, 400] current loss: 5.125269554138184\n",
      "[49, 500] current loss: 5.118773124694824\n",
      "[49, 600] current loss: 5.121653457641601\n",
      "[49, 700] current loss: 5.100420909881592\n",
      "[49, 800] current loss: 5.09739476776123\n",
      "[49, 900] current loss: 5.132623779296875\n",
      "CPU times: user 17min 1s, sys: 9.7 s, total: 17min 11s\n",
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch_num  in range(NUM_EPOCHS):\n",
    "    iter_num = 0\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        # forward (подсчёт ответа с текущими весами)\n",
    "        y_pred = net(X_batch)\n",
    "\n",
    "        # вычисляем loss'ы\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # выводем качество каждые 2000 батчей\n",
    "            \n",
    "        if iter_num % 100 == 99:\n",
    "            print('[{}, {}] current loss: {}'.format(epoch_num, iter_num + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        # зануляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward (подсчёт новых градиентов)\n",
    "        loss.backward()\n",
    "\n",
    "        # обновляем веса\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 97 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt :  0 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        y_pred = net(X_batch)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        c = (predicted == y_batch).squeeze()\n",
    "        for i in range(len(y_pred)):\n",
    "            label = y_batch[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 608 ms, sys: 36 ms, total: 644 ms\n",
      "Wall time: 406 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = net(torch.FloatTensor(X_test))\n",
    "create_submission(y_test_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 layers 300 neurons each 64-size batch 50 epochs lr 1e-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULT: 0.89000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8W0HbJjWs0-"
   },
   "outputs": [],
   "source": [
    "# N - размер батча (batch_size, нужно для метода оптимизации)\n",
    "# D_in - размерность входа (количество признаков у объекта)\n",
    "# H - размерность скрытых слоёв; \n",
    "# D_out - размерность выходного слоя (суть - количество классов)\n",
    "D_in, H, D_out = 784, 512, 10\n",
    "\n",
    "# определим нейросеть:\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, 26**2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(26**2, 24**2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(24**2, 10**2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10**2, 8**2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(8**2, D_out),\n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 100] current loss: 2.8319432392120363\n",
      "[0, 200] current loss: 2.822557628631592\n",
      "[0, 300] current loss: 2.8545734424591065\n",
      "[0, 400] current loss: 2.858660541534424\n",
      "[0, 500] current loss: 2.831114912033081\n",
      "[0, 600] current loss: 2.8231159057617186\n",
      "[0, 700] current loss: 2.8529037532806396\n",
      "[0, 800] current loss: 2.8439777545928955\n",
      "[0, 900] current loss: 2.84961346244812\n",
      "[0, 1000] current loss: 2.8341423778533934\n",
      "[0, 1100] current loss: 2.8263437595367433\n",
      "[0, 1200] current loss: 2.8571161670684813\n",
      "[0, 1300] current loss: 2.838843204498291\n",
      "[0, 1400] current loss: 2.8469231338500975\n",
      "[0, 1500] current loss: 2.8399339294433594\n",
      "[0, 1600] current loss: 2.8468408184051515\n",
      "[0, 1700] current loss: 2.8451241970062258\n",
      "[0, 1800] current loss: 2.8427805824279786\n",
      "[1, 100] current loss: 2.8316656761169434\n",
      "[1, 200] current loss: 2.8214077529907224\n",
      "[1, 300] current loss: 2.8532915687561036\n",
      "[1, 400] current loss: 2.8578501472473143\n",
      "[1, 500] current loss: 2.830705635070801\n",
      "[1, 600] current loss: 2.8223899211883543\n",
      "[1, 700] current loss: 2.8523965301513674\n",
      "[1, 800] current loss: 2.8434847278594972\n",
      "[1, 900] current loss: 2.8490519218444823\n",
      "[1, 1000] current loss: 2.8333311653137208\n",
      "[1, 1100] current loss: 2.825892454147339\n",
      "[1, 1200] current loss: 2.8568307723999022\n",
      "[1, 1300] current loss: 2.8385361461639405\n",
      "[1, 1400] current loss: 2.846780368804932\n",
      "[1, 1500] current loss: 2.8393452053070067\n",
      "[1, 1600] current loss: 2.8465174579620363\n",
      "[1, 1700] current loss: 2.8448276538848876\n",
      "[1, 1800] current loss: 2.8425392093658446\n",
      "[2, 100] current loss: 2.83132769203186\n",
      "[2, 200] current loss: 2.8207889881134034\n",
      "[2, 300] current loss: 2.8527211227416993\n",
      "[2, 400] current loss: 2.8571710090637206\n",
      "[2, 500] current loss: 2.8304213638305664\n",
      "[2, 600] current loss: 2.821948539733887\n",
      "[2, 700] current loss: 2.852067485809326\n",
      "[2, 800] current loss: 2.8431899948120116\n",
      "[2, 900] current loss: 2.8485896854400634\n",
      "[2, 1000] current loss: 2.832758647918701\n",
      "[2, 1100] current loss: 2.8255475959777834\n",
      "[2, 1200] current loss: 2.8565762729644777\n",
      "[2, 1300] current loss: 2.8382545394897463\n",
      "[2, 1400] current loss: 2.846585859298706\n",
      "[2, 1500] current loss: 2.8388444080352784\n",
      "[2, 1600] current loss: 2.8462397384643556\n",
      "[2, 1700] current loss: 2.844535064697266\n",
      "[2, 1800] current loss: 2.8423335247039794\n",
      "[3, 100] current loss: 2.830990369796753\n",
      "[3, 200] current loss: 2.820294853210449\n",
      "[3, 300] current loss: 2.8522807559967043\n",
      "[3, 400] current loss: 2.8565907745361327\n",
      "[3, 500] current loss: 2.8301477336883547\n",
      "[3, 600] current loss: 2.8215830307006837\n",
      "[3, 700] current loss: 2.8517595100402833\n",
      "[3, 800] current loss: 2.8429158687591554\n",
      "[3, 900] current loss: 2.848191358566284\n",
      "[3, 1000] current loss: 2.8322381763458253\n",
      "[3, 1100] current loss: 2.825228656768799\n",
      "[3, 1200] current loss: 2.856322816848755\n",
      "[3, 1300] current loss: 2.8379915294647216\n",
      "[3, 1400] current loss: 2.846341625213623\n",
      "[3, 1500] current loss: 2.838393653869629\n",
      "[3, 1600] current loss: 2.8459678287506103\n",
      "[3, 1700] current loss: 2.844248790740967\n",
      "[3, 1800] current loss: 2.8421247692108156\n",
      "[4, 100] current loss: 2.830683786392212\n",
      "[4, 200] current loss: 2.819855978012085\n",
      "[4, 300] current loss: 2.8519025840759276\n",
      "[4, 400] current loss: 2.8560378665924073\n",
      "[4, 500] current loss: 2.8298737564086913\n",
      "[4, 600] current loss: 2.8212549839019774\n",
      "[4, 700] current loss: 2.8514702854156493\n",
      "[4, 800] current loss: 2.842644021987915\n",
      "[4, 900] current loss: 2.8478323020935057\n",
      "[4, 1000] current loss: 2.8317524547576904\n",
      "[4, 1100] current loss: 2.8249316139221192\n",
      "[4, 1200] current loss: 2.8560498790740967\n",
      "[4, 1300] current loss: 2.837738079071045\n",
      "[4, 1400] current loss: 2.8460864238739014\n",
      "[4, 1500] current loss: 2.8379495010375977\n",
      "[4, 1600] current loss: 2.8456836490631106\n",
      "[4, 1700] current loss: 2.8439618816375734\n",
      "[4, 1800] current loss: 2.84190576171875\n",
      "[5, 100] current loss: 2.8303701877593994\n",
      "[5, 200] current loss: 2.819439371109009\n",
      "[5, 300] current loss: 2.851573526382446\n",
      "[5, 400] current loss: 2.8555268154144287\n",
      "[5, 500] current loss: 2.8296015396118164\n",
      "[5, 600] current loss: 2.8209585247039795\n",
      "[5, 700] current loss: 2.851184675216675\n",
      "[5, 800] current loss: 2.8423784217834474\n",
      "[5, 900] current loss: 2.84748313331604\n",
      "[5, 1000] current loss: 2.8312817516326905\n",
      "[5, 1100] current loss: 2.8246303234100343\n",
      "[5, 1200] current loss: 2.8557878131866454\n",
      "[5, 1300] current loss: 2.8374860668182373\n",
      "[5, 1400] current loss: 2.845814281463623\n",
      "[5, 1500] current loss: 2.8375194911956787\n",
      "[5, 1600] current loss: 2.845402862548828\n",
      "[5, 1700] current loss: 2.8436759967803953\n",
      "[5, 1800] current loss: 2.8416669254302978\n",
      "[6, 100] current loss: 2.830058977127075\n",
      "[6, 200] current loss: 2.819036502838135\n",
      "[6, 300] current loss: 2.8512503833770753\n",
      "[6, 400] current loss: 2.8550340423583984\n",
      "[6, 500] current loss: 2.8293294982910155\n",
      "[6, 600] current loss: 2.8206719818115236\n",
      "[6, 700] current loss: 2.850901346206665\n",
      "[6, 800] current loss: 2.842104820251465\n",
      "[6, 900] current loss: 2.8471643409729004\n",
      "[6, 1000] current loss: 2.8308346900939942\n",
      "[6, 1100] current loss: 2.8243315143585206\n",
      "[6, 1200] current loss: 2.855532985687256\n",
      "[6, 1300] current loss: 2.837233196258545\n",
      "[6, 1400] current loss: 2.8455279445648194\n",
      "[6, 1500] current loss: 2.837115556716919\n",
      "[6, 1600] current loss: 2.8451204986572267\n",
      "[6, 1700] current loss: 2.8433965682983398\n",
      "[6, 1800] current loss: 2.841440912246704\n",
      "[7, 100] current loss: 2.829775724411011\n",
      "[7, 200] current loss: 2.818650426864624\n",
      "[7, 300] current loss: 2.850940721511841\n",
      "[7, 400] current loss: 2.854554843902588\n",
      "[7, 500] current loss: 2.829067823410034\n",
      "[7, 600] current loss: 2.8203979682922364\n",
      "[7, 700] current loss: 2.8506104202270506\n",
      "[7, 800] current loss: 2.8418266887664796\n",
      "[7, 900] current loss: 2.8468632316589355\n",
      "[7, 1000] current loss: 2.830407718658447\n",
      "[7, 1100] current loss: 2.824035469055176\n",
      "[7, 1200] current loss: 2.855264310836792\n",
      "[7, 1300] current loss: 2.8369985580444337\n",
      "[7, 1400] current loss: 2.8452456340789793\n",
      "[7, 1500] current loss: 2.8367144470214845\n",
      "[7, 1600] current loss: 2.844832515716553\n",
      "[7, 1700] current loss: 2.843118751525879\n",
      "[7, 1800] current loss: 2.84121164894104\n",
      "[8, 100] current loss: 2.8295002536773683\n",
      "[8, 200] current loss: 2.818268688201904\n",
      "[8, 300] current loss: 2.8506613807678223\n",
      "[8, 400] current loss: 2.854108846664429\n",
      "[8, 500] current loss: 2.828818742752075\n",
      "[8, 600] current loss: 2.820130874633789\n",
      "[8, 700] current loss: 2.8503147106170656\n",
      "[8, 800] current loss: 2.8415500621795653\n",
      "[8, 900] current loss: 2.8465572452545165\n",
      "[8, 1000] current loss: 2.829998487472534\n",
      "[8, 1100] current loss: 2.823748374938965\n",
      "[8, 1200] current loss: 2.8550022315979002\n",
      "[8, 1300] current loss: 2.8367566680908203\n",
      "[8, 1400] current loss: 2.844952417373657\n",
      "[8, 1500] current loss: 2.8363006687164307\n",
      "[8, 1600] current loss: 2.8445527267456057\n",
      "[8, 1700] current loss: 2.8428373260498048\n",
      "[8, 1800] current loss: 2.8409921131134035\n",
      "[9, 100] current loss: 2.829233139038086\n",
      "[9, 200] current loss: 2.817901672363281\n",
      "[9, 300] current loss: 2.85039289855957\n",
      "[9, 400] current loss: 2.853667697906494\n",
      "[9, 500] current loss: 2.8285691566467284\n",
      "[9, 600] current loss: 2.819865201950073\n",
      "[9, 700] current loss: 2.85002809715271\n",
      "[9, 800] current loss: 2.8412682132720946\n",
      "[9, 900] current loss: 2.846262413024902\n",
      "[9, 1000] current loss: 2.829593032836914\n",
      "[9, 1100] current loss: 2.823457384109497\n",
      "[9, 1200] current loss: 2.854754144668579\n",
      "[9, 1300] current loss: 2.836518180847168\n",
      "[9, 1400] current loss: 2.8446610565185546\n",
      "[9, 1500] current loss: 2.8359013290405275\n",
      "[9, 1600] current loss: 2.8442763042449952\n",
      "[9, 1700] current loss: 2.8425538825988768\n",
      "[9, 1800] current loss: 2.8407751140594484\n",
      "[10, 100] current loss: 2.828970184326172\n",
      "[10, 200] current loss: 2.817529119491577\n",
      "[10, 300] current loss: 2.8501294174194336\n",
      "[10, 400] current loss: 2.8532414684295655\n",
      "[10, 500] current loss: 2.8283153648376467\n",
      "[10, 600] current loss: 2.819609802246094\n",
      "[10, 700] current loss: 2.849732551574707\n",
      "[10, 800] current loss: 2.840978065490723\n",
      "[10, 900] current loss: 2.8459561538696287\n",
      "[10, 1000] current loss: 2.8292047424316404\n",
      "[10, 1100] current loss: 2.823182445526123\n",
      "[10, 1200] current loss: 2.8545050449371336\n",
      "[10, 1300] current loss: 2.8362773818969726\n",
      "[10, 1400] current loss: 2.8443808536529542\n",
      "[10, 1500] current loss: 2.8355253028869627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 1600] current loss: 2.8440187549591065\n",
      "[10, 1700] current loss: 2.842259422302246\n",
      "[10, 1800] current loss: 2.8405447731018065\n",
      "[11, 100] current loss: 2.828701147079468\n",
      "[11, 200] current loss: 2.817165153503418\n",
      "[11, 300] current loss: 2.849862831115723\n",
      "[11, 400] current loss: 2.852832483291626\n",
      "[11, 500] current loss: 2.828066831588745\n",
      "[11, 600] current loss: 2.8193606243133544\n",
      "[11, 700] current loss: 2.849434144973755\n",
      "[11, 800] current loss: 2.840683620452881\n",
      "[11, 900] current loss: 2.845668888092041\n",
      "[11, 1000] current loss: 2.828828716278076\n",
      "[11, 1100] current loss: 2.82291339302063\n",
      "[11, 1200] current loss: 2.8542508354187013\n",
      "[11, 1300] current loss: 2.836033670425415\n",
      "[11, 1400] current loss: 2.8441034202575683\n",
      "[11, 1500] current loss: 2.835150001525879\n",
      "[11, 1600] current loss: 2.843764747619629\n",
      "[11, 1700] current loss: 2.8419667415618894\n",
      "[11, 1800] current loss: 2.8403109169006346\n",
      "[12, 100] current loss: 2.8284369678497314\n",
      "[12, 200] current loss: 2.8168135623931887\n",
      "[12, 300] current loss: 2.849598258972168\n",
      "[12, 400] current loss: 2.852439905166626\n",
      "[12, 500] current loss: 2.8278359375\n",
      "[12, 600] current loss: 2.8191171436309816\n",
      "[12, 700] current loss: 2.84914158821106\n",
      "[12, 800] current loss: 2.840378562927246\n",
      "[12, 900] current loss: 2.8453863048553467\n",
      "[12, 1000] current loss: 2.828449670791626\n",
      "[12, 1100] current loss: 2.8226463737487792\n",
      "[12, 1200] current loss: 2.8540073013305665\n",
      "[12, 1300] current loss: 2.835779525756836\n",
      "[12, 1400] current loss: 2.843838720321655\n",
      "[12, 1500] current loss: 2.8347852725982667\n",
      "[12, 1600] current loss: 2.8435144901275633\n",
      "[12, 1700] current loss: 2.841674556732178\n",
      "[12, 1800] current loss: 2.840064910888672\n",
      "[13, 100] current loss: 2.828176118850708\n",
      "[13, 200] current loss: 2.816471809387207\n",
      "[13, 300] current loss: 2.8493400020599364\n",
      "[13, 400] current loss: 2.8520742321014403\n",
      "[13, 500] current loss: 2.8276052265167237\n",
      "[13, 600] current loss: 2.8188688316345214\n",
      "[13, 700] current loss: 2.848856548309326\n",
      "[13, 800] current loss: 2.840070306777954\n",
      "[13, 900] current loss: 2.845111217498779\n",
      "[13, 1000] current loss: 2.828085241317749\n",
      "[13, 1100] current loss: 2.8223873691558836\n",
      "[13, 1200] current loss: 2.8537659454345703\n",
      "[13, 1300] current loss: 2.835539094924927\n",
      "[13, 1400] current loss: 2.843584379196167\n",
      "[13, 1500] current loss: 2.83442608833313\n",
      "[13, 1600] current loss: 2.8432598686218262\n",
      "[13, 1700] current loss: 2.841383758544922\n",
      "[13, 1800] current loss: 2.839808095932007\n",
      "[14, 100] current loss: 2.827917339324951\n",
      "[14, 200] current loss: 2.816127191543579\n",
      "[14, 300] current loss: 2.8490895137786865\n",
      "[14, 400] current loss: 2.851710678100586\n",
      "[14, 500] current loss: 2.8273696403503417\n",
      "[14, 600] current loss: 2.818626443862915\n",
      "[14, 700] current loss: 2.8485651321411134\n",
      "[14, 800] current loss: 2.8397625312805177\n",
      "[14, 900] current loss: 2.8448320655822754\n",
      "[14, 1000] current loss: 2.827725664138794\n",
      "[14, 1100] current loss: 2.822131193161011\n",
      "[14, 1200] current loss: 2.853534336090088\n",
      "[14, 1300] current loss: 2.835303709030151\n",
      "[14, 1400] current loss: 2.8433362121582033\n",
      "[14, 1500] current loss: 2.834050109863281\n",
      "[14, 1600] current loss: 2.843015815734863\n",
      "[14, 1700] current loss: 2.8410993976593018\n",
      "[14, 1800] current loss: 2.8395694980621338\n",
      "[15, 100] current loss: 2.827662031173706\n",
      "[15, 200] current loss: 2.8157941398620605\n",
      "[15, 300] current loss: 2.8488416709899904\n",
      "[15, 400] current loss: 2.8513661518096924\n",
      "[15, 500] current loss: 2.827140361785889\n",
      "[15, 600] current loss: 2.8183748264312745\n",
      "[15, 700] current loss: 2.848272039413452\n",
      "[15, 800] current loss: 2.8394439277648926\n",
      "[15, 900] current loss: 2.844551826477051\n",
      "[15, 1000] current loss: 2.827370464324951\n",
      "[15, 1100] current loss: 2.8218735256195067\n",
      "[15, 1200] current loss: 2.853296792984009\n",
      "[15, 1300] current loss: 2.8350687847137452\n",
      "[15, 1400] current loss: 2.843090368270874\n",
      "[15, 1500] current loss: 2.833698881149292\n",
      "[15, 1600] current loss: 2.8427542572021482\n",
      "[15, 1700] current loss: 2.8408245105743406\n",
      "[15, 1800] current loss: 2.8393246002197268\n",
      "[16, 100] current loss: 2.8274108448028565\n",
      "[16, 200] current loss: 2.8154649467468262\n",
      "[16, 300] current loss: 2.848600778579712\n",
      "[16, 400] current loss: 2.8510299015045164\n",
      "[16, 500] current loss: 2.8269070014953614\n",
      "[16, 600] current loss: 2.8181273555755615\n",
      "[16, 700] current loss: 2.8479974002838135\n",
      "[16, 800] current loss: 2.8391319217681885\n",
      "[16, 900] current loss: 2.8442752628326415\n",
      "[16, 1000] current loss: 2.8270366382598877\n",
      "[16, 1100] current loss: 2.821617473602295\n",
      "[16, 1200] current loss: 2.8530713710784914\n",
      "[16, 1300] current loss: 2.8348358688354494\n",
      "[16, 1400] current loss: 2.842856439590454\n",
      "[16, 1500] current loss: 2.8333693466186523\n",
      "[16, 1600] current loss: 2.8424900894165037\n",
      "[16, 1700] current loss: 2.8405484828948975\n",
      "[16, 1800] current loss: 2.8390778980255127\n",
      "[17, 100] current loss: 2.8271631641387938\n",
      "[17, 200] current loss: 2.8151502838134768\n",
      "[17, 300] current loss: 2.8483533039093016\n",
      "[17, 400] current loss: 2.8507156887054443\n",
      "[17, 500] current loss: 2.826677450180054\n",
      "[17, 600] current loss: 2.81787858581543\n",
      "[17, 700] current loss: 2.847725280761719\n",
      "[17, 800] current loss: 2.8388131370544434\n",
      "[17, 900] current loss: 2.8440028438568117\n",
      "[17, 1000] current loss: 2.82671252822876\n",
      "[17, 1100] current loss: 2.8213655319213866\n",
      "[17, 1200] current loss: 2.8528475971221923\n",
      "[17, 1300] current loss: 2.83460990524292\n",
      "[17, 1400] current loss: 2.84262055015564\n",
      "[17, 1500] current loss: 2.8330217304229737\n",
      "[17, 1600] current loss: 2.842240364074707\n",
      "[17, 1700] current loss: 2.8402737255096437\n",
      "[17, 1800] current loss: 2.838827331542969\n",
      "[18, 100] current loss: 2.8269254398345947\n",
      "[18, 200] current loss: 2.8148505821228027\n",
      "[18, 300] current loss: 2.8481065921783446\n",
      "[18, 400] current loss: 2.8504095039367674\n",
      "[18, 500] current loss: 2.826442155838013\n",
      "[18, 600] current loss: 2.8176340141296388\n",
      "[18, 700] current loss: 2.8474435348510743\n",
      "[18, 800] current loss: 2.8384943866729735\n",
      "[18, 900] current loss: 2.843731393814087\n",
      "[18, 1000] current loss: 2.8263988189697264\n",
      "[18, 1100] current loss: 2.8211240310668946\n",
      "[18, 1200] current loss: 2.8526242408752442\n",
      "[18, 1300] current loss: 2.834378141403198\n",
      "[18, 1400] current loss: 2.8423742389678956\n",
      "[18, 1500] current loss: 2.8326737194061278\n",
      "[18, 1600] current loss: 2.841997983932495\n",
      "[18, 1700] current loss: 2.8400044803619386\n",
      "[18, 1800] current loss: 2.8385812702178956\n",
      "[19, 100] current loss: 2.8266847553253176\n",
      "[19, 200] current loss: 2.81454500579834\n",
      "[19, 300] current loss: 2.847868309020996\n",
      "[19, 400] current loss: 2.850114809036255\n",
      "[19, 500] current loss: 2.826206853866577\n",
      "[19, 600] current loss: 2.8173933277130128\n",
      "[19, 700] current loss: 2.847177339553833\n",
      "[19, 800] current loss: 2.8381778507232664\n",
      "[19, 900] current loss: 2.8434587535858156\n",
      "[19, 1000] current loss: 2.826088274002075\n",
      "[19, 1100] current loss: 2.8208890991210938\n",
      "[19, 1200] current loss: 2.8523994522094727\n",
      "[19, 1300] current loss: 2.8341602058410644\n",
      "[19, 1400] current loss: 2.8421240482330323\n",
      "[19, 1500] current loss: 2.832355703353882\n",
      "[19, 1600] current loss: 2.841748905181885\n",
      "[19, 1700] current loss: 2.8397375354766847\n",
      "[19, 1800] current loss: 2.8383381481170655\n",
      "CPU times: user 17min 55s, sys: 2.36 s, total: 17min 57s\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch_num  in range(NUM_EPOCHS):\n",
    "    iter_num = 0\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        # forward (подсчёт ответа с текущими весами)\n",
    "        y_pred = net(X_batch)\n",
    "\n",
    "        # вычисляем loss'ы\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # выводем качество каждые 2000 батчей\n",
    "            \n",
    "        if iter_num % 100 == 99:\n",
    "            print('[{}, {}] current loss: {}'.format(epoch_num, iter_num + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        # зануляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward (подсчёт новых градиентов)\n",
    "        loss.backward()\n",
    "\n",
    "        # обновляем веса\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 89 %\n",
      "Accuracy of  Coat : 81 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 60 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag :  0 %\n",
      "Accuracy of Ankle boot :  0 %\n",
      "overall: 69.11666666666666\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        y_pred = net(X_batch)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        c = (predicted == y_batch).squeeze()\n",
    "        for i in range(len(y_pred)):\n",
    "            label = y_batch[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "sum = 0\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    sum+= 100 * class_correct[i] / class_total[i]\n",
    "print(\"overall:\", sum/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.8 s, sys: 196 ms, total: 1.99 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = net(torch.FloatTensor(X_test))\n",
    "create_submission(y_test_pred, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWNQz-SbWs1A"
   },
   "source": [
    "# Whole night test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_report(it, class_correct, class_total, H, lr, batch, proc):\n",
    "    f = open(\"report\" + str(it) + \".txt\",\"w+\")\n",
    "    f.write(\"iteration: %d \\n\" % it)\n",
    "    f.write(\"Hidden: %d \\n\" % H)\n",
    "    f.write(\"Lr: %e \\n\" % lr)\n",
    "    f.write(\"batch: %d \\n\" % batch)\n",
    "    f.write(\"\\n\")\n",
    "    sum = 0\n",
    "    for i in range(10):\n",
    "        f.write('Accuracy of %5s : %2d %% \\n' % (\n",
    "                classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        sum += 100 * class_correct[i] / class_total[i]\n",
    "    f.write(\"overall: \" + str(sum/10))\n",
    "    for i in proc:\n",
    "        f.write(str(i) + \"\\n\")\n",
    "    f.close()\n",
    "    return sum/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.65833333333334"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_report(32, class_correct, class_total, 24, 1e-06, 12,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "BEST ITERATION FOUND!!! SCORE:  60.848333333333336\n",
      "2\n",
      "3\n",
      "BEST ITERATION FOUND!!! SCORE:  64.05166666666666\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "BEST ITERATION FOUND!!! SCORE:  75.11833333333333\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "BEST ITERATION FOUND!!! SCORE:  83.73833333333333\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "BEST ITERATION FOUND!!! SCORE:  86.13500000000002\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "CPU times: user 13h 38min 2s, sys: 2min 39s, total: 13h 40min 41s\n",
      "Wall time: 4h 37min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "H_bunch = [24]\n",
    "lr_bunch = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "batch_bunch = [8, 16, 32, 64, 128, 256]\n",
    "\n",
    "NUM_EPOCHS = 40\n",
    "it = 1\n",
    "BEST_ACC = 0\n",
    "BEST_IT = 0\n",
    "\n",
    "for H in H_bunch:\n",
    "    for lr in lr_bunch:\n",
    "        for BATCH_SIZE in batch_bunch:\n",
    "            proc = []\n",
    "            D_in, D_out = 784, 10\n",
    "            net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(D_in, H**2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(H**2, int(H / 2)**2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(int(H / 2)**2, int(H / 3)**2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(int(H / 3)**2, int(H / 4)**2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(int(H / 4)**2, int(H / 6)**2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(int(H / 6)**2, D_out),\n",
    "            torch.nn.Softmax()\n",
    "            )\n",
    "            \n",
    "\n",
    "            loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "            learning_rate = lr\n",
    "            optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "            for epoch_num  in range(NUM_EPOCHS):\n",
    "                iter_num = 0\n",
    "                running_loss = 0.0\n",
    "                for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "\n",
    "                    y_pred = net(X_batch)\n",
    "\n",
    "                    loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "\n",
    "                    iter_num += 1\n",
    "                if iter_num % 100 == 99:\n",
    "                    proc.append(running_loss / 2000)\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            class_correct = list(0. for i in range(10))\n",
    "            class_total = list(0. for i in range(10))\n",
    "\n",
    "            classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "                       'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "                    y_pred = net(X_batch)\n",
    "                    _, predicted = torch.max(y_pred, 1)\n",
    "                    c = (predicted == y_batch).squeeze()\n",
    "                    for i in range(len(y_pred)):\n",
    "                        label = y_batch[i]\n",
    "                        class_correct[label] += c[i].item()\n",
    "                        class_total[label] += 1\n",
    "            y_test_pred = net(torch.FloatTensor(X_test))\n",
    "            create_submission(y_test_pred, it)\n",
    "            over = write_report(it, class_correct, class_total, H, lr, BATCH_SIZE, proc)\n",
    "            print(it)\n",
    "            if(over > BEST_ACC):\n",
    "                BEST_ACC = over\n",
    "                BEST_IT = it\n",
    "                print(\"BEST ITERATION FOUND!!! SCORE: \", BEST_ACC)\n",
    "            it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.13500000000002 17\n"
     ]
    }
   ],
   "source": [
    "print(BEST_ACC, BEST_IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final attempt 6 layers 300 neurons each 64-size batch 50 epochs lr 1e-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULT: 0.89000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8W0HbJjWs0-"
   },
   "outputs": [],
   "source": [
    "# N - размер батча (batch_size, нужно для метода оптимизации)\n",
    "# D_in - размерность входа (количество признаков у объекта)\n",
    "# H - размерность скрытых слоёв; \n",
    "# D_out - размерность выходного слоя (суть - количество классов)\n",
    "D_in, H, D_out = 784, 1024, 10\n",
    "\n",
    "# определим нейросеть:\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, int(H/2)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(int(H/2), int(H/4)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(int(H/4), int(H/8)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(int(H/8), int(H/16)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(int(H/16), int(H/32)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(int(H/32), int(H/64)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(int(H/64), D_out),\n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 100] current loss: 2.9598693561553957\n",
      "[0, 200] current loss: 2.9677581577301027\n",
      "[0, 300] current loss: 2.949913064956665\n",
      "[0, 400] current loss: 2.929131008148193\n",
      "[0, 500] current loss: 2.937423868179321\n",
      "[0, 600] current loss: 2.9480480976104735\n",
      "[0, 700] current loss: 2.9373051891326902\n",
      "[0, 800] current loss: 2.935397470474243\n",
      "[0, 900] current loss: 2.9550945281982424\n",
      "[0, 1000] current loss: 2.9243810844421385\n",
      "[0, 1100] current loss: 2.911986217498779\n",
      "[0, 1200] current loss: 2.962166591644287\n",
      "[0, 1300] current loss: 2.9359670162200926\n",
      "[0, 1400] current loss: 2.926945812225342\n",
      "[0, 1500] current loss: 2.9296164722442626\n",
      "[0, 1600] current loss: 2.8944910354614257\n",
      "[0, 1700] current loss: 2.934394779205322\n",
      "[0, 1800] current loss: 2.9155705947875976\n",
      "Accuracy of T-shirt/top : 83 %\n",
      "Accuracy of Trouser : 87 %\n",
      "Accuracy of Pullover : 68 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 49 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 43 %\n",
      "Accuracy of Sneaker : 87 %\n",
      "Accuracy of   Bag : 94 %\n",
      "Accuracy of Ankle boot : 95 %\n",
      "overall: 60.97999999999998\n",
      "[1, 100] current loss: 2.898329885482788\n",
      "[1, 200] current loss: 2.92788796043396\n",
      "[1, 300] current loss: 2.9002627239227294\n",
      "[1, 400] current loss: 2.8914126224517824\n",
      "[1, 500] current loss: 2.9079279537200926\n",
      "[1, 600] current loss: 2.9131737785339356\n",
      "[1, 700] current loss: 2.9052746715545656\n",
      "[1, 800] current loss: 2.894753984451294\n",
      "[1, 900] current loss: 2.9133832454681396\n",
      "[1, 1000] current loss: 2.8924555416107176\n",
      "[1, 1100] current loss: 2.8634719867706298\n",
      "[1, 1200] current loss: 2.926025680541992\n",
      "[1, 1300] current loss: 2.895418519973755\n",
      "[1, 1400] current loss: 2.897071102142334\n",
      "[1, 1500] current loss: 2.891751455307007\n",
      "[1, 1600] current loss: 2.8676553020477296\n",
      "[1, 1700] current loss: 2.8968636779785157\n",
      "[1, 1800] current loss: 2.8889382171630857\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 75 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 76 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 39 %\n",
      "Accuracy of Sneaker : 91 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 95 %\n",
      "overall: 66.25166666666667\n",
      "[2, 100] current loss: 2.865436944961548\n",
      "[2, 200] current loss: 2.9008403854370117\n",
      "[2, 300] current loss: 2.8774565467834474\n",
      "[2, 400] current loss: 2.8703022537231444\n",
      "[2, 500] current loss: 2.882486644744873\n",
      "[2, 600] current loss: 2.8940541858673097\n",
      "[2, 700] current loss: 2.8700428085327148\n",
      "[2, 800] current loss: 2.8690183658599855\n",
      "[2, 900] current loss: 2.894042818069458\n",
      "[2, 1000] current loss: 2.869190019607544\n",
      "[2, 1100] current loss: 2.848901592254639\n",
      "[2, 1200] current loss: 2.907830707550049\n",
      "[2, 1300] current loss: 2.8805468349456786\n",
      "[2, 1400] current loss: 2.877679780960083\n",
      "[2, 1500] current loss: 2.8773274536132813\n",
      "[2, 1600] current loss: 2.8576406841278077\n",
      "[2, 1700] current loss: 2.887182939529419\n",
      "[2, 1800] current loss: 2.87332421875\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 77 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 35 %\n",
      "Accuracy of Sneaker : 90 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 66.96333333333334\n",
      "[3, 100] current loss: 2.8552849826812743\n",
      "[3, 200] current loss: 2.890389852523804\n",
      "[3, 300] current loss: 2.8705929622650146\n",
      "[3, 400] current loss: 2.8590372886657716\n",
      "[3, 500] current loss: 2.8681211471557617\n",
      "[3, 600] current loss: 2.8741155128479003\n",
      "[3, 700] current loss: 2.853648687362671\n",
      "[3, 800] current loss: 2.861183464050293\n",
      "[3, 900] current loss: 2.8801147651672365\n",
      "[3, 1000] current loss: 2.859894359588623\n",
      "[3, 1100] current loss: 2.844316707611084\n",
      "[3, 1200] current loss: 2.8954627532958983\n",
      "[3, 1300] current loss: 2.8713933601379393\n",
      "[3, 1400] current loss: 2.8703646717071534\n",
      "[3, 1500] current loss: 2.869567911148071\n",
      "[3, 1600] current loss: 2.8447109413146974\n",
      "[3, 1700] current loss: 2.8703937034606932\n",
      "[3, 1800] current loss: 2.8596259498596193\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 73 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 80 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 43 %\n",
      "Accuracy of Sneaker : 92 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 67.17166666666667\n",
      "[4, 100] current loss: 2.8405802173614503\n",
      "[4, 200] current loss: 2.8795509490966795\n",
      "[4, 300] current loss: 2.8573398895263673\n",
      "[4, 400] current loss: 2.8571847820281984\n",
      "[4, 500] current loss: 2.855980752944946\n",
      "[4, 600] current loss: 2.8666916484832763\n",
      "[4, 700] current loss: 2.848343984603882\n",
      "[4, 800] current loss: 2.857879135131836\n",
      "[4, 900] current loss: 2.8744567852020264\n",
      "[4, 1000] current loss: 2.8541593894958495\n",
      "[4, 1100] current loss: 2.8395213279724123\n",
      "[4, 1200] current loss: 2.889280906677246\n",
      "[4, 1300] current loss: 2.8684178504943847\n",
      "[4, 1400] current loss: 2.862805097579956\n",
      "[4, 1500] current loss: 2.85938671875\n",
      "[4, 1600] current loss: 2.8393266010284424\n",
      "[4, 1700] current loss: 2.8655028228759765\n",
      "[4, 1800] current loss: 2.8508243732452394\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 77 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 80 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 44 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 67.97166666666666\n",
      "[5, 100] current loss: 2.8361921882629395\n",
      "[5, 200] current loss: 2.864135850906372\n",
      "[5, 300] current loss: 2.8538234252929686\n",
      "[5, 400] current loss: 2.852272689819336\n",
      "[5, 500] current loss: 2.8539508876800537\n",
      "[5, 600] current loss: 2.857744951248169\n",
      "[5, 700] current loss: 2.8418061141967774\n",
      "[5, 800] current loss: 2.848007787704468\n",
      "[5, 900] current loss: 2.8717114486694335\n",
      "[5, 1000] current loss: 2.8453939266204835\n",
      "[5, 1100] current loss: 2.826915662765503\n",
      "[5, 1200] current loss: 2.891732536315918\n",
      "[5, 1300] current loss: 2.8615191612243653\n",
      "[5, 1400] current loss: 2.8522243690490723\n",
      "[5, 1500] current loss: 2.8533511333465578\n",
      "[5, 1600] current loss: 2.8290570030212403\n",
      "[5, 1700] current loss: 2.8556987266540528\n",
      "[5, 1800] current loss: 2.8446422271728515\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 38 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 68.52833333333334\n",
      "[6, 100] current loss: 2.8259482250213623\n",
      "[6, 200] current loss: 2.861964521408081\n",
      "[6, 300] current loss: 2.8436353912353516\n",
      "[6, 400] current loss: 2.846382698059082\n",
      "[6, 500] current loss: 2.850112775802612\n",
      "[6, 600] current loss: 2.8549448966979982\n",
      "[6, 700] current loss: 2.8363775062561034\n",
      "[6, 800] current loss: 2.839137870788574\n",
      "[6, 900] current loss: 2.862457389831543\n",
      "[6, 1000] current loss: 2.8386109027862547\n",
      "[6, 1100] current loss: 2.8158565864562988\n",
      "[6, 1200] current loss: 2.879339277267456\n",
      "[6, 1300] current loss: 2.858486999511719\n",
      "[6, 1400] current loss: 2.8492076263427735\n",
      "[6, 1500] current loss: 2.852146141052246\n",
      "[6, 1600] current loss: 2.8289907722473147\n",
      "[6, 1700] current loss: 2.8469617137908934\n",
      "[6, 1800] current loss: 2.8338827419281007\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 81 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 51 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 68.86166666666666\n",
      "[7, 100] current loss: 2.8264387836456297\n",
      "[7, 200] current loss: 2.8601111946105955\n",
      "[7, 300] current loss: 2.840020404815674\n",
      "[7, 400] current loss: 2.844914270401001\n",
      "[7, 500] current loss: 2.8444551811218264\n",
      "[7, 600] current loss: 2.846675853729248\n",
      "[7, 700] current loss: 2.8233967323303224\n",
      "[7, 800] current loss: 2.831461847305298\n",
      "[7, 900] current loss: 2.8522806377410888\n",
      "[7, 1000] current loss: 2.8307545337677\n",
      "[7, 1100] current loss: 2.8144385910034178\n",
      "[7, 1200] current loss: 2.8714768924713137\n",
      "[7, 1300] current loss: 2.8466296005249023\n",
      "[7, 1400] current loss: 2.844067039489746\n",
      "[7, 1500] current loss: 2.8468490505218504\n",
      "[7, 1600] current loss: 2.8140377044677733\n",
      "[7, 1700] current loss: 2.839896499633789\n",
      "[7, 1800] current loss: 2.830280839920044\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 83 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 49 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 94 %\n",
      "overall: 68.99666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 100] current loss: 2.813946548461914\n",
      "[8, 200] current loss: 2.8525316295623777\n",
      "[8, 300] current loss: 2.837511377334595\n",
      "[8, 400] current loss: 2.834797340393066\n",
      "[8, 500] current loss: 2.835883674621582\n",
      "[8, 600] current loss: 2.8401525650024415\n",
      "[8, 700] current loss: 2.8259491214752197\n",
      "[8, 800] current loss: 2.823908311843872\n",
      "[8, 900] current loss: 2.84396688079834\n",
      "[8, 1000] current loss: 2.825143966674805\n",
      "[8, 1100] current loss: 2.8114095764160156\n",
      "[8, 1200] current loss: 2.861629077911377\n",
      "[8, 1300] current loss: 2.8441957836151124\n",
      "[8, 1400] current loss: 2.8347144088745115\n",
      "[8, 1500] current loss: 2.842169153213501\n",
      "[8, 1600] current loss: 2.814096279144287\n",
      "[8, 1700] current loss: 2.8413363170623778\n",
      "[8, 1800] current loss: 2.8221602115631104\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 58 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 49 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 67.78666666666666\n",
      "[9, 100] current loss: 2.8130777244567873\n",
      "[9, 200] current loss: 2.843033529281616\n",
      "[9, 300] current loss: 2.8274796714782715\n",
      "[9, 400] current loss: 2.831119379043579\n",
      "[9, 500] current loss: 2.8264358501434326\n",
      "[9, 600] current loss: 2.8319925689697265\n",
      "[9, 700] current loss: 2.815984531402588\n",
      "[9, 800] current loss: 2.8206091117858887\n",
      "[9, 900] current loss: 2.838004852294922\n",
      "[9, 1000] current loss: 2.8242427654266358\n",
      "[9, 1100] current loss: 2.805179370880127\n",
      "[9, 1200] current loss: 2.855518934249878\n",
      "[9, 1300] current loss: 2.8360176506042483\n",
      "[9, 1400] current loss: 2.834400074005127\n",
      "[9, 1500] current loss: 2.8317932357788087\n",
      "[9, 1600] current loss: 2.8107771949768066\n",
      "[9, 1700] current loss: 2.8369616470336916\n",
      "[9, 1800] current loss: 2.8197887058258058\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress :  0 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 52 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 69.62166666666666\n",
      "[10, 100] current loss: 2.8095828819274904\n",
      "[10, 200] current loss: 2.8357839584350586\n",
      "[10, 300] current loss: 2.8221354904174807\n",
      "[10, 400] current loss: 2.8281608428955076\n",
      "[10, 500] current loss: 2.8280883960723875\n",
      "[10, 600] current loss: 2.8306432609558105\n",
      "[10, 700] current loss: 2.814712385177612\n",
      "[10, 800] current loss: 2.813168586730957\n",
      "[10, 900] current loss: 2.8342336883544923\n",
      "[10, 1000] current loss: 2.817608430862427\n",
      "[10, 1100] current loss: 2.8006920166015625\n",
      "[10, 1200] current loss: 2.8382205734252928\n",
      "[10, 1300] current loss: 2.739998796463013\n",
      "[10, 1400] current loss: 2.7468111362457277\n",
      "[10, 1500] current loss: 2.7421845741271973\n",
      "[10, 1600] current loss: 2.713819353103638\n",
      "[10, 1700] current loss: 2.734461347579956\n",
      "[10, 1800] current loss: 2.7092009181976318\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 93 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 78 %\n",
      "Accuracy of  Coat : 54 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 54 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 75.23\n",
      "[11, 100] current loss: 2.705347812652588\n",
      "[11, 200] current loss: 2.716195821762085\n",
      "[11, 300] current loss: 2.7101230144500734\n",
      "[11, 400] current loss: 2.7208449325561523\n",
      "[11, 500] current loss: 2.7115734672546385\n",
      "[11, 600] current loss: 2.7100435695648195\n",
      "[11, 700] current loss: 2.7164181423187257\n",
      "[11, 800] current loss: 2.712617036819458\n",
      "[11, 900] current loss: 2.722074531555176\n",
      "[11, 1000] current loss: 2.702197629928589\n",
      "[11, 1100] current loss: 2.70806902885437\n",
      "[11, 1200] current loss: 2.7377813835144043\n",
      "[11, 1300] current loss: 2.7088474407196044\n",
      "[11, 1400] current loss: 2.72227841758728\n",
      "[11, 1500] current loss: 2.730322458267212\n",
      "[11, 1600] current loss: 2.6989324684143066\n",
      "[11, 1700] current loss: 2.7203246746063234\n",
      "[11, 1800] current loss: 2.6932786979675294\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 73 %\n",
      "Accuracy of  Coat : 75 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 55 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 76.62666666666667\n",
      "[12, 100] current loss: 2.696577661514282\n",
      "[12, 200] current loss: 2.703334665298462\n",
      "[12, 300] current loss: 2.7061126766204833\n",
      "[12, 400] current loss: 2.700341909408569\n",
      "[12, 500] current loss: 2.701862180709839\n",
      "[12, 600] current loss: 2.699122678756714\n",
      "[12, 700] current loss: 2.701870147705078\n",
      "[12, 800] current loss: 2.7023483085632325\n",
      "[12, 900] current loss: 2.710982389450073\n",
      "[12, 1000] current loss: 2.6904776878356933\n",
      "[12, 1100] current loss: 2.690089406967163\n",
      "[12, 1200] current loss: 2.7282627716064454\n",
      "[12, 1300] current loss: 2.7020965385437012\n",
      "[12, 1400] current loss: 2.708581848144531\n",
      "[12, 1500] current loss: 2.7130357513427734\n",
      "[12, 1600] current loss: 2.6855075969696043\n",
      "[12, 1700] current loss: 2.707195379257202\n",
      "[12, 1800] current loss: 2.6807910003662108\n",
      "Accuracy of T-shirt/top : 83 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 88 %\n",
      "Accuracy of  Coat : 78 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 60 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 94 %\n",
      "overall: 77.65166666666667\n",
      "[13, 100] current loss: 2.689964542388916\n",
      "[13, 200] current loss: 2.6948574752807617\n",
      "[13, 300] current loss: 2.691741138458252\n",
      "[13, 400] current loss: 2.695696334838867\n",
      "[13, 500] current loss: 2.6960565567016603\n",
      "[13, 600] current loss: 2.6981717166900636\n",
      "[13, 700] current loss: 2.6982160968780518\n",
      "[13, 800] current loss: 2.695028558731079\n",
      "[13, 900] current loss: 2.709835933685303\n",
      "[13, 1000] current loss: 2.6905503520965577\n",
      "[13, 1100] current loss: 2.685019914627075\n",
      "[13, 1200] current loss: 2.717988067626953\n",
      "[13, 1300] current loss: 2.6923671188354494\n",
      "[13, 1400] current loss: 2.7069520835876464\n",
      "[13, 1500] current loss: 2.7069136505126954\n",
      "[13, 1600] current loss: 2.6850141086578367\n",
      "[13, 1700] current loss: 2.7069187355041504\n",
      "[13, 1800] current loss: 2.6796776103973388\n",
      "Accuracy of T-shirt/top : 71 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 83 %\n",
      "Accuracy of  Coat : 83 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 65 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 77.39\n",
      "[14, 100] current loss: 2.682377700805664\n",
      "[14, 200] current loss: 2.696760362625122\n",
      "[14, 300] current loss: 2.6879140491485596\n",
      "[14, 400] current loss: 2.6888709926605223\n",
      "[14, 500] current loss: 2.684389930725098\n",
      "[14, 600] current loss: 2.693609058380127\n",
      "[14, 700] current loss: 2.691432140350342\n",
      "[14, 800] current loss: 2.6806291179656982\n",
      "[14, 900] current loss: 2.700416482925415\n",
      "[14, 1000] current loss: 2.6863754062652587\n",
      "[14, 1100] current loss: 2.6814010620117186\n",
      "[14, 1200] current loss: 2.714916275024414\n",
      "[14, 1300] current loss: 2.6836499004364014\n",
      "[14, 1400] current loss: 2.6997416572570803\n",
      "[14, 1500] current loss: 2.705319055557251\n",
      "[14, 1600] current loss: 2.675263916015625\n",
      "[14, 1700] current loss: 2.697254627227783\n",
      "[14, 1800] current loss: 2.6816030082702635\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 77 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 57 %\n",
      "Accuracy of Sneaker : 92 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 78.21833333333333\n",
      "[15, 100] current loss: 2.671479928970337\n",
      "[15, 200] current loss: 2.6837440490722657\n",
      "[15, 300] current loss: 2.6786951904296874\n",
      "[15, 400] current loss: 2.683468547821045\n",
      "[15, 500] current loss: 2.6805991802215576\n",
      "[15, 600] current loss: 2.6850654220581056\n",
      "[15, 700] current loss: 2.7027578010559083\n",
      "[15, 800] current loss: 2.6735058383941652\n",
      "[15, 900] current loss: 2.696060094833374\n",
      "[15, 1000] current loss: 2.671386615753174\n",
      "[15, 1100] current loss: 2.6658576736450197\n",
      "[15, 1200] current loss: 2.711538272857666\n",
      "[15, 1300] current loss: 2.6831702842712404\n",
      "[15, 1400] current loss: 2.697924434661865\n",
      "[15, 1500] current loss: 2.6948247318267824\n",
      "[15, 1600] current loss: 2.676063083648682\n",
      "[15, 1700] current loss: 2.696601001739502\n",
      "[15, 1800] current loss: 2.6767816219329834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 81 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress : 83 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 66 %\n",
      "Accuracy of Sneaker : 90 %\n",
      "Accuracy of   Bag : 95 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 78.06166666666667\n",
      "[16, 100] current loss: 2.6734845790863035\n",
      "[16, 200] current loss: 2.686577169418335\n",
      "[16, 300] current loss: 2.670518867492676\n",
      "[16, 400] current loss: 2.668534936904907\n",
      "[16, 500] current loss: 2.6817152767181396\n",
      "[16, 600] current loss: 2.677987710952759\n",
      "[16, 700] current loss: 2.6842796096801758\n",
      "[16, 800] current loss: 2.6657095642089845\n",
      "[16, 900] current loss: 2.6859400520324708\n",
      "[16, 1000] current loss: 2.673254379272461\n",
      "[16, 1100] current loss: 2.6644542236328124\n",
      "[16, 1200] current loss: 2.7055900173187255\n",
      "[16, 1300] current loss: 2.6741845054626463\n",
      "[16, 1400] current loss: 2.6872482395172117\n",
      "[16, 1500] current loss: 2.6972304267883302\n",
      "[16, 1600] current loss: 2.667925382614136\n",
      "[16, 1700] current loss: 2.689529630661011\n",
      "[16, 1800] current loss: 2.667640214920044\n",
      "Accuracy of T-shirt/top : 85 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 87 %\n",
      "Accuracy of  Coat : 79 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 68 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 79.03833333333333\n",
      "[17, 100] current loss: 2.668224884033203\n",
      "[17, 200] current loss: 2.6780544528961183\n",
      "[17, 300] current loss: 2.673118465423584\n",
      "[17, 400] current loss: 2.6699743118286134\n",
      "[17, 500] current loss: 2.673030912399292\n",
      "[17, 600] current loss: 2.6757329196929933\n",
      "[17, 700] current loss: 2.6776119441986084\n",
      "[17, 800] current loss: 2.6646324729919435\n",
      "[17, 900] current loss: 2.6760192222595216\n",
      "[17, 1000] current loss: 2.6629366416931153\n",
      "[17, 1100] current loss: 2.659335702896118\n",
      "[17, 1200] current loss: 2.7010672454833986\n",
      "[17, 1300] current loss: 2.6688779106140137\n",
      "[17, 1400] current loss: 2.6841451053619383\n",
      "[17, 1500] current loss: 2.6796303176879883\n",
      "[17, 1600] current loss: 2.6593709144592284\n",
      "[17, 1700] current loss: 2.684980564117432\n",
      "[17, 1800] current loss: 2.6610754680633546\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 82 %\n",
      "Accuracy of  Coat : 79 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 67 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 78.95833333333333\n",
      "[18, 100] current loss: 2.6602636070251466\n",
      "[18, 200] current loss: 2.6762573680877684\n",
      "[18, 300] current loss: 2.6663725299835206\n",
      "[18, 400] current loss: 2.668700967788696\n",
      "[18, 500] current loss: 2.6652789459228514\n",
      "[18, 600] current loss: 2.672381809234619\n",
      "[18, 700] current loss: 2.681298927307129\n",
      "[18, 800] current loss: 2.659490924835205\n",
      "[18, 900] current loss: 2.675968603134155\n",
      "[18, 1000] current loss: 2.6582414379119874\n",
      "[18, 1100] current loss: 2.66320560836792\n",
      "[18, 1200] current loss: 2.685591640472412\n",
      "[18, 1300] current loss: 2.667628568649292\n",
      "[18, 1400] current loss: 2.6775899562835694\n",
      "[18, 1500] current loss: 2.6808775978088377\n",
      "[18, 1600] current loss: 2.6570244731903077\n",
      "[18, 1700] current loss: 2.6805673866271973\n",
      "[18, 1800] current loss: 2.653320838928223\n",
      "Accuracy of T-shirt/top : 72 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 63 %\n",
      "Accuracy of Dress : 85 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 74 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 77.50833333333335\n",
      "[19, 100] current loss: 2.6617053089141844\n",
      "[19, 200] current loss: 2.665986936569214\n",
      "[19, 300] current loss: 2.663843843460083\n",
      "[19, 400] current loss: 2.6632784214019773\n",
      "[19, 500] current loss: 2.664883184432983\n",
      "[19, 600] current loss: 2.673922492980957\n",
      "[19, 700] current loss: 2.671714874267578\n",
      "[19, 800] current loss: 2.6545588188171387\n",
      "[19, 900] current loss: 2.671115089416504\n",
      "[19, 1000] current loss: 2.656970380783081\n",
      "[19, 1100] current loss: 2.657663724899292\n",
      "[19, 1200] current loss: 2.6768862323760985\n",
      "[19, 1300] current loss: 2.665391513824463\n",
      "[19, 1400] current loss: 2.6790451259613035\n",
      "[19, 1500] current loss: 2.6789464569091797\n",
      "[19, 1600] current loss: 2.659349893569946\n",
      "[19, 1700] current loss: 2.6740063667297362\n",
      "[19, 1800] current loss: 2.646356800079346\n",
      "Accuracy of T-shirt/top : 85 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 81 %\n",
      "Accuracy of  Coat : 77 %\n",
      "Accuracy of Sandal :  0 %\n",
      "Accuracy of Shirt : 73 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 96 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 78.93166666666667\n",
      "[20, 100] current loss: 2.658491933822632\n",
      "[20, 200] current loss: 2.6668990631103515\n",
      "[20, 300] current loss: 2.6563918819427492\n",
      "[20, 400] current loss: 2.660517999649048\n",
      "[20, 500] current loss: 2.662032236099243\n",
      "[20, 600] current loss: 2.6723284225463866\n",
      "[20, 700] current loss: 2.6713587188720704\n",
      "[20, 800] current loss: 2.649381624221802\n",
      "[20, 900] current loss: 2.6755358085632324\n",
      "[20, 1000] current loss: 2.6502761306762697\n",
      "[20, 1100] current loss: 2.638591344833374\n",
      "[20, 1200] current loss: 2.6415718746185304\n",
      "[20, 1300] current loss: 2.599900688171387\n",
      "[20, 1400] current loss: 2.5795812129974367\n",
      "[20, 1500] current loss: 2.5682730503082274\n",
      "[20, 1600] current loss: 2.5480035018920897\n",
      "[20, 1700] current loss: 2.554535972595215\n",
      "[20, 1800] current loss: 2.5547318000793457\n",
      "Accuracy of T-shirt/top : 80 %\n",
      "Accuracy of Trouser : 94 %\n",
      "Accuracy of Pullover : 69 %\n",
      "Accuracy of Dress : 81 %\n",
      "Accuracy of  Coat : 65 %\n",
      "Accuracy of Sandal : 94 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 88 %\n",
      "Accuracy of   Bag : 95 %\n",
      "Accuracy of Ankle boot : 94 %\n",
      "overall: 84.59\n",
      "[21, 100] current loss: 2.544187620162964\n",
      "[21, 200] current loss: 2.5344974365234374\n",
      "[21, 300] current loss: 2.5424753303527834\n",
      "[21, 400] current loss: 2.548990390777588\n",
      "[21, 500] current loss: 2.5376016216278074\n",
      "[21, 600] current loss: 2.532283405303955\n",
      "[21, 700] current loss: 2.554475444793701\n",
      "[21, 800] current loss: 2.529080154418945\n",
      "[21, 900] current loss: 2.5529661960601806\n",
      "[21, 1000] current loss: 2.533445930480957\n",
      "[21, 1100] current loss: 2.526739227294922\n",
      "[21, 1200] current loss: 2.537576240539551\n",
      "[21, 1300] current loss: 2.542280261993408\n",
      "[21, 1400] current loss: 2.537308603286743\n",
      "[21, 1500] current loss: 2.5365145320892335\n",
      "[21, 1600] current loss: 2.530816207885742\n",
      "[21, 1700] current loss: 2.5401127243041994\n",
      "[21, 1800] current loss: 2.5428106269836426\n",
      "Accuracy of T-shirt/top : 79 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 89 %\n",
      "Accuracy of  Coat : 77 %\n",
      "Accuracy of Sandal : 90 %\n",
      "Accuracy of Shirt : 77 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 92 %\n",
      "overall: 87.94500000000001\n",
      "[22, 100] current loss: 2.5304153213500977\n",
      "[22, 200] current loss: 2.5263360080718993\n",
      "[22, 300] current loss: 2.531567174911499\n",
      "[22, 400] current loss: 2.541258861541748\n",
      "[22, 500] current loss: 2.5215500240325928\n",
      "[22, 600] current loss: 2.529014226913452\n",
      "[22, 700] current loss: 2.540496248245239\n",
      "[22, 800] current loss: 2.517816680908203\n",
      "[22, 900] current loss: 2.535884759902954\n",
      "[22, 1000] current loss: 2.534883186340332\n",
      "[22, 1100] current loss: 2.524940912246704\n",
      "[22, 1200] current loss: 2.54075944519043\n",
      "[22, 1300] current loss: 2.531574825286865\n",
      "[22, 1400] current loss: 2.534051200866699\n",
      "[22, 1500] current loss: 2.5280966854095457\n",
      "[22, 1600] current loss: 2.5163482456207276\n",
      "[22, 1700] current loss: 2.5272284240722658\n",
      "[22, 1800] current loss: 2.529642370223999\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 75 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal : 95 %\n",
      "Accuracy of Shirt : 70 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 95 %\n",
      "Accuracy of Ankle boot : 94 %\n",
      "overall: 88.01166666666666\n",
      "[23, 100] current loss: 2.5327118282318115\n",
      "[23, 200] current loss: 2.5150076694488526\n",
      "[23, 300] current loss: 2.515513551712036\n",
      "[23, 400] current loss: 2.5290231380462647\n",
      "[23, 500] current loss: 2.520282123565674\n",
      "[23, 600] current loss: 2.51477414894104\n",
      "[23, 700] current loss: 2.5362588710784912\n",
      "[23, 800] current loss: 2.516360366821289\n",
      "[23, 900] current loss: 2.5290648708343504\n",
      "[23, 1000] current loss: 2.518232856750488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 1100] current loss: 2.509559215545654\n",
      "[23, 1200] current loss: 2.523383134841919\n",
      "[23, 1300] current loss: 2.5202273178100585\n",
      "[23, 1400] current loss: 2.5227741680145264\n",
      "[23, 1500] current loss: 2.5248062858581544\n",
      "[23, 1600] current loss: 2.5138731670379637\n",
      "[23, 1700] current loss: 2.530804281234741\n",
      "[23, 1800] current loss: 2.5221556034088133\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 73 %\n",
      "Accuracy of Dress : 86 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 96 %\n",
      "Accuracy of Shirt : 74 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 91 %\n",
      "overall: 88.56333333333335\n",
      "[24, 100] current loss: 2.521630548477173\n",
      "[24, 200] current loss: 2.5153438320159913\n",
      "[24, 300] current loss: 2.5143230991363525\n",
      "[24, 400] current loss: 2.5242940406799317\n",
      "[24, 500] current loss: 2.5132344875335693\n",
      "[24, 600] current loss: 2.515620153427124\n",
      "[24, 700] current loss: 2.5362646350860594\n",
      "[24, 800] current loss: 2.5039615421295167\n",
      "[24, 900] current loss: 2.5299564056396484\n",
      "[24, 1000] current loss: 2.517595006942749\n",
      "[24, 1100] current loss: 2.503026779174805\n",
      "[24, 1200] current loss: 2.5231606121063233\n",
      "[24, 1300] current loss: 2.520755256652832\n",
      "[24, 1400] current loss: 2.521236883163452\n",
      "[24, 1500] current loss: 2.5268266773223877\n",
      "[24, 1600] current loss: 2.5247874069213867\n",
      "[24, 1700] current loss: 2.522820613861084\n",
      "[24, 1800] current loss: 2.5251230125427244\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 88 %\n",
      "Accuracy of  Coat : 83 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 66 %\n",
      "Accuracy of Sneaker : 82 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 95 %\n",
      "overall: 88.56499999999998\n",
      "[25, 100] current loss: 2.518317451477051\n",
      "[25, 200] current loss: 2.5103750839233396\n",
      "[25, 300] current loss: 2.5092432346343996\n",
      "[25, 400] current loss: 2.5192660789489745\n",
      "[25, 500] current loss: 2.5130839862823486\n",
      "[25, 600] current loss: 2.5159228324890135\n",
      "[25, 700] current loss: 2.5324326400756836\n",
      "[25, 800] current loss: 2.4996321620941164\n",
      "[25, 900] current loss: 2.51854097366333\n",
      "[25, 1000] current loss: 2.5097673473358153\n",
      "[25, 1100] current loss: 2.498819393157959\n",
      "[25, 1200] current loss: 2.5090255336761476\n",
      "[25, 1300] current loss: 2.510066987991333\n",
      "[25, 1400] current loss: 2.5124495887756346\n",
      "[25, 1500] current loss: 2.5220849227905275\n",
      "[25, 1600] current loss: 2.509090145111084\n",
      "[25, 1700] current loss: 2.522996900558472\n",
      "[25, 1800] current loss: 2.519909914016724\n",
      "Accuracy of T-shirt/top : 73 %\n",
      "Accuracy of Trouser : 95 %\n",
      "Accuracy of Pullover : 71 %\n",
      "Accuracy of Dress : 88 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 96 %\n",
      "Accuracy of Shirt : 78 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 88.25833333333335\n",
      "[26, 100] current loss: 2.5189746227264402\n",
      "[26, 200] current loss: 2.5052102336883544\n",
      "[26, 300] current loss: 2.521537260055542\n",
      "[26, 400] current loss: 2.5200741138458254\n",
      "[26, 500] current loss: 2.5043419818878174\n",
      "[26, 600] current loss: 2.5056960849761962\n",
      "[26, 700] current loss: 2.523405605316162\n",
      "[26, 800] current loss: 2.498201642990112\n",
      "[26, 900] current loss: 2.5123223495483398\n",
      "[26, 1000] current loss: 2.5151596450805664\n",
      "[26, 1100] current loss: 2.497766355514526\n",
      "[26, 1200] current loss: 2.5053255462646487\n",
      "[26, 1300] current loss: 2.5063380756378173\n",
      "[26, 1400] current loss: 2.5024525985717774\n",
      "[26, 1500] current loss: 2.511164014816284\n",
      "[26, 1600] current loss: 2.5035663108825683\n",
      "[26, 1700] current loss: 2.517356161117554\n",
      "[26, 1800] current loss: 2.513078691482544\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress : 88 %\n",
      "Accuracy of  Coat : 80 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 76 %\n",
      "Accuracy of Sneaker : 91 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 89.35166666666666\n",
      "[27, 100] current loss: 2.508736255645752\n",
      "[27, 200] current loss: 2.4997913398742675\n",
      "[27, 300] current loss: 2.5048854141235353\n",
      "[27, 400] current loss: 2.5157392864227295\n",
      "[27, 500] current loss: 2.502032180786133\n",
      "[27, 600] current loss: 2.501946922302246\n",
      "[27, 700] current loss: 2.5169551086425783\n",
      "[27, 800] current loss: 2.49205385017395\n",
      "[27, 900] current loss: 2.515406370162964\n",
      "[27, 1000] current loss: 2.511244800567627\n",
      "[27, 1100] current loss: 2.492903263092041\n",
      "[27, 1200] current loss: 2.5019148292541504\n",
      "[27, 1300] current loss: 2.5053473873138428\n",
      "[27, 1400] current loss: 2.5094738597869872\n",
      "[27, 1500] current loss: 2.5165605602264405\n",
      "[27, 1600] current loss: 2.5082795810699463\n",
      "[27, 1700] current loss: 2.515913288116455\n",
      "[27, 1800] current loss: 2.512113260269165\n",
      "Accuracy of T-shirt/top : 78 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 75 %\n",
      "Accuracy of Dress : 87 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 95 %\n",
      "Accuracy of Shirt : 75 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 94 %\n",
      "overall: 88.96333333333332\n",
      "[28, 100] current loss: 2.505600803375244\n",
      "[28, 200] current loss: 2.4880141010284422\n",
      "[28, 300] current loss: 2.503948440551758\n",
      "[28, 400] current loss: 2.5191862316131592\n",
      "[28, 500] current loss: 2.5029157810211182\n",
      "[28, 600] current loss: 2.503364664077759\n",
      "[28, 700] current loss: 2.521119047164917\n",
      "[28, 800] current loss: 2.5055620155334473\n",
      "[28, 900] current loss: 2.517192434310913\n",
      "[28, 1000] current loss: 2.509453353881836\n",
      "[28, 1100] current loss: 2.5107248249053957\n",
      "[28, 1200] current loss: 2.5061197681427\n",
      "[28, 1300] current loss: 2.496177284240723\n",
      "[28, 1400] current loss: 2.5030928688049316\n",
      "[28, 1500] current loss: 2.513041255950928\n",
      "[28, 1600] current loss: 2.50122674369812\n",
      "[28, 1700] current loss: 2.508035936355591\n",
      "[28, 1800] current loss: 2.514625286102295\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 78 %\n",
      "Accuracy of Dress : 83 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal : 96 %\n",
      "Accuracy of Shirt : 76 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 89.36333333333333\n",
      "[29, 100] current loss: 2.5069942474365234\n",
      "[29, 200] current loss: 2.4952441196441653\n",
      "[29, 300] current loss: 2.49749853515625\n",
      "[29, 400] current loss: 2.5023467025756836\n",
      "[29, 500] current loss: 2.5030267906188963\n",
      "[29, 600] current loss: 2.4998616065979005\n",
      "[29, 700] current loss: 2.512894660949707\n",
      "[29, 800] current loss: 2.4910809116363524\n",
      "[29, 900] current loss: 2.5061233158111573\n",
      "[29, 1000] current loss: 2.4995566387176513\n",
      "[29, 1100] current loss: 2.497352506637573\n",
      "[29, 1200] current loss: 2.5002617607116697\n",
      "[29, 1300] current loss: 2.499958433151245\n",
      "[29, 1400] current loss: 2.5104969177246095\n",
      "[29, 1500] current loss: 2.5023430461883547\n",
      "[29, 1600] current loss: 2.499590881347656\n",
      "[29, 1700] current loss: 2.50681950378418\n",
      "[29, 1800] current loss: 2.510895574569702\n",
      "Accuracy of T-shirt/top : 79 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 95 %\n",
      "Accuracy of Shirt : 65 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 95 %\n",
      "overall: 89.06\n",
      "[30, 100] current loss: 2.505997838973999\n",
      "[30, 200] current loss: 2.487925989151001\n",
      "[30, 300] current loss: 2.495006317138672\n",
      "[30, 400] current loss: 2.508954658508301\n",
      "[30, 500] current loss: 2.50173699760437\n",
      "[30, 600] current loss: 2.4987367706298826\n",
      "[30, 700] current loss: 2.5069977245330812\n",
      "[30, 800] current loss: 2.4906474647521972\n",
      "[30, 900] current loss: 2.5050532417297364\n",
      "[30, 1000] current loss: 2.496928081512451\n",
      "[30, 1100] current loss: 2.498182270050049\n",
      "[30, 1200] current loss: 2.5025233192443848\n",
      "[30, 1300] current loss: 2.4993422107696532\n",
      "[30, 1400] current loss: 2.510942693710327\n",
      "[30, 1500] current loss: 2.5146319313049315\n",
      "[30, 1600] current loss: 2.502499757766724\n",
      "[30, 1700] current loss: 2.5121421337127687\n",
      "[30, 1800] current loss: 2.5003310012817384\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 80 %\n",
      "Accuracy of Sandal : 94 %\n",
      "Accuracy of Shirt : 71 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 93 %\n",
      "overall: 89.72333333333333\n",
      "[31, 100] current loss: 2.5047948303222656\n",
      "[31, 200] current loss: 2.4822622394561766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 300] current loss: 2.501138879776001\n",
      "[31, 400] current loss: 2.504365249633789\n",
      "[31, 500] current loss: 2.492558530807495\n",
      "[31, 600] current loss: 2.5041117401123048\n",
      "[31, 700] current loss: 2.50974542427063\n",
      "[31, 800] current loss: 2.486888301849365\n",
      "[31, 900] current loss: 2.505800947189331\n",
      "[31, 1000] current loss: 2.5116848163604737\n",
      "[31, 1100] current loss: 2.4914458236694337\n",
      "[31, 1200] current loss: 2.4997939891815184\n",
      "[31, 1300] current loss: 2.488257890701294\n",
      "[31, 1400] current loss: 2.5135619583129882\n",
      "[31, 1500] current loss: 2.5042689476013185\n",
      "[31, 1600] current loss: 2.493473403930664\n",
      "[31, 1700] current loss: 2.495901168823242\n",
      "[31, 1800] current loss: 2.50873278427124\n",
      "Accuracy of T-shirt/top : 77 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 71 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 80 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 89.275\n",
      "[32, 100] current loss: 2.4978515968322754\n",
      "[32, 200] current loss: 2.483823089599609\n",
      "[32, 300] current loss: 2.496727457046509\n",
      "[32, 400] current loss: 2.504250188827515\n",
      "[32, 500] current loss: 2.498489025115967\n",
      "[32, 600] current loss: 2.4893176136016844\n",
      "[32, 700] current loss: 2.5069460849761964\n",
      "[32, 800] current loss: 2.487315450668335\n",
      "[32, 900] current loss: 2.501129943847656\n",
      "[32, 1000] current loss: 2.495428117752075\n",
      "[32, 1100] current loss: 2.499520404815674\n",
      "[32, 1200] current loss: 2.5020709285736085\n",
      "[32, 1300] current loss: 2.4875314979553225\n",
      "[32, 1400] current loss: 2.495999948501587\n",
      "[32, 1500] current loss: 2.500195541381836\n",
      "[32, 1600] current loss: 2.4892037811279297\n",
      "[32, 1700] current loss: 2.5017163581848143\n",
      "[32, 1800] current loss: 2.501202886581421\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 95 %\n",
      "Accuracy of Shirt : 73 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 90 %\n",
      "overall: 90.1\n",
      "[33, 100] current loss: 2.4994794101715088\n",
      "[33, 200] current loss: 2.481317199707031\n",
      "[33, 300] current loss: 2.4926313304901124\n",
      "[33, 400] current loss: 2.500028673171997\n",
      "[33, 500] current loss: 2.49630228805542\n",
      "[33, 600] current loss: 2.494983512878418\n",
      "[33, 700] current loss: 2.5048331871032716\n",
      "[33, 800] current loss: 2.488071294784546\n",
      "[33, 900] current loss: 2.506396270751953\n",
      "[33, 1000] current loss: 2.5012594470977785\n",
      "[33, 1100] current loss: 2.483645132064819\n",
      "[33, 1200] current loss: 2.496879493713379\n",
      "[33, 1300] current loss: 2.4951123180389403\n",
      "[33, 1400] current loss: 2.4993766803741453\n",
      "[33, 1500] current loss: 2.500682939529419\n",
      "[33, 1600] current loss: 2.4982044143676756\n",
      "[33, 1700] current loss: 2.4996834278106688\n",
      "[33, 1800] current loss: 2.496554542541504\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 76 %\n",
      "Accuracy of Dress : 88 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 96 %\n",
      "Accuracy of Shirt : 73 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 95 %\n",
      "overall: 89.99333333333333\n",
      "[34, 100] current loss: 2.5039739265441896\n",
      "[34, 200] current loss: 2.473717842102051\n",
      "[34, 300] current loss: 2.4891875839233397\n",
      "[34, 400] current loss: 2.502144124984741\n",
      "[34, 500] current loss: 2.4906858158111573\n",
      "[34, 600] current loss: 2.490713882446289\n",
      "[34, 700] current loss: 2.5017524127960207\n",
      "[34, 800] current loss: 2.480690086364746\n",
      "[34, 900] current loss: 2.4947844104766848\n",
      "[34, 1000] current loss: 2.4894503078460692\n",
      "[34, 1100] current loss: 2.4777105197906493\n",
      "[34, 1200] current loss: 2.493882349014282\n",
      "[34, 1300] current loss: 2.5012316398620604\n",
      "[34, 1400] current loss: 2.500283973693848\n",
      "[34, 1500] current loss: 2.5069088954925536\n",
      "[34, 1600] current loss: 2.492627649307251\n",
      "[34, 1700] current loss: 2.4895334358215333\n",
      "[34, 1800] current loss: 2.4976709537506103\n",
      "Accuracy of T-shirt/top : 75 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 65 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 94 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 88.83\n",
      "[35, 100] current loss: 2.501492166519165\n",
      "[35, 200] current loss: 2.482533876419067\n",
      "[35, 300] current loss: 2.4821812591552734\n",
      "[35, 400] current loss: 2.495623035430908\n",
      "[35, 500] current loss: 2.4886129360198974\n",
      "[35, 600] current loss: 2.495087100982666\n",
      "[35, 700] current loss: 2.4949876842498777\n",
      "[35, 800] current loss: 2.487148754119873\n",
      "[35, 900] current loss: 2.5035260734558107\n",
      "[35, 1000] current loss: 2.487403329849243\n",
      "[35, 1100] current loss: 2.494698848724365\n",
      "[35, 1200] current loss: 2.4964845085144045\n",
      "[35, 1300] current loss: 2.48904594039917\n",
      "[35, 1400] current loss: 2.487051668167114\n",
      "[35, 1500] current loss: 2.509515375137329\n",
      "[35, 1600] current loss: 2.4862724895477295\n",
      "[35, 1700] current loss: 2.498882402420044\n",
      "[35, 1800] current loss: 2.5087276401519776\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 72 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 91.17666666666666\n",
      "[36, 100] current loss: 2.4986635265350343\n",
      "[36, 200] current loss: 2.4863723278045655\n",
      "[36, 300] current loss: 2.483166931152344\n",
      "[36, 400] current loss: 2.494884769439697\n",
      "[36, 500] current loss: 2.4817810878753663\n",
      "[36, 600] current loss: 2.4804520416259765\n",
      "[36, 700] current loss: 2.4936003074646\n",
      "[36, 800] current loss: 2.4815241947174074\n",
      "[36, 900] current loss: 2.496453227996826\n",
      "[36, 1000] current loss: 2.485656251907349\n",
      "[36, 1100] current loss: 2.481956285476685\n",
      "[36, 1200] current loss: 2.493874013900757\n",
      "[36, 1300] current loss: 2.4942994232177735\n",
      "[36, 1400] current loss: 2.4899943599700927\n",
      "[36, 1500] current loss: 2.5026089763641357\n",
      "[36, 1600] current loss: 2.4776383094787597\n",
      "[36, 1700] current loss: 2.499084733963013\n",
      "[36, 1800] current loss: 2.501139032363892\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress : 87 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 47 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 88.59333333333333\n",
      "[37, 100] current loss: 2.501270227432251\n",
      "[37, 200] current loss: 2.4744528102874757\n",
      "[37, 300] current loss: 2.4898158893585207\n",
      "[37, 400] current loss: 2.4886461181640627\n",
      "[37, 500] current loss: 2.48486869430542\n",
      "[37, 600] current loss: 2.4939119129180907\n",
      "[37, 700] current loss: 2.4998745613098143\n",
      "[37, 800] current loss: 2.4707977867126463\n",
      "[37, 900] current loss: 2.4958128833770754\n",
      "[37, 1000] current loss: 2.4908449115753175\n",
      "[37, 1100] current loss: 2.473168056488037\n",
      "[37, 1200] current loss: 2.4858549461364747\n",
      "[37, 1300] current loss: 2.491336326599121\n",
      "[37, 1400] current loss: 2.4886861934661866\n",
      "[37, 1500] current loss: 2.5053325080871582\n",
      "[37, 1600] current loss: 2.48708062171936\n",
      "[37, 1700] current loss: 2.485946918487549\n",
      "[37, 1800] current loss: 2.4924785270690917\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 88 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 59 %\n",
      "Accuracy of Sneaker : 91 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 89.42999999999999\n",
      "[38, 100] current loss: 2.4944348621368406\n",
      "[38, 200] current loss: 2.4843916149139402\n",
      "[38, 300] current loss: 2.4889779872894287\n",
      "[38, 400] current loss: 2.489516456604004\n",
      "[38, 500] current loss: 2.484864284515381\n",
      "[38, 600] current loss: 2.484715181350708\n",
      "[38, 700] current loss: 2.4920924453735354\n",
      "[38, 800] current loss: 2.4749943656921385\n",
      "[38, 900] current loss: 2.483895942687988\n",
      "[38, 1000] current loss: 2.4876527671813964\n",
      "[38, 1100] current loss: 2.4845620346069337\n",
      "[38, 1200] current loss: 2.487074323654175\n",
      "[38, 1300] current loss: 2.485689476013184\n",
      "[38, 1400] current loss: 2.4931908073425295\n",
      "[38, 1500] current loss: 2.493467050552368\n",
      "[38, 1600] current loss: 2.4784990253448487\n",
      "[38, 1700] current loss: 2.4889054470062257\n",
      "[38, 1800] current loss: 2.4975464363098143\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 59 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 75 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 89.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39, 100] current loss: 2.4887704372406008\n",
      "[39, 200] current loss: 2.485156394958496\n",
      "[39, 300] current loss: 2.478473201751709\n",
      "[39, 400] current loss: 2.482827533721924\n",
      "[39, 500] current loss: 2.4794591979980467\n",
      "[39, 600] current loss: 2.4786030559539793\n",
      "[39, 700] current loss: 2.494930950164795\n",
      "[39, 800] current loss: 2.470588733673096\n",
      "[39, 900] current loss: 2.492991132736206\n",
      "[39, 1000] current loss: 2.4759519996643067\n",
      "[39, 1100] current loss: 2.4806000175476073\n",
      "[39, 1200] current loss: 2.48150429725647\n",
      "[39, 1300] current loss: 2.497772394180298\n",
      "[39, 1400] current loss: 2.4981042213439943\n",
      "[39, 1500] current loss: 2.4975283908843995\n",
      "[39, 1600] current loss: 2.4802746238708497\n",
      "[39, 1700] current loss: 2.486739309310913\n",
      "[39, 1800] current loss: 2.4869371337890627\n",
      "Accuracy of T-shirt/top : 85 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 75 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 83 %\n",
      "Accuracy of Sandal : 96 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 90.47999999999999\n",
      "[40, 100] current loss: 2.490184139251709\n",
      "[40, 200] current loss: 2.471937349319458\n",
      "[40, 300] current loss: 2.4750834789276124\n",
      "[40, 400] current loss: 2.4910134334564207\n",
      "[40, 500] current loss: 2.4769045162200927\n",
      "[40, 600] current loss: 2.4774837741851807\n",
      "[40, 700] current loss: 2.4949946498870847\n",
      "[40, 800] current loss: 2.471469688415527\n",
      "[40, 900] current loss: 2.479197374343872\n",
      "[40, 1000] current loss: 2.4756923332214353\n",
      "[40, 1100] current loss: 2.4821691188812256\n",
      "[40, 1200] current loss: 2.4797600021362305\n",
      "[40, 1300] current loss: 2.485616662979126\n",
      "[40, 1400] current loss: 2.481351198196411\n",
      "[40, 1500] current loss: 2.490155965805054\n",
      "[40, 1600] current loss: 2.4825794219970705\n",
      "[40, 1700] current loss: 2.4869999504089355\n",
      "[40, 1800] current loss: 2.4931817626953126\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 77 %\n",
      "Accuracy of Sneaker : 88 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 90.42166666666667\n",
      "[41, 100] current loss: 2.4900332012176514\n",
      "[41, 200] current loss: 2.4722085704803467\n",
      "[41, 300] current loss: 2.4761008949279786\n",
      "[41, 400] current loss: 2.4805405292510985\n",
      "[41, 500] current loss: 2.4725445289611816\n",
      "[41, 600] current loss: 2.479472162246704\n",
      "[41, 700] current loss: 2.4955004444122313\n",
      "[41, 800] current loss: 2.473985023498535\n",
      "[41, 900] current loss: 2.4872463874816892\n",
      "[41, 1000] current loss: 2.4827111339569092\n",
      "[41, 1100] current loss: 2.4805273094177247\n",
      "[41, 1200] current loss: 2.4815336303710938\n",
      "[41, 1300] current loss: 2.488676647186279\n",
      "[41, 1400] current loss: 2.478260046005249\n",
      "[41, 1500] current loss: 2.4938549003601076\n",
      "[41, 1600] current loss: 2.4843775005340576\n",
      "[41, 1700] current loss: 2.487813236236572\n",
      "[41, 1800] current loss: 2.4965188694000244\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 75 %\n",
      "Accuracy of Sneaker : 93 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.19333333333334\n",
      "[42, 100] current loss: 2.48656582069397\n",
      "[42, 200] current loss: 2.4628442649841307\n",
      "[42, 300] current loss: 2.4755626945495606\n",
      "[42, 400] current loss: 2.4814810886383056\n",
      "[42, 500] current loss: 2.485058708190918\n",
      "[42, 600] current loss: 2.482777208328247\n",
      "[42, 700] current loss: 2.4932320308685303\n",
      "[42, 800] current loss: 2.4762035121917725\n",
      "[42, 900] current loss: 2.491239835739136\n",
      "[42, 1000] current loss: 2.475464548110962\n",
      "[42, 1100] current loss: 2.4697231636047365\n",
      "[42, 1200] current loss: 2.485279083251953\n",
      "[42, 1300] current loss: 2.479937917709351\n",
      "[42, 1400] current loss: 2.4865697441101076\n",
      "[42, 1500] current loss: 2.49248219871521\n",
      "[42, 1600] current loss: 2.4799759883880617\n",
      "[42, 1700] current loss: 2.4817916507720947\n",
      "[42, 1800] current loss: 2.4833064460754395\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 65 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 72 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 89.79833333333336\n",
      "[43, 100] current loss: 2.4827917079925537\n",
      "[43, 200] current loss: 2.471592325210571\n",
      "[43, 300] current loss: 2.492136375427246\n",
      "[43, 400] current loss: 2.489321786880493\n",
      "[43, 500] current loss: 2.478872373580933\n",
      "[43, 600] current loss: 2.4729681701660158\n",
      "[43, 700] current loss: 2.4867850856781004\n",
      "[43, 800] current loss: 2.4722625980377195\n",
      "[43, 900] current loss: 2.4820045986175536\n",
      "[43, 1000] current loss: 2.4897625160217287\n",
      "[43, 1100] current loss: 2.484104940414429\n",
      "[43, 1200] current loss: 2.4764601573944094\n",
      "[43, 1300] current loss: 2.478644672393799\n",
      "[43, 1400] current loss: 2.486139678955078\n",
      "[43, 1500] current loss: 2.4935347232818605\n",
      "[43, 1600] current loss: 2.4736501960754396\n",
      "[43, 1700] current loss: 2.4739937801361083\n",
      "[43, 1800] current loss: 2.483403865814209\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 96 %\n",
      "Accuracy of Shirt : 73 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 92 %\n",
      "overall: 91.33166666666668\n",
      "[44, 100] current loss: 2.4869467182159424\n",
      "[44, 200] current loss: 2.4730945892333986\n",
      "[44, 300] current loss: 2.478936403274536\n",
      "[44, 400] current loss: 2.4915128383636476\n",
      "[44, 500] current loss: 2.470630746841431\n",
      "[44, 600] current loss: 2.4832299518585206\n",
      "[44, 700] current loss: 2.4872580490112304\n",
      "[44, 800] current loss: 2.46601309967041\n",
      "[44, 900] current loss: 2.481259292602539\n",
      "[44, 1000] current loss: 2.4752773952484133\n",
      "[44, 1100] current loss: 2.4762183780670166\n",
      "[44, 1200] current loss: 2.477322292327881\n",
      "[44, 1300] current loss: 2.4853139972686766\n",
      "[44, 1400] current loss: 2.4744800033569336\n",
      "[44, 1500] current loss: 2.491237180709839\n",
      "[44, 1600] current loss: 2.4756654090881347\n",
      "[44, 1700] current loss: 2.481552282333374\n",
      "[44, 1800] current loss: 2.487748910903931\n",
      "Accuracy of T-shirt/top : 71 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 65 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 89.01666666666668\n",
      "[45, 100] current loss: 2.482710111618042\n",
      "[45, 200] current loss: 2.4703262825012207\n",
      "[45, 300] current loss: 2.4755544204711915\n",
      "[45, 400] current loss: 2.491810766220093\n",
      "[45, 500] current loss: 2.4741643409729006\n",
      "[45, 600] current loss: 2.4791457424163816\n",
      "[45, 700] current loss: 2.4874244537353514\n",
      "[45, 800] current loss: 2.467468807220459\n",
      "[45, 900] current loss: 2.490725606918335\n",
      "[45, 1000] current loss: 2.471596736907959\n",
      "[45, 1100] current loss: 2.474200475692749\n",
      "[45, 1200] current loss: 2.4879277420043944\n",
      "[45, 1300] current loss: 2.489964450836182\n",
      "[45, 1400] current loss: 2.4790688133239747\n",
      "[45, 1500] current loss: 2.47824066734314\n",
      "[45, 1600] current loss: 2.4716195888519286\n",
      "[45, 1700] current loss: 2.4791480083465576\n",
      "[45, 1800] current loss: 2.4803206520080567\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 69 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 91.97166666666666\n",
      "[46, 100] current loss: 2.4861687774658203\n",
      "[46, 200] current loss: 2.4625893745422363\n",
      "[46, 300] current loss: 2.4720376567840576\n",
      "[46, 400] current loss: 2.484103229522705\n",
      "[46, 500] current loss: 2.468512535095215\n",
      "[46, 600] current loss: 2.4731989555358886\n",
      "[46, 700] current loss: 2.4777598743438722\n",
      "[46, 800] current loss: 2.4643239288330077\n",
      "[46, 900] current loss: 2.484036247253418\n",
      "[46, 1000] current loss: 2.468507852554321\n",
      "[46, 1100] current loss: 2.469130441665649\n",
      "[46, 1200] current loss: 2.4720821590423583\n",
      "[46, 1300] current loss: 2.487310537338257\n",
      "[46, 1400] current loss: 2.4786815013885497\n",
      "[46, 1500] current loss: 2.4833695640563964\n",
      "[46, 1600] current loss: 2.4741919441223144\n",
      "[46, 1700] current loss: 2.476414945602417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 1800] current loss: 2.4728008251190188\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 81 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 78 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 90.94999999999999\n",
      "[47, 100] current loss: 2.4761273403167725\n",
      "[47, 200] current loss: 2.468827283859253\n",
      "[47, 300] current loss: 2.4683268394470215\n",
      "[47, 400] current loss: 2.487202341079712\n",
      "[47, 500] current loss: 2.4741972007751465\n",
      "[47, 600] current loss: 2.481944980621338\n",
      "[47, 700] current loss: 2.4837391204833983\n",
      "[47, 800] current loss: 2.4767004623413085\n",
      "[47, 900] current loss: 2.501410863876343\n",
      "[47, 1000] current loss: 2.479175968170166\n",
      "[47, 1100] current loss: 2.46866263961792\n",
      "[47, 1200] current loss: 2.473779588699341\n",
      "[47, 1300] current loss: 2.477196464538574\n",
      "[47, 1400] current loss: 2.4755572509765624\n",
      "[47, 1500] current loss: 2.4772283973693847\n",
      "[47, 1600] current loss: 2.4670463066101074\n",
      "[47, 1700] current loss: 2.473272653579712\n",
      "[47, 1800] current loss: 2.484432405471802\n",
      "Accuracy of T-shirt/top : 76 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 78 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 90.66666666666666\n",
      "[48, 100] current loss: 2.472750192642212\n",
      "[48, 200] current loss: 2.4602344970703127\n",
      "[48, 300] current loss: 2.473624906539917\n",
      "[48, 400] current loss: 2.475176134109497\n",
      "[48, 500] current loss: 2.476414567947388\n",
      "[48, 600] current loss: 2.4703195457458498\n",
      "[48, 700] current loss: 2.48014910697937\n",
      "[48, 800] current loss: 2.4595210456848147\n",
      "[48, 900] current loss: 2.482963411331177\n",
      "[48, 1000] current loss: 2.466711637496948\n",
      "[48, 1100] current loss: 2.468450975418091\n",
      "[48, 1200] current loss: 2.4732579002380373\n",
      "[48, 1300] current loss: 2.474185010910034\n",
      "[48, 1400] current loss: 2.476606262207031\n",
      "[48, 1500] current loss: 2.4815841598510744\n",
      "[48, 1600] current loss: 2.4776501483917235\n",
      "[48, 1700] current loss: 2.471156856536865\n",
      "[48, 1800] current loss: 2.4694472312927247\n",
      "Accuracy of T-shirt/top : 78 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 87 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 90.25666666666669\n",
      "[49, 100] current loss: 2.4791009826660155\n",
      "[49, 200] current loss: 2.4641217918395997\n",
      "[49, 300] current loss: 2.4652976245880125\n",
      "[49, 400] current loss: 2.4845609111785887\n",
      "[49, 500] current loss: 2.469951982498169\n",
      "[49, 600] current loss: 2.4833707160949707\n",
      "[49, 700] current loss: 2.473730600357056\n",
      "[49, 800] current loss: 2.470054780960083\n",
      "[49, 900] current loss: 2.4749332752227784\n",
      "[49, 1000] current loss: 2.4724808387756347\n",
      "[49, 1100] current loss: 2.470864559173584\n",
      "[49, 1200] current loss: 2.473012138366699\n",
      "[49, 1300] current loss: 2.4771010093688965\n",
      "[49, 1400] current loss: 2.4712137966156007\n",
      "[49, 1500] current loss: 2.4811106414794923\n",
      "[49, 1600] current loss: 2.472164304733276\n",
      "[49, 1700] current loss: 2.476988687515259\n",
      "[49, 1800] current loss: 2.4718017501831056\n",
      "Accuracy of T-shirt/top : 84 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 79 %\n",
      "Accuracy of Dress : 89 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.24666666666666\n",
      "[50, 100] current loss: 2.474754955291748\n",
      "[50, 200] current loss: 2.4547837905883787\n",
      "[50, 300] current loss: 2.4768604698181154\n",
      "[50, 400] current loss: 2.4819173736572266\n",
      "[50, 500] current loss: 2.4737937545776365\n",
      "[50, 600] current loss: 2.4656222038269044\n",
      "[50, 700] current loss: 2.4729799671173094\n",
      "[50, 800] current loss: 2.4630856494903566\n",
      "[50, 900] current loss: 2.4774524402618407\n",
      "[50, 1000] current loss: 2.4653495864868162\n",
      "[50, 1100] current loss: 2.4671158962249757\n",
      "[50, 1200] current loss: 2.4667380962371825\n",
      "[50, 1300] current loss: 2.470362827301025\n",
      "[50, 1400] current loss: 2.4743369579315186\n",
      "[50, 1500] current loss: 2.478540687561035\n",
      "[50, 1600] current loss: 2.475323511123657\n",
      "[50, 1700] current loss: 2.47648097038269\n",
      "[50, 1800] current loss: 2.476956792831421\n",
      "Accuracy of T-shirt/top : 70 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 77 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 89.82666666666665\n",
      "[51, 100] current loss: 2.4783477516174317\n",
      "[51, 200] current loss: 2.467263654708862\n",
      "[51, 300] current loss: 2.4760842170715334\n",
      "[51, 400] current loss: 2.479175579071045\n",
      "[51, 500] current loss: 2.4705763816833497\n",
      "[51, 600] current loss: 2.47325657081604\n",
      "[51, 700] current loss: 2.475120065689087\n",
      "[51, 800] current loss: 2.4478299407958986\n",
      "[51, 900] current loss: 2.465748680114746\n",
      "[51, 1000] current loss: 2.463157958984375\n",
      "[51, 1100] current loss: 2.460789514541626\n",
      "[51, 1200] current loss: 2.4750746231079104\n",
      "[51, 1300] current loss: 2.467542230606079\n",
      "[51, 1400] current loss: 2.472438440322876\n",
      "[51, 1500] current loss: 2.47386358833313\n",
      "[51, 1600] current loss: 2.4754460620880128\n",
      "[51, 1700] current loss: 2.471351644515991\n",
      "[51, 1800] current loss: 2.481851083755493\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 78 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 85 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 91.27333333333334\n",
      "[52, 100] current loss: 2.472520875930786\n",
      "[52, 200] current loss: 2.4545787601470948\n",
      "[52, 300] current loss: 2.4735948123931886\n",
      "[52, 400] current loss: 2.4772386074066164\n",
      "[52, 500] current loss: 2.46587412071228\n",
      "[52, 600] current loss: 2.4704981994628907\n",
      "[52, 700] current loss: 2.4785647106170656\n",
      "[52, 800] current loss: 2.458726501464844\n",
      "[52, 900] current loss: 2.4751490325927734\n",
      "[52, 1000] current loss: 2.467927192687988\n",
      "[52, 1100] current loss: 2.470233739852905\n",
      "[52, 1200] current loss: 2.47434334564209\n",
      "[52, 1300] current loss: 2.475931043624878\n",
      "[52, 1400] current loss: 2.458767967224121\n",
      "[52, 1500] current loss: 2.49049640083313\n",
      "[52, 1600] current loss: 2.4790688648223878\n",
      "[52, 1700] current loss: 2.473254186630249\n",
      "[52, 1800] current loss: 2.475719486236572\n",
      "Accuracy of T-shirt/top : 80 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 78 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 85 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 90.84333333333333\n",
      "[53, 100] current loss: 2.471595920562744\n",
      "[53, 200] current loss: 2.455195064544678\n",
      "[53, 300] current loss: 2.4699994945526123\n",
      "[53, 400] current loss: 2.4826276779174803\n",
      "[53, 500] current loss: 2.465736354827881\n",
      "[53, 600] current loss: 2.471360332489014\n",
      "[53, 700] current loss: 2.4803672389984133\n",
      "[53, 800] current loss: 2.457207424163818\n",
      "[53, 900] current loss: 2.4764983749389646\n",
      "[53, 1000] current loss: 2.462739465713501\n",
      "[53, 1100] current loss: 2.465194040298462\n",
      "[53, 1200] current loss: 2.4680540885925293\n",
      "[53, 1300] current loss: 2.4657692165374754\n",
      "[53, 1400] current loss: 2.472794891357422\n",
      "[53, 1500] current loss: 2.4733694667816164\n",
      "[53, 1600] current loss: 2.4692705287933348\n",
      "[53, 1700] current loss: 2.4656405296325685\n",
      "[53, 1800] current loss: 2.472152997970581\n",
      "Accuracy of T-shirt/top : 67 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 78 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 95 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 89.45\n",
      "[54, 100] current loss: 2.477314437866211\n",
      "[54, 200] current loss: 2.461256113052368\n",
      "[54, 300] current loss: 2.4630727405548094\n",
      "[54, 400] current loss: 2.4755833225250243\n",
      "[54, 500] current loss: 2.4732723522186277\n",
      "[54, 600] current loss: 2.477182233810425\n",
      "[54, 700] current loss: 2.4721858139038084\n",
      "[54, 800] current loss: 2.455742477416992\n",
      "[54, 900] current loss: 2.474001979827881\n",
      "[54, 1000] current loss: 2.478843366622925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 1100] current loss: 2.4734063606262207\n",
      "[54, 1200] current loss: 2.4723700942993165\n",
      "[54, 1300] current loss: 2.4809156074523924\n",
      "[54, 1400] current loss: 2.4749509372711183\n",
      "[54, 1500] current loss: 2.47086724281311\n",
      "[54, 1600] current loss: 2.4689460697174073\n",
      "[54, 1700] current loss: 2.480428134918213\n",
      "[54, 1800] current loss: 2.4764557094573973\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 58 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 90.76333333333332\n",
      "[55, 100] current loss: 2.475360189437866\n",
      "[55, 200] current loss: 2.4573533782958985\n",
      "[55, 300] current loss: 2.468516052246094\n",
      "[55, 400] current loss: 2.47509313583374\n",
      "[55, 500] current loss: 2.480569248199463\n",
      "[55, 600] current loss: 2.467629373550415\n",
      "[55, 700] current loss: 2.4716288204193115\n",
      "[55, 800] current loss: 2.460685869216919\n",
      "[55, 900] current loss: 2.476203800201416\n",
      "[55, 1000] current loss: 2.46511051940918\n",
      "[55, 1100] current loss: 2.463924512863159\n",
      "[55, 1200] current loss: 2.465536401748657\n",
      "[55, 1300] current loss: 2.4707635192871096\n",
      "[55, 1400] current loss: 2.4765611476898193\n",
      "[55, 1500] current loss: 2.4796896419525147\n",
      "[55, 1600] current loss: 2.4741957893371582\n",
      "[55, 1700] current loss: 2.4741990871429445\n",
      "[55, 1800] current loss: 2.4616037998199465\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 75 %\n",
      "Accuracy of Sneaker : 91 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.81333333333333\n",
      "[56, 100] current loss: 2.469718189239502\n",
      "[56, 200] current loss: 2.453737995147705\n",
      "[56, 300] current loss: 2.474169546127319\n",
      "[56, 400] current loss: 2.4731050128936767\n",
      "[56, 500] current loss: 2.4586018657684328\n",
      "[56, 600] current loss: 2.4606739864349367\n",
      "[56, 700] current loss: 2.4781144638061523\n",
      "[56, 800] current loss: 2.457271255493164\n",
      "[56, 900] current loss: 2.4699620704650878\n",
      "[56, 1000] current loss: 2.461644914627075\n",
      "[56, 1100] current loss: 2.456935619354248\n",
      "[56, 1200] current loss: 2.4647296504974365\n",
      "[56, 1300] current loss: 2.4676194992065428\n",
      "[56, 1400] current loss: 2.4625005760192873\n",
      "[56, 1500] current loss: 2.480071678161621\n",
      "[56, 1600] current loss: 2.470927640914917\n",
      "[56, 1700] current loss: 2.4735161361694336\n",
      "[56, 1800] current loss: 2.472590606689453\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 75 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.38500000000002\n",
      "[57, 100] current loss: 2.4704292221069335\n",
      "[57, 200] current loss: 2.456015199661255\n",
      "[57, 300] current loss: 2.4675392208099365\n",
      "[57, 400] current loss: 2.4689129199981688\n",
      "[57, 500] current loss: 2.4638831825256347\n",
      "[57, 600] current loss: 2.4649045734405517\n",
      "[57, 700] current loss: 2.4764006443023683\n",
      "[57, 800] current loss: 2.4527192420959474\n",
      "[57, 900] current loss: 2.4714239654541017\n",
      "[57, 1000] current loss: 2.4577689170837402\n",
      "[57, 1100] current loss: 2.4627323303222655\n",
      "[57, 1200] current loss: 2.4574177684783938\n",
      "[57, 1300] current loss: 2.461865270614624\n",
      "[57, 1400] current loss: 2.462515802383423\n",
      "[57, 1500] current loss: 2.4730756492614745\n",
      "[57, 1600] current loss: 2.4641376190185547\n",
      "[57, 1700] current loss: 2.470496824264526\n",
      "[57, 1800] current loss: 2.470467372894287\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.04333333333334\n",
      "[58, 100] current loss: 2.4733045082092286\n",
      "[58, 200] current loss: 2.4563206119537355\n",
      "[58, 300] current loss: 2.463744197845459\n",
      "[58, 400] current loss: 2.4645272903442383\n",
      "[58, 500] current loss: 2.462251901626587\n",
      "[58, 600] current loss: 2.465596218109131\n",
      "[58, 700] current loss: 2.469898025512695\n",
      "[58, 800] current loss: 2.445439458847046\n",
      "[58, 900] current loss: 2.4711352405548097\n",
      "[58, 1000] current loss: 2.4616505794525145\n",
      "[58, 1100] current loss: 2.464484504699707\n",
      "[58, 1200] current loss: 2.4652739963531496\n",
      "[58, 1300] current loss: 2.473715061187744\n",
      "[58, 1400] current loss: 2.46052716255188\n",
      "[58, 1500] current loss: 2.4699146251678465\n",
      "[58, 1600] current loss: 2.4601134719848634\n",
      "[58, 1700] current loss: 2.4740006732940674\n",
      "[58, 1800] current loss: 2.467031982421875\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 80 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.90666666666667\n",
      "[59, 100] current loss: 2.465131488800049\n",
      "[59, 200] current loss: 2.4550915031433105\n",
      "[59, 300] current loss: 2.453532064437866\n",
      "[59, 400] current loss: 2.468207977294922\n",
      "[59, 500] current loss: 2.4694020805358887\n",
      "[59, 600] current loss: 2.4693570518493653\n",
      "[59, 700] current loss: 2.472105405807495\n",
      "[59, 800] current loss: 2.449138807296753\n",
      "[59, 900] current loss: 2.4729026737213133\n",
      "[59, 1000] current loss: 2.4591850891113283\n",
      "[59, 1100] current loss: 2.461678258895874\n",
      "[59, 1200] current loss: 2.466063529968262\n",
      "[59, 1300] current loss: 2.4697722702026366\n",
      "[59, 1400] current loss: 2.455373306274414\n",
      "[59, 1500] current loss: 2.468801849365234\n",
      "[59, 1600] current loss: 2.45643837928772\n",
      "[59, 1700] current loss: 2.4620600242614747\n",
      "[59, 1800] current loss: 2.4748051853179933\n",
      "Accuracy of T-shirt/top : 78 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 73 %\n",
      "Accuracy of  Coat : 78 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 88.73500000000001\n",
      "[60, 100] current loss: 2.4712819137573243\n",
      "[60, 200] current loss: 2.4572740421295167\n",
      "[60, 300] current loss: 2.4557767906188963\n",
      "[60, 400] current loss: 2.460701560974121\n",
      "[60, 500] current loss: 2.46560107421875\n",
      "[60, 600] current loss: 2.4716939544677734\n",
      "[60, 700] current loss: 2.4667350559234618\n",
      "[60, 800] current loss: 2.4428506813049315\n",
      "[60, 900] current loss: 2.471323673248291\n",
      "[60, 1000] current loss: 2.4618470249176023\n",
      "[60, 1100] current loss: 2.4556858959198\n",
      "[60, 1200] current loss: 2.4571759815216065\n",
      "[60, 1300] current loss: 2.485240539550781\n",
      "[60, 1400] current loss: 2.4637687702178956\n",
      "[60, 1500] current loss: 2.4684162883758547\n",
      "[60, 1600] current loss: 2.463084665298462\n",
      "[60, 1700] current loss: 2.462541597366333\n",
      "[60, 1800] current loss: 2.4656449508666993\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 81 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 80 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.28333333333333\n",
      "[61, 100] current loss: 2.470448781967163\n",
      "[61, 200] current loss: 2.454120250701904\n",
      "[61, 300] current loss: 2.4694168605804445\n",
      "[61, 400] current loss: 2.462112854003906\n",
      "[61, 500] current loss: 2.459798803329468\n",
      "[61, 600] current loss: 2.468936586380005\n",
      "[61, 700] current loss: 2.46934454536438\n",
      "[61, 800] current loss: 2.4565923690795897\n",
      "[61, 900] current loss: 2.4780377368927002\n",
      "[61, 1000] current loss: 2.4674960441589358\n",
      "[61, 1100] current loss: 2.4586768913269044\n",
      "[61, 1200] current loss: 2.4659179344177247\n",
      "[61, 1300] current loss: 2.4669502582550047\n",
      "[61, 1400] current loss: 2.4640380821228027\n",
      "[61, 1500] current loss: 2.470143138885498\n",
      "[61, 1600] current loss: 2.4705256328582763\n",
      "[61, 1700] current loss: 2.4670492095947267\n",
      "[61, 1800] current loss: 2.4659900569915774\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 96 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress : 88 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 91.66\n",
      "[62, 100] current loss: 2.465775770187378\n",
      "[62, 200] current loss: 2.4593120975494385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 300] current loss: 2.4653356285095214\n",
      "[62, 400] current loss: 2.470979063034058\n",
      "[62, 500] current loss: 2.4664278106689452\n",
      "[62, 600] current loss: 2.462526065826416\n",
      "[62, 700] current loss: 2.475931468963623\n",
      "[62, 800] current loss: 2.4624427013397217\n",
      "[62, 900] current loss: 2.4704763526916502\n",
      "[62, 1000] current loss: 2.4629537982940675\n",
      "[62, 1100] current loss: 2.464245038986206\n",
      "[62, 1200] current loss: 2.4689385051727295\n",
      "[62, 1300] current loss: 2.4727351760864256\n",
      "[62, 1400] current loss: 2.4609651679992677\n",
      "[62, 1500] current loss: 2.476527935028076\n",
      "[62, 1600] current loss: 2.4573578186035157\n",
      "[62, 1700] current loss: 2.462201406478882\n",
      "[62, 1800] current loss: 2.467811985015869\n",
      "Accuracy of T-shirt/top : 78 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 76 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 78 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 90.96999999999998\n",
      "[63, 100] current loss: 2.464622922897339\n",
      "[63, 200] current loss: 2.4581323204040526\n",
      "[63, 300] current loss: 2.4663868465423584\n",
      "[63, 400] current loss: 2.461319267272949\n",
      "[63, 500] current loss: 2.461462661743164\n",
      "[63, 600] current loss: 2.4604692764282228\n",
      "[63, 700] current loss: 2.4688160209655763\n",
      "[63, 800] current loss: 2.4469799156188965\n",
      "[63, 900] current loss: 2.4662983894348143\n",
      "[63, 1000] current loss: 2.4547393951416017\n",
      "[63, 1100] current loss: 2.453020191192627\n",
      "[63, 1200] current loss: 2.4684303913116454\n",
      "[63, 1300] current loss: 2.466783754348755\n",
      "[63, 1400] current loss: 2.463911521911621\n",
      "[63, 1500] current loss: 2.4643257942199708\n",
      "[63, 1600] current loss: 2.4662834453582763\n",
      "[63, 1700] current loss: 2.463842155456543\n",
      "[63, 1800] current loss: 2.4711720638275145\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 79 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.60666666666665\n",
      "[64, 100] current loss: 2.4642550163269044\n",
      "[64, 200] current loss: 2.4541005573272705\n",
      "[64, 300] current loss: 2.471975826263428\n",
      "[64, 400] current loss: 2.469951511383057\n",
      "[64, 500] current loss: 2.462715894699097\n",
      "[64, 600] current loss: 2.465924264907837\n",
      "[64, 700] current loss: 2.468095874786377\n",
      "[64, 800] current loss: 2.4514150257110594\n",
      "[64, 900] current loss: 2.4720087127685546\n",
      "[64, 1000] current loss: 2.458053943634033\n",
      "[64, 1100] current loss: 2.4555631465911865\n",
      "[64, 1200] current loss: 2.4623994140625\n",
      "[64, 1300] current loss: 2.463044677734375\n",
      "[64, 1400] current loss: 2.461767681121826\n",
      "[64, 1500] current loss: 2.46659969329834\n",
      "[64, 1600] current loss: 2.4616999797821046\n",
      "[64, 1700] current loss: 2.464398572921753\n",
      "[64, 1800] current loss: 2.46411590385437\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 77 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.19166666666668\n",
      "[65, 100] current loss: 2.4785528297424317\n",
      "[65, 200] current loss: 2.4549300861358643\n",
      "[65, 300] current loss: 2.4542647762298584\n",
      "[65, 400] current loss: 2.463622985839844\n",
      "[65, 500] current loss: 2.4581216259002687\n",
      "[65, 600] current loss: 2.4590550804138185\n",
      "[65, 700] current loss: 2.462091714859009\n",
      "[65, 800] current loss: 2.4532985820770263\n",
      "[65, 900] current loss: 2.466823553085327\n",
      "[65, 1000] current loss: 2.4657162799835204\n",
      "[65, 1100] current loss: 2.452706939697266\n",
      "[65, 1200] current loss: 2.4579771060943605\n",
      "[65, 1300] current loss: 2.4631083164215086\n",
      "[65, 1400] current loss: 2.4649448013305664\n",
      "[65, 1500] current loss: 2.478402183532715\n",
      "[65, 1600] current loss: 2.4563191032409666\n",
      "[65, 1700] current loss: 2.4618898582458497\n",
      "[65, 1800] current loss: 2.4701008415222168\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 74 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.29499999999999\n",
      "[66, 100] current loss: 2.4613772296905516\n",
      "[66, 200] current loss: 2.459523639678955\n",
      "[66, 300] current loss: 2.4678289737701418\n",
      "[66, 400] current loss: 2.4754101066589356\n",
      "[66, 500] current loss: 2.4557036895751954\n",
      "[66, 600] current loss: 2.458390073776245\n",
      "[66, 700] current loss: 2.460064851760864\n",
      "[66, 800] current loss: 2.45040372467041\n",
      "[66, 900] current loss: 2.463942777633667\n",
      "[66, 1000] current loss: 2.4519633407592774\n",
      "[66, 1100] current loss: 2.450108160018921\n",
      "[66, 1200] current loss: 2.4554990310668945\n",
      "[66, 1300] current loss: 2.465204242706299\n",
      "[66, 1400] current loss: 2.449777624130249\n",
      "[66, 1500] current loss: 2.462231838226318\n",
      "[66, 1600] current loss: 2.4642073059082032\n",
      "[66, 1700] current loss: 2.4616332111358643\n",
      "[66, 1800] current loss: 2.4611233215332033\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 74 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 92.9\n",
      "[67, 100] current loss: 2.46022127532959\n",
      "[67, 200] current loss: 2.446008949279785\n",
      "[67, 300] current loss: 2.455404666900635\n",
      "[67, 400] current loss: 2.4640947227478027\n",
      "[67, 500] current loss: 2.451163908004761\n",
      "[67, 600] current loss: 2.4627054443359375\n",
      "[67, 700] current loss: 2.4661742992401123\n",
      "[67, 800] current loss: 2.439204454421997\n",
      "[67, 900] current loss: 2.4650297718048098\n",
      "[67, 1000] current loss: 2.459501756668091\n",
      "[67, 1100] current loss: 2.4499284992218016\n",
      "[67, 1200] current loss: 2.458233028411865\n",
      "[67, 1300] current loss: 2.4625941677093506\n",
      "[67, 1400] current loss: 2.456801092147827\n",
      "[67, 1500] current loss: 2.467835111618042\n",
      "[67, 1600] current loss: 2.461224691390991\n",
      "[67, 1700] current loss: 2.462650749206543\n",
      "[67, 1800] current loss: 2.4568506450653076\n",
      "Accuracy of T-shirt/top : 79 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 76 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.10333333333332\n",
      "[68, 100] current loss: 2.462538724899292\n",
      "[68, 200] current loss: 2.4511363143920897\n",
      "[68, 300] current loss: 2.4596840057373046\n",
      "[68, 400] current loss: 2.452137638092041\n",
      "[68, 500] current loss: 2.4591212635040285\n",
      "[68, 600] current loss: 2.4556396408081054\n",
      "[68, 700] current loss: 2.4679396781921388\n",
      "[68, 800] current loss: 2.447946746826172\n",
      "[68, 900] current loss: 2.467366325378418\n",
      "[68, 1000] current loss: 2.4587653064727784\n",
      "[68, 1100] current loss: 2.4732372245788574\n",
      "[68, 1200] current loss: 2.4582748565673826\n",
      "[68, 1300] current loss: 2.4605352058410643\n",
      "[68, 1400] current loss: 2.4557110862731935\n",
      "[68, 1500] current loss: 2.4660851993560793\n",
      "[68, 1600] current loss: 2.468179634094238\n",
      "[68, 1700] current loss: 2.458325231552124\n",
      "[68, 1800] current loss: 2.4561868476867676\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 82 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.16833333333334\n",
      "[69, 100] current loss: 2.4558095836639406\n",
      "[69, 200] current loss: 2.4464169330596923\n",
      "[69, 300] current loss: 2.460011775970459\n",
      "[69, 400] current loss: 2.4598492450714113\n",
      "[69, 500] current loss: 2.4474649066925047\n",
      "[69, 600] current loss: 2.4571688690185547\n",
      "[69, 700] current loss: 2.467074764251709\n",
      "[69, 800] current loss: 2.445598880767822\n",
      "[69, 900] current loss: 2.460583335876465\n",
      "[69, 1000] current loss: 2.454241781234741\n",
      "[69, 1100] current loss: 2.461408000946045\n",
      "[69, 1200] current loss: 2.462251834869385\n",
      "[69, 1300] current loss: 2.4597866859436035\n",
      "[69, 1400] current loss: 2.4602062301635743\n",
      "[69, 1500] current loss: 2.461018814086914\n",
      "[69, 1600] current loss: 2.461074209213257\n",
      "[69, 1700] current loss: 2.4479500408172608\n",
      "[69, 1800] current loss: 2.462158315658569\n",
      "Accuracy of T-shirt/top : 84 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 78 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 100] current loss: 2.454943073272705\n",
      "[70, 200] current loss: 2.4510443382263185\n",
      "[70, 300] current loss: 2.4624567832946775\n",
      "[70, 400] current loss: 2.465932975769043\n",
      "[70, 500] current loss: 2.455185308456421\n",
      "[70, 600] current loss: 2.462803876876831\n",
      "[70, 700] current loss: 2.4691564960479737\n",
      "[70, 800] current loss: 2.4459658069610595\n",
      "[70, 900] current loss: 2.4599032649993897\n",
      "[70, 1000] current loss: 2.449139591217041\n",
      "[70, 1100] current loss: 2.447434341430664\n",
      "[70, 1200] current loss: 2.4542954998016357\n",
      "[70, 1300] current loss: 2.4574238681793212\n",
      "[70, 1400] current loss: 2.4511428489685056\n",
      "[70, 1500] current loss: 2.461562433242798\n",
      "[70, 1600] current loss: 2.4508761024475096\n",
      "[70, 1700] current loss: 2.4595620937347413\n",
      "[70, 1800] current loss: 2.4619265747070314\n",
      "Accuracy of T-shirt/top : 85 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 85 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 89 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.80833333333334\n",
      "[71, 100] current loss: 2.4544127941131593\n",
      "[71, 200] current loss: 2.4562601890563966\n",
      "[71, 300] current loss: 2.450662271499634\n",
      "[71, 400] current loss: 2.4698215103149415\n",
      "[71, 500] current loss: 2.4572757568359376\n",
      "[71, 600] current loss: 2.4541042442321777\n",
      "[71, 700] current loss: 2.4668151302337646\n",
      "[71, 800] current loss: 2.4414853076934815\n",
      "[71, 900] current loss: 2.4636065979003905\n",
      "[71, 1000] current loss: 2.4534373569488523\n",
      "[71, 1100] current loss: 2.45287228012085\n",
      "[71, 1200] current loss: 2.451156162261963\n",
      "[71, 1300] current loss: 2.4545816955566404\n",
      "[71, 1400] current loss: 2.453565870285034\n",
      "[71, 1500] current loss: 2.4672557430267332\n",
      "[71, 1600] current loss: 2.461350877761841\n",
      "[71, 1700] current loss: 2.466083787918091\n",
      "[71, 1800] current loss: 2.4647782154083253\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 80 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.11000000000001\n",
      "[72, 100] current loss: 2.456520263671875\n",
      "[72, 200] current loss: 2.4411510639190674\n",
      "[72, 300] current loss: 2.4467528839111328\n",
      "[72, 400] current loss: 2.467629949569702\n",
      "[72, 500] current loss: 2.458018154144287\n",
      "[72, 600] current loss: 2.4588623962402343\n",
      "[72, 700] current loss: 2.4698227882385253\n",
      "[72, 800] current loss: 2.4447300395965574\n",
      "[72, 900] current loss: 2.46274621963501\n",
      "[72, 1000] current loss: 2.457315195083618\n",
      "[72, 1100] current loss: 2.4525625953674317\n",
      "[72, 1200] current loss: 2.467493570327759\n",
      "[72, 1300] current loss: 2.4615922794342042\n",
      "[72, 1400] current loss: 2.4538838367462157\n",
      "[72, 1500] current loss: 2.4599285202026366\n",
      "[72, 1600] current loss: 2.4591758422851564\n",
      "[72, 1700] current loss: 2.461897918701172\n",
      "[72, 1800] current loss: 2.462658479690552\n",
      "Accuracy of T-shirt/top : 72 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 71 %\n",
      "Accuracy of Dress : 86 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 89.85\n",
      "[73, 100] current loss: 2.4636580028533936\n",
      "[73, 200] current loss: 2.4455653018951415\n",
      "[73, 300] current loss: 2.451620611190796\n",
      "[73, 400] current loss: 2.4614209365844726\n",
      "[73, 500] current loss: 2.4519416236877443\n",
      "[73, 600] current loss: 2.458342741012573\n",
      "[73, 700] current loss: 2.4642056694030763\n",
      "[73, 800] current loss: 2.444287733078003\n",
      "[73, 900] current loss: 2.4675706272125244\n",
      "[73, 1000] current loss: 2.4493314228057863\n",
      "[73, 1100] current loss: 2.4593838176727294\n",
      "[73, 1200] current loss: 2.4595403137207033\n",
      "[73, 1300] current loss: 2.4566373081207273\n",
      "[73, 1400] current loss: 2.4505405979156496\n",
      "[73, 1500] current loss: 2.4601689453125\n",
      "[73, 1600] current loss: 2.4525603885650633\n",
      "[73, 1700] current loss: 2.4492715339660647\n",
      "[73, 1800] current loss: 2.4586520767211915\n",
      "Accuracy of T-shirt/top : 81 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.385\n",
      "[74, 100] current loss: 2.4509521789550783\n",
      "[74, 200] current loss: 2.440263933181763\n",
      "[74, 300] current loss: 2.446311954498291\n",
      "[74, 400] current loss: 2.4692587776184083\n",
      "[74, 500] current loss: 2.4433908672332763\n",
      "[74, 600] current loss: 2.4533960933685304\n",
      "[74, 700] current loss: 2.469643724441528\n",
      "[74, 800] current loss: 2.4413299140930174\n",
      "[74, 900] current loss: 2.461578290939331\n",
      "[74, 1000] current loss: 2.4565251960754395\n",
      "[74, 1100] current loss: 2.4523957233428955\n",
      "[74, 1200] current loss: 2.4501870136260986\n",
      "[74, 1300] current loss: 2.4559677238464355\n",
      "[74, 1400] current loss: 2.450541425704956\n",
      "[74, 1500] current loss: 2.459783983230591\n",
      "[74, 1600] current loss: 2.4565896339416504\n",
      "[74, 1700] current loss: 2.453377202987671\n",
      "[74, 1800] current loss: 2.4515345993041993\n",
      "Accuracy of T-shirt/top : 84 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 78 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.91666666666669\n",
      "[75, 100] current loss: 2.4587432899475097\n",
      "[75, 200] current loss: 2.4389088401794434\n",
      "[75, 300] current loss: 2.452737121582031\n",
      "[75, 400] current loss: 2.4630963230133056\n",
      "[75, 500] current loss: 2.4591255741119387\n",
      "[75, 600] current loss: 2.458794303894043\n",
      "[75, 700] current loss: 2.4585042839050293\n",
      "[75, 800] current loss: 2.436630624771118\n",
      "[75, 900] current loss: 2.461534481048584\n",
      "[75, 1000] current loss: 2.4533751010894775\n",
      "[75, 1100] current loss: 2.4470909538269043\n",
      "[75, 1200] current loss: 2.4547096366882326\n",
      "[75, 1300] current loss: 2.458880725860596\n",
      "[75, 1400] current loss: 2.4555321998596193\n",
      "[75, 1500] current loss: 2.468302547454834\n",
      "[75, 1600] current loss: 2.4598832149505614\n",
      "[75, 1700] current loss: 2.4538867835998537\n",
      "[75, 1800] current loss: 2.454584390640259\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.62166666666667\n",
      "[76, 100] current loss: 2.456306583404541\n",
      "[76, 200] current loss: 2.4414831504821777\n",
      "[76, 300] current loss: 2.4615440654754637\n",
      "[76, 400] current loss: 2.45889107131958\n",
      "[76, 500] current loss: 2.449746078491211\n",
      "[76, 600] current loss: 2.4568198223114015\n",
      "[76, 700] current loss: 2.458547842025757\n",
      "[76, 800] current loss: 2.43961505317688\n",
      "[76, 900] current loss: 2.471188013076782\n",
      "[76, 1000] current loss: 2.448484004974365\n",
      "[76, 1100] current loss: 2.451864650726318\n",
      "[76, 1200] current loss: 2.4483235607147216\n",
      "[76, 1300] current loss: 2.4550150833129885\n",
      "[76, 1400] current loss: 2.450592403411865\n",
      "[76, 1500] current loss: 2.4534694004058837\n",
      "[76, 1600] current loss: 2.451181604385376\n",
      "[76, 1700] current loss: 2.4502511558532714\n",
      "[76, 1800] current loss: 2.450770362854004\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 80 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 79 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.07333333333335\n",
      "[77, 100] current loss: 2.459868268966675\n",
      "[77, 200] current loss: 2.4393291416168212\n",
      "[77, 300] current loss: 2.4534126625061035\n",
      "[77, 400] current loss: 2.4529787788391113\n",
      "[77, 500] current loss: 2.4491951084136963\n",
      "[77, 600] current loss: 2.451413116455078\n",
      "[77, 700] current loss: 2.456867914199829\n",
      "[77, 800] current loss: 2.4348027172088624\n",
      "[77, 900] current loss: 2.4649548606872558\n",
      "[77, 1000] current loss: 2.446315813064575\n",
      "[77, 1100] current loss: 2.439583574295044\n",
      "[77, 1200] current loss: 2.4521648807525636\n",
      "[77, 1300] current loss: 2.4515563583374025\n",
      "[77, 1400] current loss: 2.4439123458862304\n",
      "[77, 1500] current loss: 2.454882879257202\n",
      "[77, 1600] current loss: 2.4499048576354983\n",
      "[77, 1700] current loss: 2.4441070766448973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77, 1800] current loss: 2.4502538013458253\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.86500000000001\n",
      "[78, 100] current loss: 2.4525357723236083\n",
      "[78, 200] current loss: 2.4391383934020996\n",
      "[78, 300] current loss: 2.4452090187072755\n",
      "[78, 400] current loss: 2.4589978828430175\n",
      "[78, 500] current loss: 2.453696855545044\n",
      "[78, 600] current loss: 2.4575404472351075\n",
      "[78, 700] current loss: 2.4502628917694094\n",
      "[78, 800] current loss: 2.4288469123840333\n",
      "[78, 900] current loss: 2.4622512435913086\n",
      "[78, 1000] current loss: 2.4549062690734864\n",
      "[78, 1100] current loss: 2.4503672542572024\n",
      "[78, 1200] current loss: 2.4431342849731443\n",
      "[78, 1300] current loss: 2.453248208999634\n",
      "[78, 1400] current loss: 2.4439783592224122\n",
      "[78, 1500] current loss: 2.459282018661499\n",
      "[78, 1600] current loss: 2.448208299636841\n",
      "[78, 1700] current loss: 2.4534802799224855\n",
      "[78, 1800] current loss: 2.459652862548828\n",
      "Accuracy of T-shirt/top : 84 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.75499999999998\n",
      "[79, 100] current loss: 2.4507523517608645\n",
      "[79, 200] current loss: 2.4399533824920656\n",
      "[79, 300] current loss: 2.4417271709442137\n",
      "[79, 400] current loss: 2.4532297897338866\n",
      "[79, 500] current loss: 2.4426376190185546\n",
      "[79, 600] current loss: 2.4481049270629884\n",
      "[79, 700] current loss: 2.458138343811035\n",
      "[79, 800] current loss: 2.4334097747802734\n",
      "[79, 900] current loss: 2.463913143157959\n",
      "[79, 1000] current loss: 2.4504879875183105\n",
      "[79, 1100] current loss: 2.44782297706604\n",
      "[79, 1200] current loss: 2.445348148345947\n",
      "[79, 1300] current loss: 2.456974025726318\n",
      "[79, 1400] current loss: 2.4436601810455323\n",
      "[79, 1500] current loss: 2.4570593395233153\n",
      "[79, 1600] current loss: 2.4523469581604003\n",
      "[79, 1700] current loss: 2.4506764221191406\n",
      "[79, 1800] current loss: 2.450376667022705\n",
      "Accuracy of T-shirt/top : 84 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 97 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.79000000000002\n",
      "[80, 100] current loss: 2.4512822971343993\n",
      "[80, 200] current loss: 2.441163619995117\n",
      "[80, 300] current loss: 2.4439275398254394\n",
      "[80, 400] current loss: 2.4565375175476074\n",
      "[80, 500] current loss: 2.448440507888794\n",
      "[80, 600] current loss: 2.456177183151245\n",
      "[80, 700] current loss: 2.4593817691802977\n",
      "[80, 800] current loss: 2.443732141494751\n",
      "[80, 900] current loss: 2.458982885360718\n",
      "[80, 1000] current loss: 2.451245044708252\n",
      "[80, 1100] current loss: 2.445689769744873\n",
      "[80, 1200] current loss: 2.443544542312622\n",
      "[80, 1300] current loss: 2.448921241760254\n",
      "[80, 1400] current loss: 2.4587743225097656\n",
      "[80, 1500] current loss: 2.4630327529907228\n",
      "[80, 1600] current loss: 2.457024730682373\n",
      "[80, 1700] current loss: 2.4533956069946288\n",
      "[80, 1800] current loss: 2.4520770702362062\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.34833333333333\n",
      "[81, 100] current loss: 2.4532052001953124\n",
      "[81, 200] current loss: 2.447374845504761\n",
      "[81, 300] current loss: 2.4446917476654053\n",
      "[81, 400] current loss: 2.4580182762145997\n",
      "[81, 500] current loss: 2.447393579483032\n",
      "[81, 600] current loss: 2.4455322437286378\n",
      "[81, 700] current loss: 2.4600215435028074\n",
      "[81, 800] current loss: 2.4356667289733887\n",
      "[81, 900] current loss: 2.474185489654541\n",
      "[81, 1000] current loss: 2.4516307678222655\n",
      "[81, 1100] current loss: 2.4485141067504883\n",
      "[81, 1200] current loss: 2.4536061267852785\n",
      "[81, 1300] current loss: 2.455667154312134\n",
      "[81, 1400] current loss: 2.445625587463379\n",
      "[81, 1500] current loss: 2.4538014011383056\n",
      "[81, 1600] current loss: 2.446808151245117\n",
      "[81, 1700] current loss: 2.4484844245910646\n",
      "[81, 1800] current loss: 2.451443685531616\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 92.81333333333335\n",
      "[82, 100] current loss: 2.444399839401245\n",
      "[82, 200] current loss: 2.442336681365967\n",
      "[82, 300] current loss: 2.4523544006347655\n",
      "[82, 400] current loss: 2.450894521713257\n",
      "[82, 500] current loss: 2.4474546756744386\n",
      "[82, 600] current loss: 2.452369800567627\n",
      "[82, 700] current loss: 2.45210359954834\n",
      "[82, 800] current loss: 2.4487994976043703\n",
      "[82, 900] current loss: 2.465726579666138\n",
      "[82, 1000] current loss: 2.447414072036743\n",
      "[82, 1100] current loss: 2.443689655303955\n",
      "[82, 1200] current loss: 2.452070978164673\n",
      "[82, 1300] current loss: 2.4592749614715577\n",
      "[82, 1400] current loss: 2.4501216049194334\n",
      "[82, 1500] current loss: 2.4563535900115965\n",
      "[82, 1600] current loss: 2.449352128982544\n",
      "[82, 1700] current loss: 2.4569559288024903\n",
      "[82, 1800] current loss: 2.459037673950195\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.89000000000001\n",
      "[83, 100] current loss: 2.4519384765625\n",
      "[83, 200] current loss: 2.446512954711914\n",
      "[83, 300] current loss: 2.4532730331420898\n",
      "[83, 400] current loss: 2.4556106204986574\n",
      "[83, 500] current loss: 2.4449038715362548\n",
      "[83, 600] current loss: 2.44999547958374\n",
      "[83, 700] current loss: 2.45373681640625\n",
      "[83, 800] current loss: 2.43329575920105\n",
      "[83, 900] current loss: 2.4674152336120607\n",
      "[83, 1000] current loss: 2.451019323348999\n",
      "[83, 1100] current loss: 2.4495373249053953\n",
      "[83, 1200] current loss: 2.44781925201416\n",
      "[83, 1300] current loss: 2.454357744216919\n",
      "[83, 1400] current loss: 2.4425578384399413\n",
      "[83, 1500] current loss: 2.4587979221343996\n",
      "[83, 1600] current loss: 2.45270721244812\n",
      "[83, 1700] current loss: 2.4491340751647948\n",
      "[83, 1800] current loss: 2.4498881340026855\n",
      "Accuracy of T-shirt/top : 85 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.99666666666666\n",
      "[84, 100] current loss: 2.4491108837127684\n",
      "[84, 200] current loss: 2.441567741394043\n",
      "[84, 300] current loss: 2.4438568534851073\n",
      "[84, 400] current loss: 2.4602950019836425\n",
      "[84, 500] current loss: 2.451801233291626\n",
      "[84, 600] current loss: 2.459714096069336\n",
      "[84, 700] current loss: 2.454270017623901\n",
      "[84, 800] current loss: 2.444080738067627\n",
      "[84, 900] current loss: 2.470620475769043\n",
      "[84, 1000] current loss: 2.4476324367523192\n",
      "[84, 1100] current loss: 2.4436417255401612\n",
      "[84, 1200] current loss: 2.4485227489471435\n",
      "[84, 1300] current loss: 2.4536033000946045\n",
      "[84, 1400] current loss: 2.4445396194458007\n",
      "[84, 1500] current loss: 2.4635759296417237\n",
      "[84, 1600] current loss: 2.4509328575134277\n",
      "[84, 1700] current loss: 2.449157516479492\n",
      "[84, 1800] current loss: 2.451665563583374\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 79 %\n",
      "Accuracy of Sneaker : 88 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 92.205\n",
      "[85, 100] current loss: 2.447836696624756\n",
      "[85, 200] current loss: 2.4457868690490723\n",
      "[85, 300] current loss: 2.4512992324829104\n",
      "[85, 400] current loss: 2.4659327182769775\n",
      "[85, 500] current loss: 2.44223934173584\n",
      "[85, 600] current loss: 2.452290159225464\n",
      "[85, 700] current loss: 2.4519349365234375\n",
      "[85, 800] current loss: 2.431664125442505\n",
      "[85, 900] current loss: 2.4560843696594237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85, 1000] current loss: 2.4464872856140136\n",
      "[85, 1100] current loss: 2.4452988548278807\n",
      "[85, 1200] current loss: 2.4530609092712403\n",
      "[85, 1300] current loss: 2.4611892776489257\n",
      "[85, 1400] current loss: 2.4532717151641847\n",
      "[85, 1500] current loss: 2.4493024616241454\n",
      "[85, 1600] current loss: 2.442504333496094\n",
      "[85, 1700] current loss: 2.4472731018066405\n",
      "[85, 1800] current loss: 2.450369619369507\n",
      "Accuracy of T-shirt/top : 84 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.685\n",
      "[86, 100] current loss: 2.446425682067871\n",
      "[86, 200] current loss: 2.4447530574798586\n",
      "[86, 300] current loss: 2.4477428131103514\n",
      "[86, 400] current loss: 2.458946813583374\n",
      "[86, 500] current loss: 2.4527954864501953\n",
      "[86, 600] current loss: 2.4575974159240723\n",
      "[86, 700] current loss: 2.453677635192871\n",
      "[86, 800] current loss: 2.4347668209075928\n",
      "[86, 900] current loss: 2.445247220993042\n",
      "[86, 1000] current loss: 2.4400943431854247\n",
      "[86, 1100] current loss: 2.445827117919922\n",
      "[86, 1200] current loss: 2.445310230255127\n",
      "[86, 1300] current loss: 2.453052417755127\n",
      "[86, 1400] current loss: 2.45276598739624\n",
      "[86, 1500] current loss: 2.456352970123291\n",
      "[86, 1600] current loss: 2.446781847000122\n",
      "[86, 1700] current loss: 2.4453985900878905\n",
      "[86, 1800] current loss: 2.4569845390319824\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.655\n",
      "[87, 100] current loss: 2.4458984413146974\n",
      "[87, 200] current loss: 2.450925971984863\n",
      "[87, 300] current loss: 2.4506119136810303\n",
      "[87, 400] current loss: 2.4576442317962646\n",
      "[87, 500] current loss: 2.4483170738220217\n",
      "[87, 600] current loss: 2.4447704238891603\n",
      "[87, 700] current loss: 2.4523437728881836\n",
      "[87, 800] current loss: 2.4495286140441896\n",
      "[87, 900] current loss: 2.457633146286011\n",
      "[87, 1000] current loss: 2.4472917556762694\n",
      "[87, 1100] current loss: 2.4414075622558595\n",
      "[87, 1200] current loss: 2.443341541290283\n",
      "[87, 1300] current loss: 2.462976503372192\n",
      "[87, 1400] current loss: 2.446261510848999\n",
      "[87, 1500] current loss: 2.462215585708618\n",
      "[87, 1600] current loss: 2.4426937351226807\n",
      "[87, 1700] current loss: 2.445739694595337\n",
      "[87, 1800] current loss: 2.4512073822021483\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 82 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.71166666666667\n",
      "[88, 100] current loss: 2.4496328048706055\n",
      "[88, 200] current loss: 2.437974090576172\n",
      "[88, 300] current loss: 2.4374217071533204\n",
      "[88, 400] current loss: 2.4486371917724608\n",
      "[88, 500] current loss: 2.445634490966797\n",
      "[88, 600] current loss: 2.445803663253784\n",
      "[88, 700] current loss: 2.4518277797698973\n",
      "[88, 800] current loss: 2.4386459045410156\n",
      "[88, 900] current loss: 2.4484229431152342\n",
      "[88, 1000] current loss: 2.448228666305542\n",
      "[88, 1100] current loss: 2.4294029178619385\n",
      "[88, 1200] current loss: 2.439991590499878\n",
      "[88, 1300] current loss: 2.4456207599639894\n",
      "[88, 1400] current loss: 2.4496819763183595\n",
      "[88, 1500] current loss: 2.4463574504852295\n",
      "[88, 1600] current loss: 2.447438888549805\n",
      "[88, 1700] current loss: 2.4425518798828123\n",
      "[88, 1800] current loss: 2.446914514541626\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.03999999999999\n",
      "[89, 100] current loss: 2.4433629741668703\n",
      "[89, 200] current loss: 2.4265246257781983\n",
      "[89, 300] current loss: 2.438669403076172\n",
      "[89, 400] current loss: 2.4532169742584227\n",
      "[89, 500] current loss: 2.443365550994873\n",
      "[89, 600] current loss: 2.450478239059448\n",
      "[89, 700] current loss: 2.4520262355804445\n",
      "[89, 800] current loss: 2.4338564376831053\n",
      "[89, 900] current loss: 2.4604948978424073\n",
      "[89, 1000] current loss: 2.43664306640625\n",
      "[89, 1100] current loss: 2.439893102645874\n",
      "[89, 1200] current loss: 2.44427087020874\n",
      "[89, 1300] current loss: 2.4552385807037354\n",
      "[89, 1400] current loss: 2.4386232261657717\n",
      "[89, 1500] current loss: 2.4546291847229003\n",
      "[89, 1600] current loss: 2.4459776611328126\n",
      "[89, 1700] current loss: 2.446696947097778\n",
      "[89, 1800] current loss: 2.4488058071136476\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 80 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 74 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 91.41833333333334\n",
      "[90, 100] current loss: 2.450249767303467\n",
      "[90, 200] current loss: 2.4366433963775633\n",
      "[90, 300] current loss: 2.4400315704345705\n",
      "[90, 400] current loss: 2.4514508304595948\n",
      "[90, 500] current loss: 2.4394547595977785\n",
      "[90, 600] current loss: 2.4569327354431154\n",
      "[90, 700] current loss: 2.4586368713378906\n",
      "[90, 800] current loss: 2.438688882827759\n",
      "[90, 900] current loss: 2.4466803150177\n",
      "[90, 1000] current loss: 2.4393201560974123\n",
      "[90, 1100] current loss: 2.4377801551818847\n",
      "[90, 1200] current loss: 2.443534404754639\n",
      "[90, 1300] current loss: 2.459162502288818\n",
      "[90, 1400] current loss: 2.4434449672698975\n",
      "[90, 1500] current loss: 2.454375581741333\n",
      "[90, 1600] current loss: 2.4421630210876466\n",
      "[90, 1700] current loss: 2.441721824645996\n",
      "[90, 1800] current loss: 2.4557130908966065\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 82 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 79 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.41333333333334\n",
      "[91, 100] current loss: 2.454251998901367\n",
      "[91, 200] current loss: 2.4412964782714845\n",
      "[91, 300] current loss: 2.442490036010742\n",
      "[91, 400] current loss: 2.457681451797485\n",
      "[91, 500] current loss: 2.4419001579284667\n",
      "[91, 600] current loss: 2.4589459228515627\n",
      "[91, 700] current loss: 2.448216613769531\n",
      "[91, 800] current loss: 2.4370796546936035\n",
      "[91, 900] current loss: 2.463013555526733\n",
      "[91, 1000] current loss: 2.4362744808197023\n",
      "[91, 1100] current loss: 2.442687952041626\n",
      "[91, 1200] current loss: 2.4437316761016845\n",
      "[91, 1300] current loss: 2.4515342292785642\n",
      "[91, 1400] current loss: 2.4414007034301757\n",
      "[91, 1500] current loss: 2.4507447605133055\n",
      "[91, 1600] current loss: 2.4407743892669678\n",
      "[91, 1700] current loss: 2.4444485874176025\n",
      "[91, 1800] current loss: 2.4452294502258303\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 85 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.53166666666667\n",
      "[92, 100] current loss: 2.4398159561157224\n",
      "[92, 200] current loss: 2.4428772621154784\n",
      "[92, 300] current loss: 2.445051778793335\n",
      "[92, 400] current loss: 2.454804946899414\n",
      "[92, 500] current loss: 2.446904335021973\n",
      "[92, 600] current loss: 2.4471970920562742\n",
      "[92, 700] current loss: 2.450010280609131\n",
      "[92, 800] current loss: 2.4386974143981934\n",
      "[92, 900] current loss: 2.464058156967163\n",
      "[92, 1000] current loss: 2.450857608795166\n",
      "[92, 1100] current loss: 2.4422240657806396\n",
      "[92, 1200] current loss: 2.4414805335998535\n",
      "[92, 1300] current loss: 2.44653959274292\n",
      "[92, 1400] current loss: 2.4384191646575926\n",
      "[92, 1500] current loss: 2.4589223117828367\n",
      "[92, 1600] current loss: 2.4401590003967284\n",
      "[92, 1700] current loss: 2.4413787879943847\n",
      "[92, 1800] current loss: 2.4399500122070314\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 92 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 93.00833333333333\n",
      "[93, 100] current loss: 2.4391823768615724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93, 200] current loss: 2.43220440864563\n",
      "[93, 300] current loss: 2.444489305496216\n",
      "[93, 400] current loss: 2.4424703731536863\n",
      "[93, 500] current loss: 2.4453017864227293\n",
      "[93, 600] current loss: 2.4476150665283205\n",
      "[93, 700] current loss: 2.451904676437378\n",
      "[93, 800] current loss: 2.434182674407959\n",
      "[93, 900] current loss: 2.45557389831543\n",
      "[93, 1000] current loss: 2.4498700752258302\n",
      "[93, 1100] current loss: 2.4412988929748534\n",
      "[93, 1200] current loss: 2.437079116821289\n",
      "[93, 1300] current loss: 2.449709861755371\n",
      "[93, 1400] current loss: 2.4393539962768553\n",
      "[93, 1500] current loss: 2.4469223461151124\n",
      "[93, 1600] current loss: 2.4427703304290773\n",
      "[93, 1700] current loss: 2.4457980098724366\n",
      "[93, 1800] current loss: 2.4485173530578614\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 79 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.65833333333333\n",
      "[94, 100] current loss: 2.44156516456604\n",
      "[94, 200] current loss: 2.431977773666382\n",
      "[94, 300] current loss: 2.4414475650787355\n",
      "[94, 400] current loss: 2.4467832069396973\n",
      "[94, 500] current loss: 2.439086669921875\n",
      "[94, 600] current loss: 2.4454914836883543\n",
      "[94, 700] current loss: 2.445191064834595\n",
      "[94, 800] current loss: 2.4320320205688475\n",
      "[94, 900] current loss: 2.4498774261474607\n",
      "[94, 1000] current loss: 2.4400122680664063\n",
      "[94, 1100] current loss: 2.439283973693848\n",
      "[94, 1200] current loss: 2.4434604167938234\n",
      "[94, 1300] current loss: 2.437972436904907\n",
      "[94, 1400] current loss: 2.443453233718872\n",
      "[94, 1500] current loss: 2.443618350982666\n",
      "[94, 1600] current loss: 2.4476140308380128\n",
      "[94, 1700] current loss: 2.4435288810729983\n",
      "[94, 1800] current loss: 2.4435260372161864\n",
      "Accuracy of T-shirt/top : 83 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 78 %\n",
      "Accuracy of Sneaker : 90 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 92.09666666666666\n",
      "[95, 100] current loss: 2.4458757915496827\n",
      "[95, 200] current loss: 2.430660264968872\n",
      "[95, 300] current loss: 2.440461959838867\n",
      "[95, 400] current loss: 2.447027521133423\n",
      "[95, 500] current loss: 2.4391065578460696\n",
      "[95, 600] current loss: 2.4558368759155274\n",
      "[95, 700] current loss: 2.4542225303649903\n",
      "[95, 800] current loss: 2.4294573554992676\n",
      "[95, 900] current loss: 2.4597795448303224\n",
      "[95, 1000] current loss: 2.451036417007446\n",
      "[95, 1100] current loss: 2.4424448585510254\n",
      "[95, 1200] current loss: 2.440986337661743\n",
      "[95, 1300] current loss: 2.4469508304595946\n",
      "[95, 1400] current loss: 2.434992341995239\n",
      "[95, 1500] current loss: 2.448903554916382\n",
      "[95, 1600] current loss: 2.442524007797241\n",
      "[95, 1700] current loss: 2.443268548965454\n",
      "[95, 1800] current loss: 2.4409290027618407\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.02333333333334\n",
      "[96, 100] current loss: 2.4338464221954346\n",
      "[96, 200] current loss: 2.4283693199157717\n",
      "[96, 300] current loss: 2.434225769042969\n",
      "[96, 400] current loss: 2.452817808151245\n",
      "[96, 500] current loss: 2.4414593811035155\n",
      "[96, 600] current loss: 2.447943542480469\n",
      "[96, 700] current loss: 2.4402280197143553\n",
      "[96, 800] current loss: 2.4308434276580813\n",
      "[96, 900] current loss: 2.451823501586914\n",
      "[96, 1000] current loss: 2.4402839069366453\n",
      "[96, 1100] current loss: 2.441621068954468\n",
      "[96, 1200] current loss: 2.4448594055175783\n",
      "[96, 1300] current loss: 2.442098289489746\n",
      "[96, 1400] current loss: 2.4439814910888673\n",
      "[96, 1500] current loss: 2.4476651134490965\n",
      "[96, 1600] current loss: 2.441471639633179\n",
      "[96, 1700] current loss: 2.4431882915496828\n",
      "[96, 1800] current loss: 2.442020357131958\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 96 %\n",
      "overall: 93.76666666666668\n",
      "[97, 100] current loss: 2.438559944152832\n",
      "[97, 200] current loss: 2.432966556549072\n",
      "[97, 300] current loss: 2.432858636856079\n",
      "[97, 400] current loss: 2.44018320274353\n",
      "[97, 500] current loss: 2.4458953094482423\n",
      "[97, 600] current loss: 2.4482282142639162\n",
      "[97, 700] current loss: 2.4392108573913576\n",
      "[97, 800] current loss: 2.4326501865386962\n",
      "[97, 900] current loss: 2.455602031707764\n",
      "[97, 1000] current loss: 2.440283136367798\n",
      "[97, 1100] current loss: 2.441634546279907\n",
      "[97, 1200] current loss: 2.437729955673218\n",
      "[97, 1300] current loss: 2.4472541332244875\n",
      "[97, 1400] current loss: 2.441765060424805\n",
      "[97, 1500] current loss: 2.443720579147339\n",
      "[97, 1600] current loss: 2.440995431900024\n",
      "[97, 1700] current loss: 2.4433663940429686\n",
      "[97, 1800] current loss: 2.4443923206329345\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.91333333333333\n",
      "[98, 100] current loss: 2.4420825672149657\n",
      "[98, 200] current loss: 2.4315238132476806\n",
      "[98, 300] current loss: 2.441901054382324\n",
      "[98, 400] current loss: 2.4484885063171387\n",
      "[98, 500] current loss: 2.436890836715698\n",
      "[98, 600] current loss: 2.441139991760254\n",
      "[98, 700] current loss: 2.4498938217163087\n",
      "[98, 800] current loss: 2.425133909225464\n",
      "[98, 900] current loss: 2.455311902999878\n",
      "[98, 1000] current loss: 2.435998489379883\n",
      "[98, 1100] current loss: 2.4337576427459715\n",
      "[98, 1200] current loss: 2.4451711254119872\n",
      "[98, 1300] current loss: 2.4569215278625487\n",
      "[98, 1400] current loss: 2.449489559173584\n",
      "[98, 1500] current loss: 2.4401234970092776\n",
      "[98, 1600] current loss: 2.4434738426208495\n",
      "[98, 1700] current loss: 2.443046842575073\n",
      "[98, 1800] current loss: 2.4413453006744383\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.20333333333335\n",
      "[99, 100] current loss: 2.439897048950195\n",
      "[99, 200] current loss: 2.4337553272247314\n",
      "[99, 300] current loss: 2.440627456665039\n",
      "[99, 400] current loss: 2.443288728713989\n",
      "[99, 500] current loss: 2.4359250717163086\n",
      "[99, 600] current loss: 2.440853456497192\n",
      "[99, 700] current loss: 2.4388572006225586\n",
      "[99, 800] current loss: 2.428814956665039\n",
      "[99, 900] current loss: 2.448797794342041\n",
      "[99, 1000] current loss: 2.437638311386108\n",
      "[99, 1100] current loss: 2.43403387260437\n",
      "[99, 1200] current loss: 2.433895273208618\n",
      "[99, 1300] current loss: 2.4431755924224854\n",
      "[99, 1400] current loss: 2.436572467803955\n",
      "[99, 1500] current loss: 2.454740243911743\n",
      "[99, 1600] current loss: 2.4441319332122804\n",
      "[99, 1700] current loss: 2.443863437652588\n",
      "[99, 1800] current loss: 2.4466243171691895\n",
      "Accuracy of T-shirt/top : 79 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 73 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 94 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.7\n",
      "[100, 100] current loss: 2.4450903358459475\n",
      "[100, 200] current loss: 2.432577154159546\n",
      "[100, 300] current loss: 2.4359385604858397\n",
      "[100, 400] current loss: 2.453221784591675\n",
      "[100, 500] current loss: 2.4431495323181154\n",
      "[100, 600] current loss: 2.449914894104004\n",
      "[100, 700] current loss: 2.4420667991638183\n",
      "[100, 800] current loss: 2.4310800647735595\n",
      "[100, 900] current loss: 2.4414086303710936\n",
      "[100, 1000] current loss: 2.438751226425171\n",
      "[100, 1100] current loss: 2.435317401885986\n",
      "[100, 1200] current loss: 2.437016839981079\n",
      "[100, 1300] current loss: 2.4472991752624513\n",
      "[100, 1400] current loss: 2.439522735595703\n",
      "[100, 1500] current loss: 2.4552553367614744\n",
      "[100, 1600] current loss: 2.4376049194335936\n",
      "[100, 1700] current loss: 2.448039686203003\n",
      "[100, 1800] current loss: 2.4494053058624266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.78\n",
      "[101, 100] current loss: 2.441931116104126\n",
      "[101, 200] current loss: 2.4374158973693847\n",
      "[101, 300] current loss: 2.4450397415161134\n",
      "[101, 400] current loss: 2.436819236755371\n",
      "[101, 500] current loss: 2.4396005401611327\n",
      "[101, 600] current loss: 2.452257583618164\n",
      "[101, 700] current loss: 2.4440186729431153\n",
      "[101, 800] current loss: 2.433298728942871\n",
      "[101, 900] current loss: 2.447680725097656\n",
      "[101, 1000] current loss: 2.433166751861572\n",
      "[101, 1100] current loss: 2.4306820182800295\n",
      "[101, 1200] current loss: 2.4408822212219237\n",
      "[101, 1300] current loss: 2.445207145690918\n",
      "[101, 1400] current loss: 2.4372177505493164\n",
      "[101, 1500] current loss: 2.4432100563049315\n",
      "[101, 1600] current loss: 2.4375281467437744\n",
      "[101, 1700] current loss: 2.4409508266448974\n",
      "[101, 1800] current loss: 2.442047046661377\n",
      "Accuracy of T-shirt/top : 84 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.38\n",
      "[102, 100] current loss: 2.444559595108032\n",
      "[102, 200] current loss: 2.431495147705078\n",
      "[102, 300] current loss: 2.4366496601104735\n",
      "[102, 400] current loss: 2.4539401893615724\n",
      "[102, 500] current loss: 2.4336182136535642\n",
      "[102, 600] current loss: 2.447716064453125\n",
      "[102, 700] current loss: 2.4394638442993166\n",
      "[102, 800] current loss: 2.4260609512329103\n",
      "[102, 900] current loss: 2.4564711418151854\n",
      "[102, 1000] current loss: 2.433664304733276\n",
      "[102, 1100] current loss: 2.442443857192993\n",
      "[102, 1200] current loss: 2.4432493991851807\n",
      "[102, 1300] current loss: 2.4449754962921144\n",
      "[102, 1400] current loss: 2.4423962478637695\n",
      "[102, 1500] current loss: 2.442537281036377\n",
      "[102, 1600] current loss: 2.435340898513794\n",
      "[102, 1700] current loss: 2.4395013542175294\n",
      "[102, 1800] current loss: 2.437536376953125\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 97 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.44333333333334\n",
      "[103, 100] current loss: 2.4392034606933595\n",
      "[103, 200] current loss: 2.428203004837036\n",
      "[103, 300] current loss: 2.438393123626709\n",
      "[103, 400] current loss: 2.434023536682129\n",
      "[103, 500] current loss: 2.4417704067230224\n",
      "[103, 600] current loss: 2.444421249389648\n",
      "[103, 700] current loss: 2.4444235687255857\n",
      "[103, 800] current loss: 2.4306743717193604\n",
      "[103, 900] current loss: 2.4488421173095705\n",
      "[103, 1000] current loss: 2.4378593044281005\n",
      "[103, 1100] current loss: 2.4289480876922607\n",
      "[103, 1200] current loss: 2.4357383403778075\n",
      "[103, 1300] current loss: 2.44577059173584\n",
      "[103, 1400] current loss: 2.4381276874542235\n",
      "[103, 1500] current loss: 2.4391459407806395\n",
      "[103, 1600] current loss: 2.436386535644531\n",
      "[103, 1700] current loss: 2.4404021492004393\n",
      "[103, 1800] current loss: 2.4409174041748045\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.90833333333333\n",
      "[104, 100] current loss: 2.4380460166931153\n",
      "[104, 200] current loss: 2.432301284790039\n",
      "[104, 300] current loss: 2.439934417724609\n",
      "[104, 400] current loss: 2.440446178436279\n",
      "[104, 500] current loss: 2.4431039810180666\n",
      "[104, 600] current loss: 2.4424361553192138\n",
      "[104, 700] current loss: 2.4434616050720215\n",
      "[104, 800] current loss: 2.4346466217041014\n",
      "[104, 900] current loss: 2.449723472595215\n",
      "[104, 1000] current loss: 2.43080620765686\n",
      "[104, 1100] current loss: 2.433656755447388\n",
      "[104, 1200] current loss: 2.4420947074890136\n",
      "[104, 1300] current loss: 2.443815341949463\n",
      "[104, 1400] current loss: 2.444214630126953\n",
      "[104, 1500] current loss: 2.4551814708709716\n",
      "[104, 1600] current loss: 2.4440196895599366\n",
      "[104, 1700] current loss: 2.4410403690338134\n",
      "[104, 1800] current loss: 2.4429241428375246\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 94 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 76 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.66000000000001\n",
      "[105, 100] current loss: 2.4438968544006348\n",
      "[105, 200] current loss: 2.430143701553345\n",
      "[105, 300] current loss: 2.4363634738922118\n",
      "[105, 400] current loss: 2.450760934829712\n",
      "[105, 500] current loss: 2.439259843826294\n",
      "[105, 600] current loss: 2.4480396556854247\n",
      "[105, 700] current loss: 2.4433579559326173\n",
      "[105, 800] current loss: 2.420960735321045\n",
      "[105, 900] current loss: 2.449050491333008\n",
      "[105, 1000] current loss: 2.4402146110534666\n",
      "[105, 1100] current loss: 2.434542785644531\n",
      "[105, 1200] current loss: 2.4431993160247805\n",
      "[105, 1300] current loss: 2.4443605365753176\n",
      "[105, 1400] current loss: 2.438567588806152\n",
      "[105, 1500] current loss: 2.4469701461791993\n",
      "[105, 1600] current loss: 2.4419111385345458\n",
      "[105, 1700] current loss: 2.443056182861328\n",
      "[105, 1800] current loss: 2.456051239013672\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.70833333333333\n",
      "[106, 100] current loss: 2.4432388401031493\n",
      "[106, 200] current loss: 2.4266157436370848\n",
      "[106, 300] current loss: 2.4320915222167967\n",
      "[106, 400] current loss: 2.4407021675109863\n",
      "[106, 500] current loss: 2.4402394275665285\n",
      "[106, 600] current loss: 2.441266353607178\n",
      "[106, 700] current loss: 2.4365272941589358\n",
      "[106, 800] current loss: 2.4181918869018553\n",
      "[106, 900] current loss: 2.4612979717254637\n",
      "[106, 1000] current loss: 2.4327142868041993\n",
      "[106, 1100] current loss: 2.434406270980835\n",
      "[106, 1200] current loss: 2.439038263320923\n",
      "[106, 1300] current loss: 2.4413524322509765\n",
      "[106, 1400] current loss: 2.4347640724182127\n",
      "[106, 1500] current loss: 2.44514988899231\n",
      "[106, 1600] current loss: 2.4347655220031736\n",
      "[106, 1700] current loss: 2.4385422954559326\n",
      "[106, 1800] current loss: 2.446346471786499\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 85 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.01833333333335\n",
      "[107, 100] current loss: 2.433655656814575\n",
      "[107, 200] current loss: 2.4279970016479493\n",
      "[107, 300] current loss: 2.4377724266052248\n",
      "[107, 400] current loss: 2.438560850143433\n",
      "[107, 500] current loss: 2.4360106410980227\n",
      "[107, 600] current loss: 2.4523418083190918\n",
      "[107, 700] current loss: 2.451651294708252\n",
      "[107, 800] current loss: 2.449431568145752\n",
      "[107, 900] current loss: 2.451150968551636\n",
      "[107, 1000] current loss: 2.43028325843811\n",
      "[107, 1100] current loss: 2.4389753284454345\n",
      "[107, 1200] current loss: 2.433293279647827\n",
      "[107, 1300] current loss: 2.441845712661743\n",
      "[107, 1400] current loss: 2.43692663192749\n",
      "[107, 1500] current loss: 2.4424672832489014\n",
      "[107, 1600] current loss: 2.441501138687134\n",
      "[107, 1700] current loss: 2.4452708415985107\n",
      "[107, 1800] current loss: 2.4461127014160158\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 76 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.83833333333332\n",
      "[108, 100] current loss: 2.4354684066772463\n",
      "[108, 200] current loss: 2.429407989501953\n",
      "[108, 300] current loss: 2.4370087261199953\n",
      "[108, 400] current loss: 2.4391205043792725\n",
      "[108, 500] current loss: 2.4318942584991454\n",
      "[108, 600] current loss: 2.442115804672241\n",
      "[108, 700] current loss: 2.4397134380340577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108, 800] current loss: 2.4259109230041505\n",
      "[108, 900] current loss: 2.4492082767486574\n",
      "[108, 1000] current loss: 2.427159429550171\n",
      "[108, 1100] current loss: 2.4278797073364258\n",
      "[108, 1200] current loss: 2.433200584411621\n",
      "[108, 1300] current loss: 2.440592134475708\n",
      "[108, 1400] current loss: 2.4406412982940675\n",
      "[108, 1500] current loss: 2.4494130764007567\n",
      "[108, 1600] current loss: 2.4316168937683105\n",
      "[108, 1700] current loss: 2.4399297275543215\n",
      "[108, 1800] current loss: 2.4399423389434816\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 83 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 92 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 92.835\n",
      "[109, 100] current loss: 2.4422347812652587\n",
      "[109, 200] current loss: 2.4343378047943114\n",
      "[109, 300] current loss: 2.4402200374603273\n",
      "[109, 400] current loss: 2.4423024253845216\n",
      "[109, 500] current loss: 2.4330311622619627\n",
      "[109, 600] current loss: 2.4333789749145507\n",
      "[109, 700] current loss: 2.437120973587036\n",
      "[109, 800] current loss: 2.4279433689117433\n",
      "[109, 900] current loss: 2.454232992172241\n",
      "[109, 1000] current loss: 2.4380456886291504\n",
      "[109, 1100] current loss: 2.434192195892334\n",
      "[109, 1200] current loss: 2.435913974761963\n",
      "[109, 1300] current loss: 2.437223575592041\n",
      "[109, 1400] current loss: 2.436697980880737\n",
      "[109, 1500] current loss: 2.449672073364258\n",
      "[109, 1600] current loss: 2.4372942810058595\n",
      "[109, 1700] current loss: 2.4373048877716066\n",
      "[109, 1800] current loss: 2.4494401741027834\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.98333333333333\n",
      "[110, 100] current loss: 2.4337820224761963\n",
      "[110, 200] current loss: 2.4239531536102294\n",
      "[110, 300] current loss: 2.4466710700988767\n",
      "[110, 400] current loss: 2.43683327293396\n",
      "[110, 500] current loss: 2.435688323974609\n",
      "[110, 600] current loss: 2.441577814102173\n",
      "[110, 700] current loss: 2.4447060680389403\n",
      "[110, 800] current loss: 2.424481634140015\n",
      "[110, 900] current loss: 2.4486063022613527\n",
      "[110, 1000] current loss: 2.4304021644592284\n",
      "[110, 1100] current loss: 2.4360077896118164\n",
      "[110, 1200] current loss: 2.429580181121826\n",
      "[110, 1300] current loss: 2.4524033966064454\n",
      "[110, 1400] current loss: 2.4447532787323\n",
      "[110, 1500] current loss: 2.443768856048584\n",
      "[110, 1600] current loss: 2.4342767906188967\n",
      "[110, 1700] current loss: 2.4361562671661376\n",
      "[110, 1800] current loss: 2.443586862564087\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 85 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 79 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.95666666666668\n",
      "[111, 100] current loss: 2.4390406131744387\n",
      "[111, 200] current loss: 2.425977544784546\n",
      "[111, 300] current loss: 2.4327849826812744\n",
      "[111, 400] current loss: 2.4451927185058593\n",
      "[111, 500] current loss: 2.4357390518188478\n",
      "[111, 600] current loss: 2.4481097106933594\n",
      "[111, 700] current loss: 2.440468189239502\n",
      "[111, 800] current loss: 2.4272270374298097\n",
      "[111, 900] current loss: 2.4532337265014648\n",
      "[111, 1000] current loss: 2.4307386741638184\n",
      "[111, 1100] current loss: 2.4320305709838865\n",
      "[111, 1200] current loss: 2.4364338130950927\n",
      "[111, 1300] current loss: 2.4469150009155274\n",
      "[111, 1400] current loss: 2.4355567893981935\n",
      "[111, 1500] current loss: 2.444436891555786\n",
      "[111, 1600] current loss: 2.4378910465240478\n",
      "[111, 1700] current loss: 2.4373740921020506\n",
      "[111, 1800] current loss: 2.4483005065917967\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.73\n",
      "[112, 100] current loss: 2.4392831497192384\n",
      "[112, 200] current loss: 2.430322744369507\n",
      "[112, 300] current loss: 2.435285249710083\n",
      "[112, 400] current loss: 2.435223762512207\n",
      "[112, 500] current loss: 2.4292572784423827\n",
      "[112, 600] current loss: 2.440087600708008\n",
      "[112, 700] current loss: 2.4332676982879637\n",
      "[112, 800] current loss: 2.4300728874206543\n",
      "[112, 900] current loss: 2.4431839408874514\n",
      "[112, 1000] current loss: 2.427409086227417\n",
      "[112, 1100] current loss: 2.4274682273864747\n",
      "[112, 1200] current loss: 2.4291428813934326\n",
      "[112, 1300] current loss: 2.441532217025757\n",
      "[112, 1400] current loss: 2.4296117458343507\n",
      "[112, 1500] current loss: 2.438954683303833\n",
      "[112, 1600] current loss: 2.4290740547180176\n",
      "[112, 1700] current loss: 2.4471361141204833\n",
      "[112, 1800] current loss: 2.445938673019409\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.82833333333333\n",
      "[113, 100] current loss: 2.4362305088043215\n",
      "[113, 200] current loss: 2.422196491241455\n",
      "[113, 300] current loss: 2.4318246459960937\n",
      "[113, 400] current loss: 2.4447482318878175\n",
      "[113, 500] current loss: 2.4326177673339844\n",
      "[113, 600] current loss: 2.457423000335693\n",
      "[113, 700] current loss: 2.440705629348755\n",
      "[113, 800] current loss: 2.4192438926696775\n",
      "[113, 900] current loss: 2.4414746379852295\n",
      "[113, 1000] current loss: 2.4250802249908445\n",
      "[113, 1100] current loss: 2.4264326171875\n",
      "[113, 1200] current loss: 2.4403197536468504\n",
      "[113, 1300] current loss: 2.441135763168335\n",
      "[113, 1400] current loss: 2.429634313583374\n",
      "[113, 1500] current loss: 2.433322052001953\n",
      "[113, 1600] current loss: 2.4434323749542237\n",
      "[113, 1700] current loss: 2.436386152267456\n",
      "[113, 1800] current loss: 2.4357738399505617\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.27666666666667\n",
      "[114, 100] current loss: 2.4373937606811524\n",
      "[114, 200] current loss: 2.4172919006347655\n",
      "[114, 300] current loss: 2.437442180633545\n",
      "[114, 400] current loss: 2.435809274673462\n",
      "[114, 500] current loss: 2.4297650394439696\n",
      "[114, 600] current loss: 2.436611135482788\n",
      "[114, 700] current loss: 2.4332191829681395\n",
      "[114, 800] current loss: 2.4177362613677977\n",
      "[114, 900] current loss: 2.4443582820892336\n",
      "[114, 1000] current loss: 2.4277155017852783\n",
      "[114, 1100] current loss: 2.4243607501983644\n",
      "[114, 1200] current loss: 2.4236002464294435\n",
      "[114, 1300] current loss: 2.4384863739013674\n",
      "[114, 1400] current loss: 2.434044481277466\n",
      "[114, 1500] current loss: 2.4355535659790037\n",
      "[114, 1600] current loss: 2.4356946392059324\n",
      "[114, 1700] current loss: 2.43565354347229\n",
      "[114, 1800] current loss: 2.43581707572937\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.1\n",
      "[115, 100] current loss: 2.430969867706299\n",
      "[115, 200] current loss: 2.4206781921386717\n",
      "[115, 300] current loss: 2.424668476104736\n",
      "[115, 400] current loss: 2.433452266693115\n",
      "[115, 500] current loss: 2.430172327041626\n",
      "[115, 600] current loss: 2.4345764827728273\n",
      "[115, 700] current loss: 2.4342670974731444\n",
      "[115, 800] current loss: 2.415210277557373\n",
      "[115, 900] current loss: 2.4459559707641603\n",
      "[115, 1000] current loss: 2.4282571125030517\n",
      "[115, 1100] current loss: 2.428649784088135\n",
      "[115, 1200] current loss: 2.426068037033081\n",
      "[115, 1300] current loss: 2.439439260482788\n",
      "[115, 1400] current loss: 2.436698133468628\n",
      "[115, 1500] current loss: 2.44355233001709\n",
      "[115, 1600] current loss: 2.431887327194214\n",
      "[115, 1700] current loss: 2.4480747833251955\n",
      "[115, 1800] current loss: 2.4391562366485595\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.17999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116, 100] current loss: 2.433004165649414\n",
      "[116, 200] current loss: 2.426183687210083\n",
      "[116, 300] current loss: 2.436092237472534\n",
      "[116, 400] current loss: 2.4496903438568114\n",
      "[116, 500] current loss: 2.433829458236694\n",
      "[116, 600] current loss: 2.4421546840667725\n",
      "[116, 700] current loss: 2.4349038791656494\n",
      "[116, 800] current loss: 2.4206441402435304\n",
      "[116, 900] current loss: 2.440851854324341\n",
      "[116, 1000] current loss: 2.433756898880005\n",
      "[116, 1100] current loss: 2.4284433212280274\n",
      "[116, 1200] current loss: 2.4349303932189943\n",
      "[116, 1300] current loss: 2.443963514328003\n",
      "[116, 1400] current loss: 2.4375094661712646\n",
      "[116, 1500] current loss: 2.4360342140197755\n",
      "[116, 1600] current loss: 2.4255715885162354\n",
      "[116, 1700] current loss: 2.4401098461151123\n",
      "[116, 1800] current loss: 2.445454698562622\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.83666666666666\n",
      "[117, 100] current loss: 2.434728853225708\n",
      "[117, 200] current loss: 2.4261802253723146\n",
      "[117, 300] current loss: 2.4294530754089356\n",
      "[117, 400] current loss: 2.44696688079834\n",
      "[117, 500] current loss: 2.447469757080078\n",
      "[117, 600] current loss: 2.4534900417327883\n",
      "[117, 700] current loss: 2.4326281242370604\n",
      "[117, 800] current loss: 2.4195082569122315\n",
      "[117, 900] current loss: 2.4438169651031494\n",
      "[117, 1000] current loss: 2.4252791938781737\n",
      "[117, 1100] current loss: 2.432628438949585\n",
      "[117, 1200] current loss: 2.4349339179992677\n",
      "[117, 1300] current loss: 2.442796070098877\n",
      "[117, 1400] current loss: 2.4306715755462647\n",
      "[117, 1500] current loss: 2.4389052047729494\n",
      "[117, 1600] current loss: 2.4382516593933103\n",
      "[117, 1700] current loss: 2.4373926105499266\n",
      "[117, 1800] current loss: 2.4410312213897707\n",
      "Accuracy of T-shirt/top : 83 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.00666666666666\n",
      "[118, 100] current loss: 2.430753782272339\n",
      "[118, 200] current loss: 2.431322383880615\n",
      "[118, 300] current loss: 2.432966941833496\n",
      "[118, 400] current loss: 2.4364804344177244\n",
      "[118, 500] current loss: 2.422336269378662\n",
      "[118, 600] current loss: 2.4373629550933837\n",
      "[118, 700] current loss: 2.428545419692993\n",
      "[118, 800] current loss: 2.417162601470947\n",
      "[118, 900] current loss: 2.4485104331970216\n",
      "[118, 1000] current loss: 2.4249857902526855\n",
      "[118, 1100] current loss: 2.4248479843139648\n",
      "[118, 1200] current loss: 2.427780611038208\n",
      "[118, 1300] current loss: 2.4418883113861085\n",
      "[118, 1400] current loss: 2.4376286945343018\n",
      "[118, 1500] current loss: 2.447743169784546\n",
      "[118, 1600] current loss: 2.4343041572570803\n",
      "[118, 1700] current loss: 2.4339642391204834\n",
      "[118, 1800] current loss: 2.4313380908966065\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 84 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 88 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 92.62666666666667\n",
      "[119, 100] current loss: 2.4317247734069825\n",
      "[119, 200] current loss: 2.4244071083068848\n",
      "[119, 300] current loss: 2.427421775817871\n",
      "[119, 400] current loss: 2.4403708782196043\n",
      "[119, 500] current loss: 2.4316653804779054\n",
      "[119, 600] current loss: 2.4417299003601074\n",
      "[119, 700] current loss: 2.4358799667358397\n",
      "[119, 800] current loss: 2.4274541149139406\n",
      "[119, 900] current loss: 2.4488689002990722\n",
      "[119, 1000] current loss: 2.4308127250671387\n",
      "[119, 1100] current loss: 2.428201097488403\n",
      "[119, 1200] current loss: 2.4359034385681153\n",
      "[119, 1300] current loss: 2.435860851287842\n",
      "[119, 1400] current loss: 2.426987371444702\n",
      "[119, 1500] current loss: 2.438876745223999\n",
      "[119, 1600] current loss: 2.431953214645386\n",
      "[119, 1700] current loss: 2.44374808883667\n",
      "[119, 1800] current loss: 2.440505977630615\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.535\n",
      "[120, 100] current loss: 2.434057424545288\n",
      "[120, 200] current loss: 2.423298837661743\n",
      "[120, 300] current loss: 2.4318679008483888\n",
      "[120, 400] current loss: 2.4377151660919187\n",
      "[120, 500] current loss: 2.4273524017333985\n",
      "[120, 600] current loss: 2.437220504760742\n",
      "[120, 700] current loss: 2.427013463973999\n",
      "[120, 800] current loss: 2.418974641799927\n",
      "[120, 900] current loss: 2.4401170673370363\n",
      "[120, 1000] current loss: 2.418347724914551\n",
      "[120, 1100] current loss: 2.42920871925354\n",
      "[120, 1200] current loss: 2.4251384143829346\n",
      "[120, 1300] current loss: 2.438833604812622\n",
      "[120, 1400] current loss: 2.4271428871154783\n",
      "[120, 1500] current loss: 2.441056631088257\n",
      "[120, 1600] current loss: 2.421901615142822\n",
      "[120, 1700] current loss: 2.4332528228759767\n",
      "[120, 1800] current loss: 2.4371787281036377\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.225\n",
      "[121, 100] current loss: 2.4273464660644533\n",
      "[121, 200] current loss: 2.4198384628295897\n",
      "[121, 300] current loss: 2.4291082363128664\n",
      "[121, 400] current loss: 2.441083616256714\n",
      "[121, 500] current loss: 2.436513189315796\n",
      "[121, 600] current loss: 2.4469958839416504\n",
      "[121, 700] current loss: 2.428432870864868\n",
      "[121, 800] current loss: 2.4197460861206053\n",
      "[121, 900] current loss: 2.4398217487335203\n",
      "[121, 1000] current loss: 2.415353006362915\n",
      "[121, 1100] current loss: 2.4212917346954344\n",
      "[121, 1200] current loss: 2.425328876495361\n",
      "[121, 1300] current loss: 2.4386329307556154\n",
      "[121, 1400] current loss: 2.429238338470459\n",
      "[121, 1500] current loss: 2.432434415817261\n",
      "[121, 1600] current loss: 2.4226625022888184\n",
      "[121, 1700] current loss: 2.4279095973968507\n",
      "[121, 1800] current loss: 2.432206428527832\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.715\n",
      "[122, 100] current loss: 2.4241968154907227\n",
      "[122, 200] current loss: 2.4208513755798338\n",
      "[122, 300] current loss: 2.4260706272125243\n",
      "[122, 400] current loss: 2.4315225830078124\n",
      "[122, 500] current loss: 2.430654733657837\n",
      "[122, 600] current loss: 2.4349752655029295\n",
      "[122, 700] current loss: 2.427252521514893\n",
      "[122, 800] current loss: 2.4164782276153565\n",
      "[122, 900] current loss: 2.447377292633057\n",
      "[122, 1000] current loss: 2.4250425167083742\n",
      "[122, 1100] current loss: 2.432381965637207\n",
      "[122, 1200] current loss: 2.426273002624512\n",
      "[122, 1300] current loss: 2.441516275405884\n",
      "[122, 1400] current loss: 2.432193214416504\n",
      "[122, 1500] current loss: 2.43866237449646\n",
      "[122, 1600] current loss: 2.4257395458221436\n",
      "[122, 1700] current loss: 2.4386798667907716\n",
      "[122, 1800] current loss: 2.4367058391571046\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 92.85833333333333\n",
      "[123, 100] current loss: 2.4436371154785155\n",
      "[123, 200] current loss: 2.4265368576049804\n",
      "[123, 300] current loss: 2.433010862350464\n",
      "[123, 400] current loss: 2.4324168128967285\n",
      "[123, 500] current loss: 2.4333035945892334\n",
      "[123, 600] current loss: 2.444401575088501\n",
      "[123, 700] current loss: 2.4426177482604983\n",
      "[123, 800] current loss: 2.422325162887573\n",
      "[123, 900] current loss: 2.4503627128601075\n",
      "[123, 1000] current loss: 2.4225290851593018\n",
      "[123, 1100] current loss: 2.429274524688721\n",
      "[123, 1200] current loss: 2.4283378505706787\n",
      "[123, 1300] current loss: 2.441637990951538\n",
      "[123, 1400] current loss: 2.4312402305603027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 1500] current loss: 2.439060541152954\n",
      "[123, 1600] current loss: 2.4359295864105226\n",
      "[123, 1700] current loss: 2.4375214614868166\n",
      "[123, 1800] current loss: 2.4411227645874023\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 76 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.59333333333333\n",
      "[124, 100] current loss: 2.4339791145324705\n",
      "[124, 200] current loss: 2.4196729640960695\n",
      "[124, 300] current loss: 2.429593900680542\n",
      "[124, 400] current loss: 2.4390655460357666\n",
      "[124, 500] current loss: 2.430178804397583\n",
      "[124, 600] current loss: 2.435759620666504\n",
      "[124, 700] current loss: 2.426652843475342\n",
      "[124, 800] current loss: 2.417581926345825\n",
      "[124, 900] current loss: 2.437754039764404\n",
      "[124, 1000] current loss: 2.4194041213989257\n",
      "[124, 1100] current loss: 2.4311829090118406\n",
      "[124, 1200] current loss: 2.4281484336853025\n",
      "[124, 1300] current loss: 2.4400191764831543\n",
      "[124, 1400] current loss: 2.428414665222168\n",
      "[124, 1500] current loss: 2.4284980907440183\n",
      "[124, 1600] current loss: 2.429450386047363\n",
      "[124, 1700] current loss: 2.43545791053772\n",
      "[124, 1800] current loss: 2.4313285541534424\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 92 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.54499999999999\n",
      "[125, 100] current loss: 2.4429522533416748\n",
      "[125, 200] current loss: 2.4203099060058593\n",
      "[125, 300] current loss: 2.423307056427002\n",
      "[125, 400] current loss: 2.4342287940979004\n",
      "[125, 500] current loss: 2.4295556926727295\n",
      "[125, 600] current loss: 2.441358381271362\n",
      "[125, 700] current loss: 2.43264102935791\n",
      "[125, 800] current loss: 2.424977378845215\n",
      "[125, 900] current loss: 2.4485001144409178\n",
      "[125, 1000] current loss: 2.4161293144226073\n",
      "[125, 1100] current loss: 2.4315755729675295\n",
      "[125, 1200] current loss: 2.426472106933594\n",
      "[125, 1300] current loss: 2.438741044998169\n",
      "[125, 1400] current loss: 2.4330132579803467\n",
      "[125, 1500] current loss: 2.44423211479187\n",
      "[125, 1600] current loss: 2.4331506958007814\n",
      "[125, 1700] current loss: 2.433315456390381\n",
      "[125, 1800] current loss: 2.4349221172332762\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.19000000000001\n",
      "[126, 100] current loss: 2.4278841552734374\n",
      "[126, 200] current loss: 2.422197607040405\n",
      "[126, 300] current loss: 2.426754148483276\n",
      "[126, 400] current loss: 2.4387570610046385\n",
      "[126, 500] current loss: 2.44396283531189\n",
      "[126, 600] current loss: 2.443631450653076\n",
      "[126, 700] current loss: 2.4307617359161378\n",
      "[126, 800] current loss: 2.4181047592163085\n",
      "[126, 900] current loss: 2.437665424346924\n",
      "[126, 1000] current loss: 2.4312365837097167\n",
      "[126, 1100] current loss: 2.4242781982421877\n",
      "[126, 1200] current loss: 2.4368811225891114\n",
      "[126, 1300] current loss: 2.4388024444580076\n",
      "[126, 1400] current loss: 2.428540515899658\n",
      "[126, 1500] current loss: 2.4428204021453856\n",
      "[126, 1600] current loss: 2.4339863414764404\n",
      "[126, 1700] current loss: 2.435046640396118\n",
      "[126, 1800] current loss: 2.452362474441528\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 93 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.47666666666667\n",
      "[127, 100] current loss: 2.4349702606201173\n",
      "[127, 200] current loss: 2.424251756668091\n",
      "[127, 300] current loss: 2.42649799156189\n",
      "[127, 400] current loss: 2.431828031539917\n",
      "[127, 500] current loss: 2.427573875427246\n",
      "[127, 600] current loss: 2.4407506465911863\n",
      "[127, 700] current loss: 2.4382233753204345\n",
      "[127, 800] current loss: 2.4241474266052245\n",
      "[127, 900] current loss: 2.440343538284302\n",
      "[127, 1000] current loss: 2.4266379375457765\n",
      "[127, 1100] current loss: 2.4279524364471436\n",
      "[127, 1200] current loss: 2.420675764083862\n",
      "[127, 1300] current loss: 2.433094924926758\n",
      "[127, 1400] current loss: 2.429967607498169\n",
      "[127, 1500] current loss: 2.446371747970581\n",
      "[127, 1600] current loss: 2.43171435546875\n",
      "[127, 1700] current loss: 2.4498279151916504\n",
      "[127, 1800] current loss: 2.441556306838989\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 91 %\n",
      "Accuracy of  Coat : 85 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.30833333333332\n",
      "[128, 100] current loss: 2.4384219970703125\n",
      "[128, 200] current loss: 2.424164939880371\n",
      "[128, 300] current loss: 2.4407441539764405\n",
      "[128, 400] current loss: 2.4374101219177247\n",
      "[128, 500] current loss: 2.437782207489014\n",
      "[128, 600] current loss: 2.444039867401123\n",
      "[128, 700] current loss: 2.4347649154663085\n",
      "[128, 800] current loss: 2.4193867130279543\n",
      "[128, 900] current loss: 2.4466422729492185\n",
      "[128, 1000] current loss: 2.4251044807434083\n",
      "[128, 1100] current loss: 2.4340241641998293\n",
      "[128, 1200] current loss: 2.4241744899749755\n",
      "[128, 1300] current loss: 2.440586528778076\n",
      "[128, 1400] current loss: 2.431683687210083\n",
      "[128, 1500] current loss: 2.441135499954224\n",
      "[128, 1600] current loss: 2.4289762115478517\n",
      "[128, 1700] current loss: 2.428852777481079\n",
      "[128, 1800] current loss: 2.4387145156860353\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.24499999999999\n",
      "[129, 100] current loss: 2.4271990928649902\n",
      "[129, 200] current loss: 2.4210860137939454\n",
      "[129, 300] current loss: 2.432493927001953\n",
      "[129, 400] current loss: 2.440674415588379\n",
      "[129, 500] current loss: 2.4395659885406493\n",
      "[129, 600] current loss: 2.436973663330078\n",
      "[129, 700] current loss: 2.431641010284424\n",
      "[129, 800] current loss: 2.4132655010223387\n",
      "[129, 900] current loss: 2.438870946884155\n",
      "[129, 1000] current loss: 2.4208155517578125\n",
      "[129, 1100] current loss: 2.426272497177124\n",
      "[129, 1200] current loss: 2.4339190158843995\n",
      "[129, 1300] current loss: 2.4418912048339845\n",
      "[129, 1400] current loss: 2.4323063278198243\n",
      "[129, 1500] current loss: 2.4353432559967043\n",
      "[129, 1600] current loss: 2.4256324653625487\n",
      "[129, 1700] current loss: 2.4303264522552492\n",
      "[129, 1800] current loss: 2.4384128341674804\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.445\n",
      "[130, 100] current loss: 2.4302374362945556\n",
      "[130, 200] current loss: 2.4229959411621094\n",
      "[130, 300] current loss: 2.4280931987762453\n",
      "[130, 400] current loss: 2.436554124832153\n",
      "[130, 500] current loss: 2.437111511230469\n",
      "[130, 600] current loss: 2.4319330501556395\n",
      "[130, 700] current loss: 2.4417355632781983\n",
      "[130, 800] current loss: 2.418875692367554\n",
      "[130, 900] current loss: 2.4419426460266114\n",
      "[130, 1000] current loss: 2.4223195934295654\n",
      "[130, 1100] current loss: 2.4281179237365724\n",
      "[130, 1200] current loss: 2.429059394836426\n",
      "[130, 1300] current loss: 2.4422531852722167\n",
      "[130, 1400] current loss: 2.438798511505127\n",
      "[130, 1500] current loss: 2.434780158996582\n",
      "[130, 1600] current loss: 2.424690891265869\n",
      "[130, 1700] current loss: 2.4304396743774412\n",
      "[130, 1800] current loss: 2.4330820598602294\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.13833333333335\n",
      "[131, 100] current loss: 2.4326372089385986\n",
      "[131, 200] current loss: 2.4186485939025877\n",
      "[131, 300] current loss: 2.4311218795776366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131, 400] current loss: 2.4301759300231933\n",
      "[131, 500] current loss: 2.4314431171417237\n",
      "[131, 600] current loss: 2.43108477973938\n",
      "[131, 700] current loss: 2.4283742446899415\n",
      "[131, 800] current loss: 2.405790107727051\n",
      "[131, 900] current loss: 2.4450028495788576\n",
      "[131, 1000] current loss: 2.419367820739746\n",
      "[131, 1100] current loss: 2.4221558837890624\n",
      "[131, 1200] current loss: 2.4277338428497313\n",
      "[131, 1300] current loss: 2.437973024368286\n",
      "[131, 1400] current loss: 2.428925489425659\n",
      "[131, 1500] current loss: 2.4412357597351075\n",
      "[131, 1600] current loss: 2.426287452697754\n",
      "[131, 1700] current loss: 2.4396491050720215\n",
      "[131, 1800] current loss: 2.4344838428497315\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.215\n",
      "[132, 100] current loss: 2.4274401206970215\n",
      "[132, 200] current loss: 2.4221494159698485\n",
      "[132, 300] current loss: 2.427546993255615\n",
      "[132, 400] current loss: 2.4323811321258546\n",
      "[132, 500] current loss: 2.432465467453003\n",
      "[132, 600] current loss: 2.4300908241271975\n",
      "[132, 700] current loss: 2.428023509979248\n",
      "[132, 800] current loss: 2.4069650115966796\n",
      "[132, 900] current loss: 2.4472649688720702\n",
      "[132, 1000] current loss: 2.432619258880615\n",
      "[132, 1100] current loss: 2.4175893135070803\n",
      "[132, 1200] current loss: 2.420737377166748\n",
      "[132, 1300] current loss: 2.4364114990234373\n",
      "[132, 1400] current loss: 2.428415491104126\n",
      "[132, 1500] current loss: 2.4363508110046386\n",
      "[132, 1600] current loss: 2.4261804904937745\n",
      "[132, 1700] current loss: 2.4247877407073974\n",
      "[132, 1800] current loss: 2.4342014808654784\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.18666666666667\n",
      "[133, 100] current loss: 2.4268960018157957\n",
      "[133, 200] current loss: 2.4174788970947265\n",
      "[133, 300] current loss: 2.42625980758667\n",
      "[133, 400] current loss: 2.4353991470336913\n",
      "[133, 500] current loss: 2.4294343643188476\n",
      "[133, 600] current loss: 2.429639705657959\n",
      "[133, 700] current loss: 2.4290597343444826\n",
      "[133, 800] current loss: 2.409201166152954\n",
      "[133, 900] current loss: 2.4329868392944336\n",
      "[133, 1000] current loss: 2.4162268924713133\n",
      "[133, 1100] current loss: 2.4216056289672854\n",
      "[133, 1200] current loss: 2.4282442569732665\n",
      "[133, 1300] current loss: 2.432259241104126\n",
      "[133, 1400] current loss: 2.4332523956298826\n",
      "[133, 1500] current loss: 2.4430672454833986\n",
      "[133, 1600] current loss: 2.4215122051239013\n",
      "[133, 1700] current loss: 2.4353957004547118\n",
      "[133, 1800] current loss: 2.4378207817077637\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.21833333333333\n",
      "[134, 100] current loss: 2.425500102996826\n",
      "[134, 200] current loss: 2.4218710746765137\n",
      "[134, 300] current loss: 2.4323799209594728\n",
      "[134, 400] current loss: 2.430644733428955\n",
      "[134, 500] current loss: 2.4299462871551514\n",
      "[134, 600] current loss: 2.435840663909912\n",
      "[134, 700] current loss: 2.4402855644226076\n",
      "[134, 800] current loss: 2.4250407047271727\n",
      "[134, 900] current loss: 2.4422070903778077\n",
      "[134, 1000] current loss: 2.414226516723633\n",
      "[134, 1100] current loss: 2.421625150680542\n",
      "[134, 1200] current loss: 2.4197231063842772\n",
      "[134, 1300] current loss: 2.4357566928863523\n",
      "[134, 1400] current loss: 2.4343132820129396\n",
      "[134, 1500] current loss: 2.4460744915008545\n",
      "[134, 1600] current loss: 2.4300905952453613\n",
      "[134, 1700] current loss: 2.423903217315674\n",
      "[134, 1800] current loss: 2.4361734085083007\n",
      "Accuracy of T-shirt/top : 85 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.77166666666668\n",
      "[135, 100] current loss: 2.4254335765838624\n",
      "[135, 200] current loss: 2.429914125442505\n",
      "[135, 300] current loss: 2.432478031158447\n",
      "[135, 400] current loss: 2.4373255882263183\n",
      "[135, 500] current loss: 2.4291304836273193\n",
      "[135, 600] current loss: 2.4421094131469725\n",
      "[135, 700] current loss: 2.4284431972503664\n",
      "[135, 800] current loss: 2.4141584949493406\n",
      "[135, 900] current loss: 2.440994905471802\n",
      "[135, 1000] current loss: 2.4276935634613035\n",
      "[135, 1100] current loss: 2.423665349960327\n",
      "[135, 1200] current loss: 2.424448455810547\n",
      "[135, 1300] current loss: 2.4378305015563964\n",
      "[135, 1400] current loss: 2.42637110710144\n",
      "[135, 1500] current loss: 2.4401805095672606\n",
      "[135, 1600] current loss: 2.4275793704986572\n",
      "[135, 1700] current loss: 2.436855932235718\n",
      "[135, 1800] current loss: 2.435987190246582\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.46333333333334\n",
      "[136, 100] current loss: 2.4319515686035156\n",
      "[136, 200] current loss: 2.4230015239715574\n",
      "[136, 300] current loss: 2.4347012023925783\n",
      "[136, 400] current loss: 2.438709671020508\n",
      "[136, 500] current loss: 2.4251508502960206\n",
      "[136, 600] current loss: 2.4357429523468017\n",
      "[136, 700] current loss: 2.432103925704956\n",
      "[136, 800] current loss: 2.422145528793335\n",
      "[136, 900] current loss: 2.4423599071502684\n",
      "[136, 1000] current loss: 2.4205579833984374\n",
      "[136, 1100] current loss: 2.427274164199829\n",
      "[136, 1200] current loss: 2.4237258701324462\n",
      "[136, 1300] current loss: 2.4331744289398194\n",
      "[136, 1400] current loss: 2.427871280670166\n",
      "[136, 1500] current loss: 2.4321316833496094\n",
      "[136, 1600] current loss: 2.4239452018737793\n",
      "[136, 1700] current loss: 2.4279073390960693\n",
      "[136, 1800] current loss: 2.4333648891448973\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.89000000000001\n",
      "[137, 100] current loss: 2.429188940048218\n",
      "[137, 200] current loss: 2.4230384540557863\n",
      "[137, 300] current loss: 2.429593698501587\n",
      "[137, 400] current loss: 2.4314923000335695\n",
      "[137, 500] current loss: 2.426560411453247\n",
      "[137, 600] current loss: 2.427302837371826\n",
      "[137, 700] current loss: 2.4294445877075197\n",
      "[137, 800] current loss: 2.409534185409546\n",
      "[137, 900] current loss: 2.4311794395446777\n",
      "[137, 1000] current loss: 2.422743722915649\n",
      "[137, 1100] current loss: 2.424618408203125\n",
      "[137, 1200] current loss: 2.416128974914551\n",
      "[137, 1300] current loss: 2.433304584503174\n",
      "[137, 1400] current loss: 2.42837406539917\n",
      "[137, 1500] current loss: 2.4290261001586915\n",
      "[137, 1600] current loss: 2.4225810146331788\n",
      "[137, 1700] current loss: 2.4388069553375242\n",
      "[137, 1800] current loss: 2.440031587600708\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 90 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.62333333333332\n",
      "[138, 100] current loss: 2.434624212265015\n",
      "[138, 200] current loss: 2.417033857345581\n",
      "[138, 300] current loss: 2.4250359172821043\n",
      "[138, 400] current loss: 2.432393877029419\n",
      "[138, 500] current loss: 2.434749523162842\n",
      "[138, 600] current loss: 2.4460409660339355\n",
      "[138, 700] current loss: 2.4306164989471437\n",
      "[138, 800] current loss: 2.4185500717163086\n",
      "[138, 900] current loss: 2.445315885543823\n",
      "[138, 1000] current loss: 2.421631000518799\n",
      "[138, 1100] current loss: 2.4219075603485107\n",
      "[138, 1200] current loss: 2.417788736343384\n",
      "[138, 1300] current loss: 2.4286441459655763\n",
      "[138, 1400] current loss: 2.424544506072998\n",
      "[138, 1500] current loss: 2.4388380088806154\n",
      "[138, 1600] current loss: 2.424907159805298\n",
      "[138, 1700] current loss: 2.4280310935974123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138, 1800] current loss: 2.441286376953125\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.39166666666665\n",
      "[139, 100] current loss: 2.428089309692383\n",
      "[139, 200] current loss: 2.4209617652893067\n",
      "[139, 300] current loss: 2.4268783798217775\n",
      "[139, 400] current loss: 2.4262772006988524\n",
      "[139, 500] current loss: 2.4233892555236816\n",
      "[139, 600] current loss: 2.429290355682373\n",
      "[139, 700] current loss: 2.426982116699219\n",
      "[139, 800] current loss: 2.41192271232605\n",
      "[139, 900] current loss: 2.4297790851593017\n",
      "[139, 1000] current loss: 2.4182961902618407\n",
      "[139, 1100] current loss: 2.418662057876587\n",
      "[139, 1200] current loss: 2.4256385555267332\n",
      "[139, 1300] current loss: 2.431547399520874\n",
      "[139, 1400] current loss: 2.4318925609588624\n",
      "[139, 1500] current loss: 2.4375475025177002\n",
      "[139, 1600] current loss: 2.42344402885437\n",
      "[139, 1700] current loss: 2.4369858112335203\n",
      "[139, 1800] current loss: 2.446770181655884\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 91 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.48333333333332\n",
      "[140, 100] current loss: 2.432873514175415\n",
      "[140, 200] current loss: 2.4157028751373293\n",
      "[140, 300] current loss: 2.432965021133423\n",
      "[140, 400] current loss: 2.437313217163086\n",
      "[140, 500] current loss: 2.432227123260498\n",
      "[140, 600] current loss: 2.4409764251708985\n",
      "[140, 700] current loss: 2.4295111083984375\n",
      "[140, 800] current loss: 2.413660228729248\n",
      "[140, 900] current loss: 2.435668050765991\n",
      "[140, 1000] current loss: 2.4201651725769042\n",
      "[140, 1100] current loss: 2.422174966812134\n",
      "[140, 1200] current loss: 2.4224454441070558\n",
      "[140, 1300] current loss: 2.439568111419678\n",
      "[140, 1400] current loss: 2.4264543018341063\n",
      "[140, 1500] current loss: 2.4294334716796877\n",
      "[140, 1600] current loss: 2.4214200420379637\n",
      "[140, 1700] current loss: 2.429902233123779\n",
      "[140, 1800] current loss: 2.433707124710083\n",
      "Accuracy of T-shirt/top : 86 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.17333333333333\n",
      "[141, 100] current loss: 2.4313497047424315\n",
      "[141, 200] current loss: 2.412574035644531\n",
      "[141, 300] current loss: 2.417634473800659\n",
      "[141, 400] current loss: 2.427725591659546\n",
      "[141, 500] current loss: 2.4242294921875\n",
      "[141, 600] current loss: 2.434186273574829\n",
      "[141, 700] current loss: 2.4273825187683107\n",
      "[141, 800] current loss: 2.407245193481445\n",
      "[141, 900] current loss: 2.4336028366088867\n",
      "[141, 1000] current loss: 2.415577096939087\n",
      "[141, 1100] current loss: 2.4244642276763915\n",
      "[141, 1200] current loss: 2.4173076934814453\n",
      "[141, 1300] current loss: 2.436952341079712\n",
      "[141, 1400] current loss: 2.425327365875244\n",
      "[141, 1500] current loss: 2.4322884120941164\n",
      "[141, 1600] current loss: 2.434294538497925\n",
      "[141, 1700] current loss: 2.4371750984191896\n",
      "[141, 1800] current loss: 2.4359394264221192\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 84 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.16833333333334\n",
      "[142, 100] current loss: 2.4273064575195313\n",
      "[142, 200] current loss: 2.420374881744385\n",
      "[142, 300] current loss: 2.4243519344329836\n",
      "[142, 400] current loss: 2.4373990726470947\n",
      "[142, 500] current loss: 2.4239031677246095\n",
      "[142, 600] current loss: 2.427390697479248\n",
      "[142, 700] current loss: 2.4264539699554444\n",
      "[142, 800] current loss: 2.4081736221313474\n",
      "[142, 900] current loss: 2.4376190433502196\n",
      "[142, 1000] current loss: 2.4238226737976074\n",
      "[142, 1100] current loss: 2.423284534454346\n",
      "[142, 1200] current loss: 2.415371608734131\n",
      "[142, 1300] current loss: 2.432195285797119\n",
      "[142, 1400] current loss: 2.4286483764648437\n",
      "[142, 1500] current loss: 2.438168035507202\n",
      "[142, 1600] current loss: 2.4254046211242675\n",
      "[142, 1700] current loss: 2.427432863235474\n",
      "[142, 1800] current loss: 2.430052635192871\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.45\n",
      "[143, 100] current loss: 2.43996205329895\n",
      "[143, 200] current loss: 2.4256058406829832\n",
      "[143, 300] current loss: 2.4257290534973146\n",
      "[143, 400] current loss: 2.4306819190979003\n",
      "[143, 500] current loss: 2.421382963180542\n",
      "[143, 600] current loss: 2.435955551147461\n",
      "[143, 700] current loss: 2.437950944900513\n",
      "[143, 800] current loss: 2.4123885612487794\n",
      "[143, 900] current loss: 2.440697822570801\n",
      "[143, 1000] current loss: 2.418332429885864\n",
      "[143, 1100] current loss: 2.419817684173584\n",
      "[143, 1200] current loss: 2.4206098728179932\n",
      "[143, 1300] current loss: 2.443146396636963\n",
      "[143, 1400] current loss: 2.424036277770996\n",
      "[143, 1500] current loss: 2.4366964473724364\n",
      "[143, 1600] current loss: 2.4236562690734864\n",
      "[143, 1700] current loss: 2.4311596546173098\n",
      "[143, 1800] current loss: 2.432091899871826\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 89 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 93.475\n",
      "[144, 100] current loss: 2.4286128368377686\n",
      "[144, 200] current loss: 2.4134426708221435\n",
      "[144, 300] current loss: 2.42563853263855\n",
      "[144, 400] current loss: 2.43195046043396\n",
      "[144, 500] current loss: 2.4284705486297606\n",
      "[144, 600] current loss: 2.4272645626068114\n",
      "[144, 700] current loss: 2.4271115131378176\n",
      "[144, 800] current loss: 2.4132304706573486\n",
      "[144, 900] current loss: 2.430226379394531\n",
      "[144, 1000] current loss: 2.420291187286377\n",
      "[144, 1100] current loss: 2.415619016647339\n",
      "[144, 1200] current loss: 2.4164832134246828\n",
      "[144, 1300] current loss: 2.4338629970550536\n",
      "[144, 1400] current loss: 2.4221715240478514\n",
      "[144, 1500] current loss: 2.4342044944763184\n",
      "[144, 1600] current loss: 2.421450273513794\n",
      "[144, 1700] current loss: 2.426745054244995\n",
      "[144, 1800] current loss: 2.4400759716033935\n",
      "Accuracy of T-shirt/top : 83 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 93 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.7\n",
      "[145, 100] current loss: 2.425620397567749\n",
      "[145, 200] current loss: 2.4168118324279786\n",
      "[145, 300] current loss: 2.4202691822052\n",
      "[145, 400] current loss: 2.4365783367156983\n",
      "[145, 500] current loss: 2.4269587421417236\n",
      "[145, 600] current loss: 2.4311761837005617\n",
      "[145, 700] current loss: 2.4280060482025148\n",
      "[145, 800] current loss: 2.410901948928833\n",
      "[145, 900] current loss: 2.4387594871520997\n",
      "[145, 1000] current loss: 2.42457905960083\n",
      "[145, 1100] current loss: 2.42601501083374\n",
      "[145, 1200] current loss: 2.420194358825684\n",
      "[145, 1300] current loss: 2.427794158935547\n",
      "[145, 1400] current loss: 2.4255764064788816\n",
      "[145, 1500] current loss: 2.4343709812164307\n",
      "[145, 1600] current loss: 2.4141641025543215\n",
      "[145, 1700] current loss: 2.4290700035095214\n",
      "[145, 1800] current loss: 2.4371788291931153\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 80 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.18\n",
      "[146, 100] current loss: 2.4286187286376952\n",
      "[146, 200] current loss: 2.4225710411071777\n",
      "[146, 300] current loss: 2.430622245788574\n",
      "[146, 400] current loss: 2.4314257736206053\n",
      "[146, 500] current loss: 2.4203087863922117\n",
      "[146, 600] current loss: 2.4317362842559813\n",
      "[146, 700] current loss: 2.4292951965332032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146, 800] current loss: 2.405878341674805\n",
      "[146, 900] current loss: 2.4367377223968507\n",
      "[146, 1000] current loss: 2.4202680854797363\n",
      "[146, 1100] current loss: 2.420906660079956\n",
      "[146, 1200] current loss: 2.433799310684204\n",
      "[146, 1300] current loss: 2.4394407367706297\n",
      "[146, 1400] current loss: 2.430228645324707\n",
      "[146, 1500] current loss: 2.4354123497009277\n",
      "[146, 1600] current loss: 2.425267889022827\n",
      "[146, 1700] current loss: 2.4283110332489013\n",
      "[146, 1800] current loss: 2.4299650840759277\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 81 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.50833333333334\n",
      "[147, 100] current loss: 2.427075532913208\n",
      "[147, 200] current loss: 2.4161518688201906\n",
      "[147, 300] current loss: 2.4199358978271484\n",
      "[147, 400] current loss: 2.443413297653198\n",
      "[147, 500] current loss: 2.4276652164459227\n",
      "[147, 600] current loss: 2.437770971298218\n",
      "[147, 700] current loss: 2.4293682880401613\n",
      "[147, 800] current loss: 2.409293365478516\n",
      "[147, 900] current loss: 2.434713291168213\n",
      "[147, 1000] current loss: 2.4167436771392823\n",
      "[147, 1100] current loss: 2.4182266941070556\n",
      "[147, 1200] current loss: 2.420300765991211\n",
      "[147, 1300] current loss: 2.4343371486663816\n",
      "[147, 1400] current loss: 2.422907207489014\n",
      "[147, 1500] current loss: 2.431887529373169\n",
      "[147, 1600] current loss: 2.422280620574951\n",
      "[147, 1700] current loss: 2.425922679901123\n",
      "[147, 1800] current loss: 2.428626977920532\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.95666666666666\n",
      "[148, 100] current loss: 2.416561918258667\n",
      "[148, 200] current loss: 2.414771839141846\n",
      "[148, 300] current loss: 2.4182057933807375\n",
      "[148, 400] current loss: 2.427107400894165\n",
      "[148, 500] current loss: 2.4220707817077636\n",
      "[148, 600] current loss: 2.438627679824829\n",
      "[148, 700] current loss: 2.4297020397186277\n",
      "[148, 800] current loss: 2.409971263885498\n",
      "[148, 900] current loss: 2.4337226638793945\n",
      "[148, 1000] current loss: 2.4166103496551514\n",
      "[148, 1100] current loss: 2.418054979324341\n",
      "[148, 1200] current loss: 2.4288564605712892\n",
      "[148, 1300] current loss: 2.4350085182189942\n",
      "[148, 1400] current loss: 2.4290889739990233\n",
      "[148, 1500] current loss: 2.437972246170044\n",
      "[148, 1600] current loss: 2.4223157711029053\n",
      "[148, 1700] current loss: 2.42702707862854\n",
      "[148, 1800] current loss: 2.4263322792053224\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.80833333333332\n",
      "[149, 100] current loss: 2.4193065319061278\n",
      "[149, 200] current loss: 2.4110874500274657\n",
      "[149, 300] current loss: 2.4203881435394288\n",
      "[149, 400] current loss: 2.4228395366668702\n",
      "[149, 500] current loss: 2.4270173416137695\n",
      "[149, 600] current loss: 2.4306132698059084\n",
      "[149, 700] current loss: 2.4215686740875246\n",
      "[149, 800] current loss: 2.414712968826294\n",
      "[149, 900] current loss: 2.4360012092590333\n",
      "[149, 1000] current loss: 2.424027572631836\n",
      "[149, 1100] current loss: 2.418410400390625\n",
      "[149, 1200] current loss: 2.4211573600769043\n",
      "[149, 1300] current loss: 2.4261561851501465\n",
      "[149, 1400] current loss: 2.418557611465454\n",
      "[149, 1500] current loss: 2.4374942111968996\n",
      "[149, 1600] current loss: 2.4208454189300537\n",
      "[149, 1700] current loss: 2.424252046585083\n",
      "[149, 1800] current loss: 2.4219455680847166\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.88166666666667\n",
      "[150, 100] current loss: 2.422314167022705\n",
      "[150, 200] current loss: 2.4110407485961916\n",
      "[150, 300] current loss: 2.4252229804992678\n",
      "[150, 400] current loss: 2.4260218772888185\n",
      "[150, 500] current loss: 2.42497806930542\n",
      "[150, 600] current loss: 2.4337238597869875\n",
      "[150, 700] current loss: 2.422155569076538\n",
      "[150, 800] current loss: 2.40455277633667\n",
      "[150, 900] current loss: 2.4310959434509276\n",
      "[150, 1000] current loss: 2.411676586151123\n",
      "[150, 1100] current loss: 2.4133432140350344\n",
      "[150, 1200] current loss: 2.422798370361328\n",
      "[150, 1300] current loss: 2.43103609085083\n",
      "[150, 1400] current loss: 2.421314661026001\n",
      "[150, 1500] current loss: 2.4359471645355226\n",
      "[150, 1600] current loss: 2.4254844589233397\n",
      "[150, 1700] current loss: 2.431956712722778\n",
      "[150, 1800] current loss: 2.4284900856018066\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 94.815\n",
      "[151, 100] current loss: 2.4272269611358643\n",
      "[151, 200] current loss: 2.4136513385772704\n",
      "[151, 300] current loss: 2.422611753463745\n",
      "[151, 400] current loss: 2.42582314491272\n",
      "[151, 500] current loss: 2.414319116592407\n",
      "[151, 600] current loss: 2.4306777515411375\n",
      "[151, 700] current loss: 2.421309034347534\n",
      "[151, 800] current loss: 2.4052706413269043\n",
      "[151, 900] current loss: 2.4290806941986083\n",
      "[151, 1000] current loss: 2.4187174377441405\n",
      "[151, 1100] current loss: 2.4255635814666747\n",
      "[151, 1200] current loss: 2.412492076873779\n",
      "[151, 1300] current loss: 2.4339525928497316\n",
      "[151, 1400] current loss: 2.427480121612549\n",
      "[151, 1500] current loss: 2.4430160732269286\n",
      "[151, 1600] current loss: 2.4250695781707763\n",
      "[151, 1700] current loss: 2.4413066806793213\n",
      "[151, 1800] current loss: 2.436485954284668\n",
      "Accuracy of T-shirt/top : 95 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 93 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 94.6\n",
      "[152, 100] current loss: 2.4193100757598875\n",
      "[152, 200] current loss: 2.4125518856048584\n",
      "[152, 300] current loss: 2.4209824657440184\n",
      "[152, 400] current loss: 2.42798371887207\n",
      "[152, 500] current loss: 2.4167589893341064\n",
      "[152, 600] current loss: 2.4258756561279298\n",
      "[152, 700] current loss: 2.4228135890960694\n",
      "[152, 800] current loss: 2.405435962677002\n",
      "[152, 900] current loss: 2.432568151473999\n",
      "[152, 1000] current loss: 2.412922067642212\n",
      "[152, 1100] current loss: 2.416229082107544\n",
      "[152, 1200] current loss: 2.420831958770752\n",
      "[152, 1300] current loss: 2.4427436180114745\n",
      "[152, 1400] current loss: 2.423038541793823\n",
      "[152, 1500] current loss: 2.4353204669952393\n",
      "[152, 1600] current loss: 2.4259100437164305\n",
      "[152, 1700] current loss: 2.4275439491271973\n",
      "[152, 1800] current loss: 2.4312606830596923\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 93 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.98166666666667\n",
      "[153, 100] current loss: 2.419097940444946\n",
      "[153, 200] current loss: 2.4092445831298828\n",
      "[153, 300] current loss: 2.4272060031890867\n",
      "[153, 400] current loss: 2.425078722000122\n",
      "[153, 500] current loss: 2.4182607555389404\n",
      "[153, 600] current loss: 2.4318104877471924\n",
      "[153, 700] current loss: 2.429518159866333\n",
      "[153, 800] current loss: 2.402218795776367\n",
      "[153, 900] current loss: 2.4321147079467775\n",
      "[153, 1000] current loss: 2.425384754180908\n",
      "[153, 1100] current loss: 2.416009099960327\n",
      "[153, 1200] current loss: 2.4183881435394285\n",
      "[153, 1300] current loss: 2.4270725059509277\n",
      "[153, 1400] current loss: 2.427612043380737\n",
      "[153, 1500] current loss: 2.434078973770142\n",
      "[153, 1600] current loss: 2.4221050758361815\n",
      "[153, 1700] current loss: 2.431381753921509\n",
      "[153, 1800] current loss: 2.4294458026885986\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 85 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 83 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 93.70833333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154, 100] current loss: 2.422486352920532\n",
      "[154, 200] current loss: 2.413011423110962\n",
      "[154, 300] current loss: 2.4233962841033936\n",
      "[154, 400] current loss: 2.434073699951172\n",
      "[154, 500] current loss: 2.419033802032471\n",
      "[154, 600] current loss: 2.431059080123901\n",
      "[154, 700] current loss: 2.4256290683746338\n",
      "[154, 800] current loss: 2.4111733379364013\n",
      "[154, 900] current loss: 2.4411067352294924\n",
      "[154, 1000] current loss: 2.4148689155578613\n",
      "[154, 1100] current loss: 2.4174369106292724\n",
      "[154, 1200] current loss: 2.416355787277222\n",
      "[154, 1300] current loss: 2.4294560546875\n",
      "[154, 1400] current loss: 2.4334932708740236\n",
      "[154, 1500] current loss: 2.4485166778564453\n",
      "[154, 1600] current loss: 2.424064640045166\n",
      "[154, 1700] current loss: 2.425492151260376\n",
      "[154, 1800] current loss: 2.4369982719421386\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 96 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.91333333333333\n",
      "[155, 100] current loss: 2.4178782787323\n",
      "[155, 200] current loss: 2.4113836612701416\n",
      "[155, 300] current loss: 2.4211243953704833\n",
      "[155, 400] current loss: 2.426060972213745\n",
      "[155, 500] current loss: 2.420444128036499\n",
      "[155, 600] current loss: 2.4333226337432863\n",
      "[155, 700] current loss: 2.423038673400879\n",
      "[155, 800] current loss: 2.4109125671386717\n",
      "[155, 900] current loss: 2.4416072158813478\n",
      "[155, 1000] current loss: 2.4153102588653566\n",
      "[155, 1100] current loss: 2.416989091873169\n",
      "[155, 1200] current loss: 2.424232915878296\n",
      "[155, 1300] current loss: 2.4351144390106203\n",
      "[155, 1400] current loss: 2.4243662929534913\n",
      "[155, 1500] current loss: 2.442986560821533\n",
      "[155, 1600] current loss: 2.4184900283813477\n",
      "[155, 1700] current loss: 2.4235641098022462\n",
      "[155, 1800] current loss: 2.435244071960449\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 92 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 94.24833333333333\n",
      "[156, 100] current loss: 2.424017827987671\n",
      "[156, 200] current loss: 2.4165806064605713\n",
      "[156, 300] current loss: 2.4311946430206297\n",
      "[156, 400] current loss: 2.4332868938446044\n",
      "[156, 500] current loss: 2.4276646995544433\n",
      "[156, 600] current loss: 2.4282851791381836\n",
      "[156, 700] current loss: 2.417514888763428\n",
      "[156, 800] current loss: 2.409005163192749\n",
      "[156, 900] current loss: 2.4245488624572755\n",
      "[156, 1000] current loss: 2.4233349800109862\n",
      "[156, 1100] current loss: 2.4168210163116455\n",
      "[156, 1200] current loss: 2.4157814769744874\n",
      "[156, 1300] current loss: 2.438727596282959\n",
      "[156, 1400] current loss: 2.421964790344238\n",
      "[156, 1500] current loss: 2.436097867965698\n",
      "[156, 1600] current loss: 2.4178074779510497\n",
      "[156, 1700] current loss: 2.432374309539795\n",
      "[156, 1800] current loss: 2.4271790370941164\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.93166666666667\n",
      "[157, 100] current loss: 2.4201370239257813\n",
      "[157, 200] current loss: 2.4112978172302246\n",
      "[157, 300] current loss: 2.4199023990631106\n",
      "[157, 400] current loss: 2.430327091217041\n",
      "[157, 500] current loss: 2.419501220703125\n",
      "[157, 600] current loss: 2.4334296798706054\n",
      "[157, 700] current loss: 2.4347378368377686\n",
      "[157, 800] current loss: 2.4099036865234376\n",
      "[157, 900] current loss: 2.4327466850280763\n",
      "[157, 1000] current loss: 2.4125316734313964\n",
      "[157, 1100] current loss: 2.4152396450042724\n",
      "[157, 1200] current loss: 2.413183500289917\n",
      "[157, 1300] current loss: 2.432904109954834\n",
      "[157, 1400] current loss: 2.426241590499878\n",
      "[157, 1500] current loss: 2.4330422344207765\n",
      "[157, 1600] current loss: 2.4194957485198976\n",
      "[157, 1700] current loss: 2.426423629760742\n",
      "[157, 1800] current loss: 2.431736385345459\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.995\n",
      "[158, 100] current loss: 2.4263944969177245\n",
      "[158, 200] current loss: 2.4120783252716063\n",
      "[158, 300] current loss: 2.420748550415039\n",
      "[158, 400] current loss: 2.428657293319702\n",
      "[158, 500] current loss: 2.425142589569092\n",
      "[158, 600] current loss: 2.4290859661102293\n",
      "[158, 700] current loss: 2.4335248374938967\n",
      "[158, 800] current loss: 2.4103854389190675\n",
      "[158, 900] current loss: 2.436549711227417\n",
      "[158, 1000] current loss: 2.414736186981201\n",
      "[158, 1100] current loss: 2.416347688674927\n",
      "[158, 1200] current loss: 2.4089989471435547\n",
      "[158, 1300] current loss: 2.4223852252960203\n",
      "[158, 1400] current loss: 2.418795419692993\n",
      "[158, 1500] current loss: 2.43069988822937\n",
      "[158, 1600] current loss: 2.4189761753082277\n",
      "[158, 1700] current loss: 2.4195695190429687\n",
      "[158, 1800] current loss: 2.423307899475098\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.68666666666667\n",
      "[159, 100] current loss: 2.4298918724060057\n",
      "[159, 200] current loss: 2.4089264602661133\n",
      "[159, 300] current loss: 2.4232944355010986\n",
      "[159, 400] current loss: 2.4256992015838623\n",
      "[159, 500] current loss: 2.416505994796753\n",
      "[159, 600] current loss: 2.4289496479034423\n",
      "[159, 700] current loss: 2.431500410079956\n",
      "[159, 800] current loss: 2.4071121215820312\n",
      "[159, 900] current loss: 2.428986490249634\n",
      "[159, 1000] current loss: 2.417831293106079\n",
      "[159, 1100] current loss: 2.4128412799835206\n",
      "[159, 1200] current loss: 2.4144930686950685\n",
      "[159, 1300] current loss: 2.4354136810302736\n",
      "[159, 1400] current loss: 2.415798048019409\n",
      "[159, 1500] current loss: 2.4279040298461916\n",
      "[159, 1600] current loss: 2.418140329360962\n",
      "[159, 1700] current loss: 2.431998489379883\n",
      "[159, 1800] current loss: 2.428019979476929\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 87 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 93.83833333333332\n",
      "[160, 100] current loss: 2.424725341796875\n",
      "[160, 200] current loss: 2.4171590156555176\n",
      "[160, 300] current loss: 2.422792860031128\n",
      "[160, 400] current loss: 2.426693696975708\n",
      "[160, 500] current loss: 2.4241202087402343\n",
      "[160, 600] current loss: 2.4226450672149658\n",
      "[160, 700] current loss: 2.4212422676086427\n",
      "[160, 800] current loss: 2.4068424186706543\n",
      "[160, 900] current loss: 2.4302140579223632\n",
      "[160, 1000] current loss: 2.4119833450317385\n",
      "[160, 1100] current loss: 2.412134496688843\n",
      "[160, 1200] current loss: 2.408317174911499\n",
      "[160, 1300] current loss: 2.430060920715332\n",
      "[160, 1400] current loss: 2.415569372177124\n",
      "[160, 1500] current loss: 2.425945316314697\n",
      "[160, 1600] current loss: 2.415453601837158\n",
      "[160, 1700] current loss: 2.429985258102417\n",
      "[160, 1800] current loss: 2.432979803085327\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.69166666666665\n",
      "[161, 100] current loss: 2.42584059715271\n",
      "[161, 200] current loss: 2.408515619277954\n",
      "[161, 300] current loss: 2.422112718582153\n",
      "[161, 400] current loss: 2.4205473308563232\n",
      "[161, 500] current loss: 2.4184844703674315\n",
      "[161, 600] current loss: 2.425327491760254\n",
      "[161, 700] current loss: 2.4158735542297363\n",
      "[161, 800] current loss: 2.400537483215332\n",
      "[161, 900] current loss: 2.429903205871582\n",
      "[161, 1000] current loss: 2.412591886520386\n",
      "[161, 1100] current loss: 2.410797222137451\n",
      "[161, 1200] current loss: 2.412097059249878\n",
      "[161, 1300] current loss: 2.4254422416687014\n",
      "[161, 1400] current loss: 2.4200491981506347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161, 1500] current loss: 2.4282535572052\n",
      "[161, 1600] current loss: 2.4218647918701173\n",
      "[161, 1700] current loss: 2.4278902950286865\n",
      "[161, 1800] current loss: 2.42640460395813\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.12166666666668\n",
      "[162, 100] current loss: 2.416720531463623\n",
      "[162, 200] current loss: 2.4099656372070313\n",
      "[162, 300] current loss: 2.4184514446258545\n",
      "[162, 400] current loss: 2.421591157913208\n",
      "[162, 500] current loss: 2.419316219329834\n",
      "[162, 600] current loss: 2.4263891830444337\n",
      "[162, 700] current loss: 2.4186581287384032\n",
      "[162, 800] current loss: 2.4047551803588867\n",
      "[162, 900] current loss: 2.4238377723693847\n",
      "[162, 1000] current loss: 2.405616542816162\n",
      "[162, 1100] current loss: 2.4143943367004392\n",
      "[162, 1200] current loss: 2.423064989089966\n",
      "[162, 1300] current loss: 2.4286127643585207\n",
      "[162, 1400] current loss: 2.422340738296509\n",
      "[162, 1500] current loss: 2.429977731704712\n",
      "[162, 1600] current loss: 2.4252528610229493\n",
      "[162, 1700] current loss: 2.43232564163208\n",
      "[162, 1800] current loss: 2.4270204734802245\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 84 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.44666666666667\n",
      "[163, 100] current loss: 2.4299022121429443\n",
      "[163, 200] current loss: 2.4051096858978274\n",
      "[163, 300] current loss: 2.4203538341522215\n",
      "[163, 400] current loss: 2.4227882957458498\n",
      "[163, 500] current loss: 2.4158982276916503\n",
      "[163, 600] current loss: 2.4206763095855712\n",
      "[163, 700] current loss: 2.422741289138794\n",
      "[163, 800] current loss: 2.402053592681885\n",
      "[163, 900] current loss: 2.4380471744537355\n",
      "[163, 1000] current loss: 2.423541177749634\n",
      "[163, 1100] current loss: 2.421002462387085\n",
      "[163, 1200] current loss: 2.4293098812103273\n",
      "[163, 1300] current loss: 2.430451515197754\n",
      "[163, 1400] current loss: 2.4207902755737303\n",
      "[163, 1500] current loss: 2.431615520477295\n",
      "[163, 1600] current loss: 2.420431335449219\n",
      "[163, 1700] current loss: 2.4262104816436767\n",
      "[163, 1800] current loss: 2.4301303062438966\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.24666666666666\n",
      "[164, 100] current loss: 2.417339063644409\n",
      "[164, 200] current loss: 2.410081188201904\n",
      "[164, 300] current loss: 2.41653218460083\n",
      "[164, 400] current loss: 2.426746530532837\n",
      "[164, 500] current loss: 2.4213632984161375\n",
      "[164, 600] current loss: 2.4289917545318604\n",
      "[164, 700] current loss: 2.4199849681854246\n",
      "[164, 800] current loss: 2.402657024383545\n",
      "[164, 900] current loss: 2.4379794006347657\n",
      "[164, 1000] current loss: 2.4163295097351076\n",
      "[164, 1100] current loss: 2.4217756538391115\n",
      "[164, 1200] current loss: 2.414942419052124\n",
      "[164, 1300] current loss: 2.4382396602630614\n",
      "[164, 1400] current loss: 2.4295582790374755\n",
      "[164, 1500] current loss: 2.43023673248291\n",
      "[164, 1600] current loss: 2.4190147132873534\n",
      "[164, 1700] current loss: 2.429377815246582\n",
      "[164, 1800] current loss: 2.426326313018799\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 94 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.29166666666667\n",
      "[165, 100] current loss: 2.423815715789795\n",
      "[165, 200] current loss: 2.4220260887145995\n",
      "[165, 300] current loss: 2.4163813686370847\n",
      "[165, 400] current loss: 2.4297137660980224\n",
      "[165, 500] current loss: 2.4191392307281494\n",
      "[165, 600] current loss: 2.4241417083740235\n",
      "[165, 700] current loss: 2.4215381717681885\n",
      "[165, 800] current loss: 2.403436052322388\n",
      "[165, 900] current loss: 2.4351465911865233\n",
      "[165, 1000] current loss: 2.413089891433716\n",
      "[165, 1100] current loss: 2.4302198028564455\n",
      "[165, 1200] current loss: 2.4189373836517336\n",
      "[165, 1300] current loss: 2.4279206523895263\n",
      "[165, 1400] current loss: 2.4220186214447024\n",
      "[165, 1500] current loss: 2.430069074630737\n",
      "[165, 1600] current loss: 2.419409023284912\n",
      "[165, 1700] current loss: 2.425314249038696\n",
      "[165, 1800] current loss: 2.4344273166656496\n",
      "Accuracy of T-shirt/top : 87 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 94 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 62 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 91.85999999999999\n",
      "[166, 100] current loss: 2.4345469837188722\n",
      "[166, 200] current loss: 2.415640535354614\n",
      "[166, 300] current loss: 2.422377338409424\n",
      "[166, 400] current loss: 2.431274217605591\n",
      "[166, 500] current loss: 2.417033483505249\n",
      "[166, 600] current loss: 2.4317190036773684\n",
      "[166, 700] current loss: 2.425334810256958\n",
      "[166, 800] current loss: 2.4109177417755125\n",
      "[166, 900] current loss: 2.439959352493286\n",
      "[166, 1000] current loss: 2.4141005420684816\n",
      "[166, 1100] current loss: 2.4229667148590086\n",
      "[166, 1200] current loss: 2.4159661693573\n",
      "[166, 1300] current loss: 2.427918193817139\n",
      "[166, 1400] current loss: 2.4228666019439697\n",
      "[166, 1500] current loss: 2.426463384628296\n",
      "[166, 1600] current loss: 2.4224832992553713\n",
      "[166, 1700] current loss: 2.4325513763427735\n",
      "[166, 1800] current loss: 2.4296725521087645\n",
      "Accuracy of T-shirt/top : 91 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.88499999999999\n",
      "[167, 100] current loss: 2.4228030433654784\n",
      "[167, 200] current loss: 2.408342483520508\n",
      "[167, 300] current loss: 2.4195321655273436\n",
      "[167, 400] current loss: 2.433814655303955\n",
      "[167, 500] current loss: 2.415971488952637\n",
      "[167, 600] current loss: 2.4272837085723875\n",
      "[167, 700] current loss: 2.427259557723999\n",
      "[167, 800] current loss: 2.4123685264587404\n",
      "[167, 900] current loss: 2.424111780166626\n",
      "[167, 1000] current loss: 2.4089385204315183\n",
      "[167, 1100] current loss: 2.421680751800537\n",
      "[167, 1200] current loss: 2.413332727432251\n",
      "[167, 1300] current loss: 2.4295731563568115\n",
      "[167, 1400] current loss: 2.4120959396362305\n",
      "[167, 1500] current loss: 2.421817464828491\n",
      "[167, 1600] current loss: 2.4208992462158205\n",
      "[167, 1700] current loss: 2.4255439987182617\n",
      "[167, 1800] current loss: 2.422077196121216\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.86166666666666\n",
      "[168, 100] current loss: 2.4234836044311523\n",
      "[168, 200] current loss: 2.4174062728881838\n",
      "[168, 300] current loss: 2.421236713409424\n",
      "[168, 400] current loss: 2.425767505645752\n",
      "[168, 500] current loss: 2.420188859939575\n",
      "[168, 600] current loss: 2.4244526386260987\n",
      "[168, 700] current loss: 2.415685520172119\n",
      "[168, 800] current loss: 2.4082170314788818\n",
      "[168, 900] current loss: 2.426334627151489\n",
      "[168, 1000] current loss: 2.4100039539337157\n",
      "[168, 1100] current loss: 2.415559617996216\n",
      "[168, 1200] current loss: 2.410205686569214\n",
      "[168, 1300] current loss: 2.422367721557617\n",
      "[168, 1400] current loss: 2.424688789367676\n",
      "[168, 1500] current loss: 2.430746524810791\n",
      "[168, 1600] current loss: 2.424000318527222\n",
      "[168, 1700] current loss: 2.435761833190918\n",
      "[168, 1800] current loss: 2.4246781940460207\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.89\n",
      "[169, 100] current loss: 2.426641263961792\n",
      "[169, 200] current loss: 2.4170726585388183\n",
      "[169, 300] current loss: 2.4187789726257325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169, 400] current loss: 2.4207694606781005\n",
      "[169, 500] current loss: 2.415100486755371\n",
      "[169, 600] current loss: 2.427154188156128\n",
      "[169, 700] current loss: 2.42466526222229\n",
      "[169, 800] current loss: 2.39958900642395\n",
      "[169, 900] current loss: 2.4368221111297608\n",
      "[169, 1000] current loss: 2.416474369049072\n",
      "[169, 1100] current loss: 2.4136904296875\n",
      "[169, 1200] current loss: 2.4185207386016847\n",
      "[169, 1300] current loss: 2.434426847457886\n",
      "[169, 1400] current loss: 2.4248778228759766\n",
      "[169, 1500] current loss: 2.4307481594085694\n",
      "[169, 1600] current loss: 2.4255171108245848\n",
      "[169, 1700] current loss: 2.423752202987671\n",
      "[169, 1800] current loss: 2.434121311187744\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 86 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 87 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.24833333333333\n",
      "[170, 100] current loss: 2.4170399284362794\n",
      "[170, 200] current loss: 2.410161064147949\n",
      "[170, 300] current loss: 2.418267520904541\n",
      "[170, 400] current loss: 2.423477600097656\n",
      "[170, 500] current loss: 2.4228513622283936\n",
      "[170, 600] current loss: 2.423228319168091\n",
      "[170, 700] current loss: 2.4162170753479004\n",
      "[170, 800] current loss: 2.3984747772216797\n",
      "[170, 900] current loss: 2.422502323150635\n",
      "[170, 1000] current loss: 2.409243684768677\n",
      "[170, 1100] current loss: 2.4098374118804933\n",
      "[170, 1200] current loss: 2.407286918640137\n",
      "[170, 1300] current loss: 2.424129913330078\n",
      "[170, 1400] current loss: 2.4251543254852295\n",
      "[170, 1500] current loss: 2.4262845687866212\n",
      "[170, 1600] current loss: 2.4177096672058105\n",
      "[170, 1700] current loss: 2.4175832233428953\n",
      "[170, 1800] current loss: 2.4295300121307375\n",
      "Accuracy of T-shirt/top : 88 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.60499999999999\n",
      "[171, 100] current loss: 2.423439640045166\n",
      "[171, 200] current loss: 2.4115579986572264\n",
      "[171, 300] current loss: 2.4090945777893067\n",
      "[171, 400] current loss: 2.419569339752197\n",
      "[171, 500] current loss: 2.415565647125244\n",
      "[171, 600] current loss: 2.4181322231292723\n",
      "[171, 700] current loss: 2.4139480934143065\n",
      "[171, 800] current loss: 2.39930454826355\n",
      "[171, 900] current loss: 2.427157983779907\n",
      "[171, 1000] current loss: 2.4121399307250977\n",
      "[171, 1100] current loss: 2.4300580291748046\n",
      "[171, 1200] current loss: 2.4118573722839356\n",
      "[171, 1300] current loss: 2.4273481101989747\n",
      "[171, 1400] current loss: 2.414298343658447\n",
      "[171, 1500] current loss: 2.4232658195495604\n",
      "[171, 1600] current loss: 2.4184590377807615\n",
      "[171, 1700] current loss: 2.424473457336426\n",
      "[171, 1800] current loss: 2.4219081649780274\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.82666666666665\n",
      "[172, 100] current loss: 2.4191796588897705\n",
      "[172, 200] current loss: 2.413125560760498\n",
      "[172, 300] current loss: 2.4182047443389894\n",
      "[172, 400] current loss: 2.437978910446167\n",
      "[172, 500] current loss: 2.425252014160156\n",
      "[172, 600] current loss: 2.4268150997161864\n",
      "[172, 700] current loss: 2.4248964462280274\n",
      "[172, 800] current loss: 2.4038403720855714\n",
      "[172, 900] current loss: 2.423729574203491\n",
      "[172, 1000] current loss: 2.409423843383789\n",
      "[172, 1100] current loss: 2.4081897411346436\n",
      "[172, 1200] current loss: 2.4069011096954345\n",
      "[172, 1300] current loss: 2.421693571090698\n",
      "[172, 1400] current loss: 2.4214742469787596\n",
      "[172, 1500] current loss: 2.425386194229126\n",
      "[172, 1600] current loss: 2.42248579788208\n",
      "[172, 1700] current loss: 2.4266240558624266\n",
      "[172, 1800] current loss: 2.4244883403778075\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 83 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 94 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 82 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 94.00166666666667\n",
      "[173, 100] current loss: 2.41969744682312\n",
      "[173, 200] current loss: 2.406909511566162\n",
      "[173, 300] current loss: 2.4096956424713136\n",
      "[173, 400] current loss: 2.4247465095520018\n",
      "[173, 500] current loss: 2.4114629497528077\n",
      "[173, 600] current loss: 2.4317687187194825\n",
      "[173, 700] current loss: 2.4156797142028807\n",
      "[173, 800] current loss: 2.4112542343139647\n",
      "[173, 900] current loss: 2.428176467895508\n",
      "[173, 1000] current loss: 2.413964332580566\n",
      "[173, 1100] current loss: 2.408887092590332\n",
      "[173, 1200] current loss: 2.4109662628173827\n",
      "[173, 1300] current loss: 2.4235084705352783\n",
      "[173, 1400] current loss: 2.417935655593872\n",
      "[173, 1500] current loss: 2.425795373916626\n",
      "[173, 1600] current loss: 2.41855464553833\n",
      "[173, 1700] current loss: 2.4334770793914795\n",
      "[173, 1800] current loss: 2.424574504852295\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 94.995\n",
      "[174, 100] current loss: 2.421725254058838\n",
      "[174, 200] current loss: 2.4084527854919435\n",
      "[174, 300] current loss: 2.4096817779541015\n",
      "[174, 400] current loss: 2.4249521465301513\n",
      "[174, 500] current loss: 2.4163301277160643\n",
      "[174, 600] current loss: 2.41626166343689\n",
      "[174, 700] current loss: 2.4161823444366455\n",
      "[174, 800] current loss: 2.4101867141723634\n",
      "[174, 900] current loss: 2.4237548446655275\n",
      "[174, 1000] current loss: 2.412711420059204\n",
      "[174, 1100] current loss: 2.4096393089294432\n",
      "[174, 1200] current loss: 2.408525375366211\n",
      "[174, 1300] current loss: 2.4258140640258787\n",
      "[174, 1400] current loss: 2.4233380489349363\n",
      "[174, 1500] current loss: 2.4257083759307863\n",
      "[174, 1600] current loss: 2.419258394241333\n",
      "[174, 1700] current loss: 2.4217160682678225\n",
      "[174, 1800] current loss: 2.4271302032470703\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.08333333333334\n",
      "[175, 100] current loss: 2.419367649078369\n",
      "[175, 200] current loss: 2.405636890411377\n",
      "[175, 300] current loss: 2.4194514961242675\n",
      "[175, 400] current loss: 2.423429849624634\n",
      "[175, 500] current loss: 2.4161270580291747\n",
      "[175, 600] current loss: 2.4257183895111085\n",
      "[175, 700] current loss: 2.424827974319458\n",
      "[175, 800] current loss: 2.4080498390197755\n",
      "[175, 900] current loss: 2.426715612411499\n",
      "[175, 1000] current loss: 2.407438009262085\n",
      "[175, 1100] current loss: 2.4096638526916503\n",
      "[175, 1200] current loss: 2.4110692329406738\n",
      "[175, 1300] current loss: 2.424975992202759\n",
      "[175, 1400] current loss: 2.4180846042633055\n",
      "[175, 1500] current loss: 2.430187480926514\n",
      "[175, 1600] current loss: 2.418539176940918\n",
      "[175, 1700] current loss: 2.4205751934051514\n",
      "[175, 1800] current loss: 2.4215464668273925\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 94 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.545\n",
      "[176, 100] current loss: 2.4216144847869874\n",
      "[176, 200] current loss: 2.4128156185150145\n",
      "[176, 300] current loss: 2.4235487365722657\n",
      "[176, 400] current loss: 2.4327243576049806\n",
      "[176, 500] current loss: 2.419191106796265\n",
      "[176, 600] current loss: 2.426969181060791\n",
      "[176, 700] current loss: 2.4143359355926512\n",
      "[176, 800] current loss: 2.4012113628387453\n",
      "[176, 900] current loss: 2.4255025424957277\n",
      "[176, 1000] current loss: 2.408862632751465\n",
      "[176, 1100] current loss: 2.4133764266967774\n",
      "[176, 1200] current loss: 2.4131504573822022\n",
      "[176, 1300] current loss: 2.4247500267028808\n",
      "[176, 1400] current loss: 2.428335792541504\n",
      "[176, 1500] current loss: 2.426823541641235\n",
      "[176, 1600] current loss: 2.420042236328125\n",
      "[176, 1700] current loss: 2.420947256088257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176, 1800] current loss: 2.4232236080169676\n",
      "Accuracy of T-shirt/top : 95 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 79 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 91 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 93.56333333333332\n",
      "[177, 100] current loss: 2.427659692764282\n",
      "[177, 200] current loss: 2.4042648143768313\n",
      "[177, 300] current loss: 2.406638137817383\n",
      "[177, 400] current loss: 2.419618375778198\n",
      "[177, 500] current loss: 2.418227121353149\n",
      "[177, 600] current loss: 2.419880891799927\n",
      "[177, 700] current loss: 2.422264673233032\n",
      "[177, 800] current loss: 2.4046091842651367\n",
      "[177, 900] current loss: 2.42896844291687\n",
      "[177, 1000] current loss: 2.408399612426758\n",
      "[177, 1100] current loss: 2.417708086013794\n",
      "[177, 1200] current loss: 2.41282018661499\n",
      "[177, 1300] current loss: 2.4238817234039307\n",
      "[177, 1400] current loss: 2.4220773124694825\n",
      "[177, 1500] current loss: 2.4236584873199463\n",
      "[177, 1600] current loss: 2.411458656311035\n",
      "[177, 1700] current loss: 2.4216509265899657\n",
      "[177, 1800] current loss: 2.419810308456421\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 83 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.31166666666668\n",
      "[178, 100] current loss: 2.4126054401397705\n",
      "[178, 200] current loss: 2.410529697418213\n",
      "[178, 300] current loss: 2.4118556041717527\n",
      "[178, 400] current loss: 2.4173173751831056\n",
      "[178, 500] current loss: 2.417448522567749\n",
      "[178, 600] current loss: 2.419545364379883\n",
      "[178, 700] current loss: 2.4242014179229736\n",
      "[178, 800] current loss: 2.3962211322784426\n",
      "[178, 900] current loss: 2.4310037727355955\n",
      "[178, 1000] current loss: 2.4109959144592286\n",
      "[178, 1100] current loss: 2.4184664821624757\n",
      "[178, 1200] current loss: 2.4188523654937746\n",
      "[178, 1300] current loss: 2.4287332706451417\n",
      "[178, 1400] current loss: 2.4221457920074463\n",
      "[178, 1500] current loss: 2.4251930923461913\n",
      "[178, 1600] current loss: 2.42336789894104\n",
      "[178, 1700] current loss: 2.420973222732544\n",
      "[178, 1800] current loss: 2.417976716995239\n",
      "Accuracy of T-shirt/top : 90 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.95500000000001\n",
      "[179, 100] current loss: 2.4129146633148193\n",
      "[179, 200] current loss: 2.406107162475586\n",
      "[179, 300] current loss: 2.4131794357299805\n",
      "[179, 400] current loss: 2.4181539592742918\n",
      "[179, 500] current loss: 2.418985179901123\n",
      "[179, 600] current loss: 2.4229893226623536\n",
      "[179, 700] current loss: 2.422309324264526\n",
      "[179, 800] current loss: 2.399616359710693\n",
      "[179, 900] current loss: 2.4241174907684324\n",
      "[179, 1000] current loss: 2.408537788391113\n",
      "[179, 1100] current loss: 2.416117847442627\n",
      "[179, 1200] current loss: 2.410457427978516\n",
      "[179, 1300] current loss: 2.422551279067993\n",
      "[179, 1400] current loss: 2.4153619537353515\n",
      "[179, 1500] current loss: 2.4240379619598387\n",
      "[179, 1600] current loss: 2.4157419376373293\n",
      "[179, 1700] current loss: 2.429236915588379\n",
      "[179, 1800] current loss: 2.420862949371338\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 94 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.38833333333334\n",
      "[180, 100] current loss: 2.417486166000366\n",
      "[180, 200] current loss: 2.403826528549194\n",
      "[180, 300] current loss: 2.411536903381348\n",
      "[180, 400] current loss: 2.418835905075073\n",
      "[180, 500] current loss: 2.417339391708374\n",
      "[180, 600] current loss: 2.4184544887542723\n",
      "[180, 700] current loss: 2.4273867797851563\n",
      "[180, 800] current loss: 2.404176044464111\n",
      "[180, 900] current loss: 2.426221426010132\n",
      "[180, 1000] current loss: 2.410961837768555\n",
      "[180, 1100] current loss: 2.4183037490844725\n",
      "[180, 1200] current loss: 2.4224888496398926\n",
      "[180, 1300] current loss: 2.439770589828491\n",
      "[180, 1400] current loss: 2.421323928833008\n",
      "[180, 1500] current loss: 2.4261992473602296\n",
      "[180, 1600] current loss: 2.4189825744628908\n",
      "[180, 1700] current loss: 2.422772903442383\n",
      "[180, 1800] current loss: 2.4328217124938964\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 97 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 94.94666666666667\n",
      "[181, 100] current loss: 2.420938365936279\n",
      "[181, 200] current loss: 2.418707830429077\n",
      "[181, 300] current loss: 2.422203441619873\n",
      "[181, 400] current loss: 2.4187533473968506\n",
      "[181, 500] current loss: 2.416252077102661\n",
      "[181, 600] current loss: 2.423264764785767\n",
      "[181, 700] current loss: 2.415731735229492\n",
      "[181, 800] current loss: 2.4000882549285887\n",
      "[181, 900] current loss: 2.4241428661346434\n",
      "[181, 1000] current loss: 2.4108234729766846\n",
      "[181, 1100] current loss: 2.418624925613403\n",
      "[181, 1200] current loss: 2.4102615909576417\n",
      "[181, 1300] current loss: 2.42915301322937\n",
      "[181, 1400] current loss: 2.416283172607422\n",
      "[181, 1500] current loss: 2.4256380920410154\n",
      "[181, 1600] current loss: 2.420044813156128\n",
      "[181, 1700] current loss: 2.426779727935791\n",
      "[181, 1800] current loss: 2.4357402954101564\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 87 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.08666666666667\n",
      "[182, 100] current loss: 2.421691581726074\n",
      "[182, 200] current loss: 2.411380979537964\n",
      "[182, 300] current loss: 2.4212906150817872\n",
      "[182, 400] current loss: 2.4226673049926757\n",
      "[182, 500] current loss: 2.4230520553588866\n",
      "[182, 600] current loss: 2.4216269607543945\n",
      "[182, 700] current loss: 2.412250925064087\n",
      "[182, 800] current loss: 2.401376022338867\n",
      "[182, 900] current loss: 2.4292618293762205\n",
      "[182, 1000] current loss: 2.414810047149658\n",
      "[182, 1100] current loss: 2.421068103790283\n",
      "[182, 1200] current loss: 2.4140815296173095\n",
      "[182, 1300] current loss: 2.4201525020599366\n",
      "[182, 1400] current loss: 2.4166545276641846\n",
      "[182, 1500] current loss: 2.4255384216308595\n",
      "[182, 1600] current loss: 2.42562957572937\n",
      "[182, 1700] current loss: 2.4235089359283446\n",
      "[182, 1800] current loss: 2.4174987907409666\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 97 %\n",
      "overall: 95.33500000000001\n",
      "[183, 100] current loss: 2.4151343097686766\n",
      "[183, 200] current loss: 2.407606611251831\n",
      "[183, 300] current loss: 2.4128140964508056\n",
      "[183, 400] current loss: 2.4195317192077637\n",
      "[183, 500] current loss: 2.414268051147461\n",
      "[183, 600] current loss: 2.4279299144744875\n",
      "[183, 700] current loss: 2.4160407085418703\n",
      "[183, 800] current loss: 2.402091878890991\n",
      "[183, 900] current loss: 2.4232419052124023\n",
      "[183, 1000] current loss: 2.4075304794311525\n",
      "[183, 1100] current loss: 2.406899543762207\n",
      "[183, 1200] current loss: 2.410114133834839\n",
      "[183, 1300] current loss: 2.4260753860473634\n",
      "[183, 1400] current loss: 2.4156906509399416\n",
      "[183, 1500] current loss: 2.4197538242340086\n",
      "[183, 1600] current loss: 2.4177620887756346\n",
      "[183, 1700] current loss: 2.4294635677337646\n",
      "[183, 1800] current loss: 2.431548936843872\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 86 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 94 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 94.55666666666666\n",
      "[184, 100] current loss: 2.4212433013916015\n",
      "[184, 200] current loss: 2.4135298252105715\n",
      "[184, 300] current loss: 2.423214296340942\n",
      "[184, 400] current loss: 2.4258017082214356\n",
      "[184, 500] current loss: 2.417960132598877\n",
      "[184, 600] current loss: 2.4201543064117432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184, 700] current loss: 2.41972131729126\n",
      "[184, 800] current loss: 2.4003411865234376\n",
      "[184, 900] current loss: 2.424183010101318\n",
      "[184, 1000] current loss: 2.418952928543091\n",
      "[184, 1100] current loss: 2.416502799987793\n",
      "[184, 1200] current loss: 2.416446710586548\n",
      "[184, 1300] current loss: 2.426573944091797\n",
      "[184, 1400] current loss: 2.4146720085144042\n",
      "[184, 1500] current loss: 2.421692970275879\n",
      "[184, 1600] current loss: 2.416506715774536\n",
      "[184, 1700] current loss: 2.4225570182800293\n",
      "[184, 1800] current loss: 2.4235813541412354\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.34333333333333\n",
      "[185, 100] current loss: 2.41988374710083\n",
      "[185, 200] current loss: 2.406297218322754\n",
      "[185, 300] current loss: 2.4168560371398926\n",
      "[185, 400] current loss: 2.419608108520508\n",
      "[185, 500] current loss: 2.417475639343262\n",
      "[185, 600] current loss: 2.4185516929626463\n",
      "[185, 700] current loss: 2.4160280990600587\n",
      "[185, 800] current loss: 2.398462438583374\n",
      "[185, 900] current loss: 2.430465593338013\n",
      "[185, 1000] current loss: 2.4253682651519775\n",
      "[185, 1100] current loss: 2.4126237354278564\n",
      "[185, 1200] current loss: 2.409406850814819\n",
      "[185, 1300] current loss: 2.4274632778167726\n",
      "[185, 1400] current loss: 2.418440540313721\n",
      "[185, 1500] current loss: 2.418854751586914\n",
      "[185, 1600] current loss: 2.4167405166625975\n",
      "[185, 1700] current loss: 2.425637315750122\n",
      "[185, 1800] current loss: 2.427068359375\n",
      "Accuracy of T-shirt/top : 95 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 95 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 99 %\n",
      "overall: 95.31666666666665\n",
      "[186, 100] current loss: 2.4141770248413086\n",
      "[186, 200] current loss: 2.407023462295532\n",
      "[186, 300] current loss: 2.4116149692535402\n",
      "[186, 400] current loss: 2.418262544631958\n",
      "[186, 500] current loss: 2.413661840438843\n",
      "[186, 600] current loss: 2.416357702255249\n",
      "[186, 700] current loss: 2.416341205596924\n",
      "[186, 800] current loss: 2.402759874343872\n",
      "[186, 900] current loss: 2.4283997287750245\n",
      "[186, 1000] current loss: 2.4049589939117433\n",
      "[186, 1100] current loss: 2.40877329826355\n",
      "[186, 1200] current loss: 2.416099277496338\n",
      "[186, 1300] current loss: 2.4359449634552\n",
      "[186, 1400] current loss: 2.4302427597045897\n",
      "[186, 1500] current loss: 2.4211684265136717\n",
      "[186, 1600] current loss: 2.4156017780303953\n",
      "[186, 1700] current loss: 2.4260585327148436\n",
      "[186, 1800] current loss: 2.4212059020996093\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 88 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.05166666666666\n",
      "[187, 100] current loss: 2.4250837268829346\n",
      "[187, 200] current loss: 2.4093497676849367\n",
      "[187, 300] current loss: 2.4143665504455565\n",
      "[187, 400] current loss: 2.4191922416687013\n",
      "[187, 500] current loss: 2.4206038608551026\n",
      "[187, 600] current loss: 2.430276168823242\n",
      "[187, 700] current loss: 2.418738971710205\n",
      "[187, 800] current loss: 2.406372121810913\n",
      "[187, 900] current loss: 2.4329976177215578\n",
      "[187, 1000] current loss: 2.411051305770874\n",
      "[187, 1100] current loss: 2.413356834411621\n",
      "[187, 1200] current loss: 2.418469627380371\n",
      "[187, 1300] current loss: 2.421450620651245\n",
      "[187, 1400] current loss: 2.4162839069366453\n",
      "[187, 1500] current loss: 2.4188508853912354\n",
      "[187, 1600] current loss: 2.411084587097168\n",
      "[187, 1700] current loss: 2.419951141357422\n",
      "[187, 1800] current loss: 2.426422622680664\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 81 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.42999999999999\n",
      "[188, 100] current loss: 2.414473596572876\n",
      "[188, 200] current loss: 2.415779748916626\n",
      "[188, 300] current loss: 2.413395971298218\n",
      "[188, 400] current loss: 2.412426872253418\n",
      "[188, 500] current loss: 2.414320951461792\n",
      "[188, 600] current loss: 2.422673065185547\n",
      "[188, 700] current loss: 2.4227926292419433\n",
      "[188, 800] current loss: 2.398627290725708\n",
      "[188, 900] current loss: 2.4304128704071046\n",
      "[188, 1000] current loss: 2.4160225410461424\n",
      "[188, 1100] current loss: 2.4090418548583985\n",
      "[188, 1200] current loss: 2.404011484146118\n",
      "[188, 1300] current loss: 2.422357042312622\n",
      "[188, 1400] current loss: 2.4182112979888917\n",
      "[188, 1500] current loss: 2.417956729888916\n",
      "[188, 1600] current loss: 2.4177468032836913\n",
      "[188, 1700] current loss: 2.4238530788421633\n",
      "[188, 1800] current loss: 2.423149116516113\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 91 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.35333333333332\n",
      "[189, 100] current loss: 2.412013818740845\n",
      "[189, 200] current loss: 2.4104096298217774\n",
      "[189, 300] current loss: 2.4106580009460448\n",
      "[189, 400] current loss: 2.417706506729126\n",
      "[189, 500] current loss: 2.411600475311279\n",
      "[189, 600] current loss: 2.4232116203308105\n",
      "[189, 700] current loss: 2.4244299335479735\n",
      "[189, 800] current loss: 2.398273241043091\n",
      "[189, 900] current loss: 2.428510793685913\n",
      "[189, 1000] current loss: 2.4155738468170167\n",
      "[189, 1100] current loss: 2.4119138526916504\n",
      "[189, 1200] current loss: 2.4297636432647707\n",
      "[189, 1300] current loss: 2.431620386123657\n",
      "[189, 1400] current loss: 2.417918737411499\n",
      "[189, 1500] current loss: 2.4246931705474855\n",
      "[189, 1600] current loss: 2.418387731552124\n",
      "[189, 1700] current loss: 2.422691635131836\n",
      "[189, 1800] current loss: 2.426774040222168\n",
      "Accuracy of T-shirt/top : 89 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 97 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.80999999999999\n",
      "[190, 100] current loss: 2.4185253620147704\n",
      "[190, 200] current loss: 2.400751094818115\n",
      "[190, 300] current loss: 2.412873804092407\n",
      "[190, 400] current loss: 2.4182573947906496\n",
      "[190, 500] current loss: 2.417552722930908\n",
      "[190, 600] current loss: 2.416686185836792\n",
      "[190, 700] current loss: 2.4168860721588135\n",
      "[190, 800] current loss: 2.4056203956604003\n",
      "[190, 900] current loss: 2.4325629501342774\n",
      "[190, 1000] current loss: 2.4173660316467287\n",
      "[190, 1100] current loss: 2.4124870834350585\n",
      "[190, 1200] current loss: 2.411717691421509\n",
      "[190, 1300] current loss: 2.4207534809112548\n",
      "[190, 1400] current loss: 2.4176971912384033\n",
      "[190, 1500] current loss: 2.424435707092285\n",
      "[190, 1600] current loss: 2.4116378326416017\n",
      "[190, 1700] current loss: 2.4236139011383058\n",
      "[190, 1800] current loss: 2.414767559051514\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.15833333333333\n",
      "[191, 100] current loss: 2.4163186073303224\n",
      "[191, 200] current loss: 2.419814805984497\n",
      "[191, 300] current loss: 2.408244918823242\n",
      "[191, 400] current loss: 2.416436014175415\n",
      "[191, 500] current loss: 2.418176658630371\n",
      "[191, 600] current loss: 2.4150994262695313\n",
      "[191, 700] current loss: 2.412029573440552\n",
      "[191, 800] current loss: 2.398548002243042\n",
      "[191, 900] current loss: 2.428602830886841\n",
      "[191, 1000] current loss: 2.4072360610961914\n",
      "[191, 1100] current loss: 2.4130903129577637\n",
      "[191, 1200] current loss: 2.4147859897613526\n",
      "[191, 1300] current loss: 2.424581228256226\n",
      "[191, 1400] current loss: 2.422818296432495\n",
      "[191, 1500] current loss: 2.4277437725067137\n",
      "[191, 1600] current loss: 2.4153846340179443\n",
      "[191, 1700] current loss: 2.428582723617554\n",
      "[191, 1800] current loss: 2.4165569877624513\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192, 100] current loss: 2.417358221054077\n",
      "[192, 200] current loss: 2.413285181045532\n",
      "[192, 300] current loss: 2.4141196193695067\n",
      "[192, 400] current loss: 2.4212736663818357\n",
      "[192, 500] current loss: 2.4177258739471434\n",
      "[192, 600] current loss: 2.423355716705322\n",
      "[192, 700] current loss: 2.4151138954162596\n",
      "[192, 800] current loss: 2.406716152191162\n",
      "[192, 900] current loss: 2.430402172088623\n",
      "[192, 1000] current loss: 2.4038186874389647\n",
      "[192, 1100] current loss: 2.4067337856292723\n",
      "[192, 1200] current loss: 2.4058921241760256\n",
      "[192, 1300] current loss: 2.4429107208251954\n",
      "[192, 1400] current loss: 2.423968683242798\n",
      "[192, 1500] current loss: 2.418977149963379\n",
      "[192, 1600] current loss: 2.415757774353027\n",
      "[192, 1700] current loss: 2.4227050342559813\n",
      "[192, 1800] current loss: 2.4232839088439944\n",
      "Accuracy of T-shirt/top : 95 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 98 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.52333333333334\n",
      "[193, 100] current loss: 2.423122856140137\n",
      "[193, 200] current loss: 2.404641622543335\n",
      "[193, 300] current loss: 2.408054491043091\n",
      "[193, 400] current loss: 2.419085096359253\n",
      "[193, 500] current loss: 2.412141925811768\n",
      "[193, 600] current loss: 2.419814401626587\n",
      "[193, 700] current loss: 2.4161549549102785\n",
      "[193, 800] current loss: 2.3953082427978516\n",
      "[193, 900] current loss: 2.4229331741333007\n",
      "[193, 1000] current loss: 2.4075060825347903\n",
      "[193, 1100] current loss: 2.408669780731201\n",
      "[193, 1200] current loss: 2.4136209411621095\n",
      "[193, 1300] current loss: 2.4228870029449463\n",
      "[193, 1400] current loss: 2.419351926803589\n",
      "[193, 1500] current loss: 2.4275346965789795\n",
      "[193, 1600] current loss: 2.4124501190185548\n",
      "[193, 1700] current loss: 2.412931350708008\n",
      "[193, 1800] current loss: 2.422181035995483\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 89 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 89 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 94.91833333333334\n",
      "[194, 100] current loss: 2.414795787811279\n",
      "[194, 200] current loss: 2.4036077156066895\n",
      "[194, 300] current loss: 2.4154469356536867\n",
      "[194, 400] current loss: 2.4178675270080565\n",
      "[194, 500] current loss: 2.410474573135376\n",
      "[194, 600] current loss: 2.41313175201416\n",
      "[194, 700] current loss: 2.4139315547943117\n",
      "[194, 800] current loss: 2.3978222408294676\n",
      "[194, 900] current loss: 2.4191780796051026\n",
      "[194, 1000] current loss: 2.4047278232574465\n",
      "[194, 1100] current loss: 2.4114458065032958\n",
      "[194, 1200] current loss: 2.4071583366394043\n",
      "[194, 1300] current loss: 2.4220891189575195\n",
      "[194, 1400] current loss: 2.4101398487091066\n",
      "[194, 1500] current loss: 2.421091163635254\n",
      "[194, 1600] current loss: 2.410633810043335\n",
      "[194, 1700] current loss: 2.416058141708374\n",
      "[194, 1800] current loss: 2.4255537109375\n",
      "Accuracy of T-shirt/top : 92 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 92 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 90 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 88 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.48333333333332\n",
      "[195, 100] current loss: 2.4136774826049803\n",
      "[195, 200] current loss: 2.404696407318115\n",
      "[195, 300] current loss: 2.412039602279663\n",
      "[195, 400] current loss: 2.4116464443206787\n",
      "[195, 500] current loss: 2.4072019767761232\n",
      "[195, 600] current loss: 2.4179027061462404\n",
      "[195, 700] current loss: 2.4155234851837157\n",
      "[195, 800] current loss: 2.405473077774048\n",
      "[195, 900] current loss: 2.4210290756225588\n",
      "[195, 1000] current loss: 2.4038941593170167\n",
      "[195, 1100] current loss: 2.415828996658325\n",
      "[195, 1200] current loss: 2.413728223800659\n",
      "[195, 1300] current loss: 2.425978115081787\n",
      "[195, 1400] current loss: 2.416732648849487\n",
      "[195, 1500] current loss: 2.421180814743042\n",
      "[195, 1600] current loss: 2.4088943920135497\n",
      "[195, 1700] current loss: 2.414034383773804\n",
      "[195, 1800] current loss: 2.4167527236938477\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 85 %\n",
      "Accuracy of Sneaker : 97 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.20166666666667\n",
      "[196, 100] current loss: 2.420289144515991\n",
      "[196, 200] current loss: 2.4079015197753906\n",
      "[196, 300] current loss: 2.4090816593170166\n",
      "[196, 400] current loss: 2.4315273113250733\n",
      "[196, 500] current loss: 2.4155475482940676\n",
      "[196, 600] current loss: 2.417282554626465\n",
      "[196, 700] current loss: 2.4163363094329835\n",
      "[196, 800] current loss: 2.404190481185913\n",
      "[196, 900] current loss: 2.4276289291381836\n",
      "[196, 1000] current loss: 2.40660258102417\n",
      "[196, 1100] current loss: 2.415857181549072\n",
      "[196, 1200] current loss: 2.407170030593872\n",
      "[196, 1300] current loss: 2.429008451461792\n",
      "[196, 1400] current loss: 2.414728496551514\n",
      "[196, 1500] current loss: 2.4181916007995605\n",
      "[196, 1600] current loss: 2.411844244003296\n",
      "[196, 1700] current loss: 2.4145539054870606\n",
      "[196, 1800] current loss: 2.4216130981445314\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 91 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.42333333333332\n",
      "[197, 100] current loss: 2.4175161685943602\n",
      "[197, 200] current loss: 2.404391170501709\n",
      "[197, 300] current loss: 2.4166897220611574\n",
      "[197, 400] current loss: 2.4178952407836913\n",
      "[197, 500] current loss: 2.4139951820373535\n",
      "[197, 600] current loss: 2.4209708976745605\n",
      "[197, 700] current loss: 2.4128220176696775\n",
      "[197, 800] current loss: 2.403215847015381\n",
      "[197, 900] current loss: 2.423685037612915\n",
      "[197, 1000] current loss: 2.411910985946655\n",
      "[197, 1100] current loss: 2.4120257472991944\n",
      "[197, 1200] current loss: 2.4022321529388426\n",
      "[197, 1300] current loss: 2.426633975982666\n",
      "[197, 1400] current loss: 2.4189201107025147\n",
      "[197, 1500] current loss: 2.4245355548858645\n",
      "[197, 1600] current loss: 2.4193723640441895\n",
      "[197, 1700] current loss: 2.4181731147766112\n",
      "[197, 1800] current loss: 2.42284256362915\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.15833333333333\n",
      "[198, 100] current loss: 2.41690295791626\n",
      "[198, 200] current loss: 2.4086424751281736\n",
      "[198, 300] current loss: 2.408781114578247\n",
      "[198, 400] current loss: 2.414579969406128\n",
      "[198, 500] current loss: 2.4077507095336914\n",
      "[198, 600] current loss: 2.416678544998169\n",
      "[198, 700] current loss: 2.4200765285491945\n",
      "[198, 800] current loss: 2.3976833839416503\n",
      "[198, 900] current loss: 2.42779008102417\n",
      "[198, 1000] current loss: 2.406566047668457\n",
      "[198, 1100] current loss: 2.404021167755127\n",
      "[198, 1200] current loss: 2.4045498485565187\n",
      "[198, 1300] current loss: 2.422306192398071\n",
      "[198, 1400] current loss: 2.4102602043151857\n",
      "[198, 1500] current loss: 2.418203695297241\n",
      "[198, 1600] current loss: 2.4181940250396727\n",
      "[198, 1700] current loss: 2.4193171195983885\n",
      "[198, 1800] current loss: 2.423477758407593\n",
      "Accuracy of T-shirt/top : 94 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 90 %\n",
      "Accuracy of Dress : 95 %\n",
      "Accuracy of  Coat : 93 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 86 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.36666666666666\n",
      "[199, 100] current loss: 2.4152775554656984\n",
      "[199, 200] current loss: 2.410207082748413\n",
      "[199, 300] current loss: 2.4108635597229005\n",
      "[199, 400] current loss: 2.414509708404541\n",
      "[199, 500] current loss: 2.409790061950684\n",
      "[199, 600] current loss: 2.4123415184020995\n",
      "[199, 700] current loss: 2.415263847351074\n",
      "[199, 800] current loss: 2.3944336910247803\n",
      "[199, 900] current loss: 2.420928829193115\n",
      "[199, 1000] current loss: 2.4099959697723388\n",
      "[199, 1100] current loss: 2.4055463771820067\n",
      "[199, 1200] current loss: 2.4076497974395754\n",
      "[199, 1300] current loss: 2.422228145599365\n",
      "[199, 1400] current loss: 2.4106902923583986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199, 1500] current loss: 2.41771364402771\n",
      "[199, 1600] current loss: 2.406993902206421\n",
      "[199, 1700] current loss: 2.416448064804077\n",
      "[199, 1800] current loss: 2.4153811569213866\n",
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.31166666666668\n",
      "CPU times: user 5h 23min 27s, sys: 36.7 s, total: 5h 24min 4s\n",
      "Wall time: 1h 54min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch_num  in range(NUM_EPOCHS):\n",
    "    iter_num = 0\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        # forward (подсчёт ответа с текущими весами)\n",
    "        y_pred = net(X_batch)\n",
    "\n",
    "        # вычисляем loss'ы\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # выводем качество каждые 2000 батчей\n",
    "            \n",
    "        if iter_num % 100 == 99:\n",
    "            print('[{}, {}] current loss: {}'.format(epoch_num, iter_num + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        # зануляем градиенты\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward (подсчёт новых градиентов)\n",
    "        loss.backward()\n",
    "\n",
    "        # обновляем веса\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter_num += 1\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "                       'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "            y_pred = net(X_batch)\n",
    "            _, predicted = torch.max(y_pred, 1)\n",
    "            c = (predicted == y_batch).squeeze()\n",
    "            for i in range(len(y_pred)):\n",
    "                label = y_batch[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    sum = 0\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        sum+= 100 * class_correct[i] / class_total[i]\n",
    "    print(\"overall:\", sum/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of T-shirt/top : 93 %\n",
      "Accuracy of Trouser : 98 %\n",
      "Accuracy of Pullover : 88 %\n",
      "Accuracy of Dress : 96 %\n",
      "Accuracy of  Coat : 92 %\n",
      "Accuracy of Sandal : 99 %\n",
      "Accuracy of Shirt : 87 %\n",
      "Accuracy of Sneaker : 98 %\n",
      "Accuracy of   Bag : 98 %\n",
      "Accuracy of Ankle boot : 98 %\n",
      "overall: 95.31166666666668\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "           'Sandal', 'Shirt', 'Sneaker','Bag', 'Ankle boot']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in generate_batches(X_train_tensor, y_train_tensor, BATCH_SIZE):\n",
    "        y_pred = net(X_batch)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        c = (predicted == y_batch).squeeze()\n",
    "        for i in range(len(y_pred)):\n",
    "            label = y_batch[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "sum = 0\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    sum+= 100 * class_correct[i] / class_total[i]\n",
    "print(\"overall:\", sum/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.06 s, sys: 12 ms, total: 1.07 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = net(torch.FloatTensor(X_test))\n",
    "create_submission(y_test_pred, 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWdogJnfWs1C"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4Tq7vBXWs1D"
   },
   "source": [
    "1). *Примеры написания нейросетей на PyTorch (офийиальные туториалы) (на английском): https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#examples  \n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html*\n",
    "\n",
    "2). ***Один из самых подробных и полных курсов по deep learning на данный момент - это курс Стэнфордского Университета (он вообще сейчас один из лидеров в области ИИ, его выпускники работают в Google, Facebook, Amazon, Microsoft, в стартапах в Кремниевой долине):  http://cs231n.github.io/***  \n",
    "\n",
    "3). Практически исчерпывающая информация по основам нейросетей (из cs231n) (на английском):  \n",
    "\n",
    "http://cs231n.github.io/neural-networks-1/,  \n",
    "http://cs231n.github.io/neural-networks-2/,  \n",
    "http://cs231n.github.io/neural-networks-3/,  \n",
    "http://cs231n.github.io/neural-networks-case-study/#linear\n",
    "\n",
    "4). *Хорошие статьи по основам нейросетей (на английском):  http://neuralnetworksanddeeplearning.com/chap1.html*\n",
    "\n",
    "5). *Наглядная демонстрация того, как обучаются нейросети:  https://cs.stanford.edu/people/karpathy/convnetjs/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xwm-U0_fWs1D"
   },
   "source": [
    "6). *Подробнее про backprop -- статья на Medium: https://medium.com/autonomous-agents/backpropagation-how-neural-networks-learn-complex-behaviors-9572ac161670*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEp-J26CWs1E"
   },
   "source": [
    "7). *Статья из интернет по Backprop: http://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]fashionmnist_kaggle.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
